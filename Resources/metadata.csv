Paper Number,Paper Venue,Keywords,Paper Link,Authors,Citation (BibTeX),Paper Name,Figure of Widget(s),Size,Quantity,Physicalization,Tangible-Virtual Mapping,Inherent Material Properties,Material Properties,Physical Form,Description of the Physical Form,Functional Shape,Description of the Functional Shape,Manipulation Method,Interaction Type,Interaction Description,Where the Interaction Happens,Input Type of Interaction,Input Description,Task Content,Task Entity's Representation,Description of the Task Entity's Representation,Description of the Output on Task Entity,Task Environment,Task-Interaction-Widget Mapping,Accessible Distance between User and Visualization Widget(s),Impact of Distance Change between User and Visualization Widget(s),Accessible Distance between User and Task Entity,Impact of Distance Change between User and Task Entity,Spatial Integration between Task Entity and Visualization Widget(s),Description of Spatial Integration between Task Entity and Visualization Widget(s)
1,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1753846.1754229,"Spindler, Martin and Dachselt, Raimund","@inproceedings{10.1145/1753846.1754229,
author = {Spindler, Martin and Dachselt, Raimund},
title = {Exploring information spaces by using tangible magic lenses in a tabletop environment},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1754229},
doi = {10.1145/1753846.1754229},
abstract = {To solve the challenge of exploring large information spaces on interactive surfaces such as tabletops, we developed an optically tracked, lightweight, passive display (magic lens) that provides elegant three-dimensional exploration of rich datasets. This can either be volumetric, layered, zoomable, or temporal information spaces, which are mapped onto the physical volume above a tabletop. By moving the magic lens through the volume, corresponding data is displayed, thus serving as a window into virtuality. Hereby, various interaction techniques are introduced, which especially utilize the lens' height above a tabletop in a novel way, e.g. for zooming or displaying information layers.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {4771¨C4776},
numpages = {6},
keywords = {data exploration, interactive surface, ir-tracking, magic lens, natural interaction, paper display, passive display, tabletop, tangible interaction, volume slicing, window into virtuality},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}",Exploring information spaces by using tangible magic lenses in a tabletop environment,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning+Rotating,Moving a paper-based display in space for slicing the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Clipping,3D,3D medical volume rendering,"The image, position and rotation of the slice from the 3D visualization of medical volume data displayed on the paper-based display.",2D display,Use a plate to clip a 3D medical volume rendering by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The paper-based display is in user's hand.
2. The cutting plane attached to paper-based display is crossed over the 3D visualization.
3. The 3D visualization is above the desktop."
1,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1753846.1754229,"Spindler, Martin and Dachselt, Raimund","@inproceedings{10.1145/1753846.1754229,
author = {Spindler, Martin and Dachselt, Raimund},
title = {Exploring information spaces by using tangible magic lenses in a tabletop environment},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1754229},
doi = {10.1145/1753846.1754229},
abstract = {To solve the challenge of exploring large information spaces on interactive surfaces such as tabletops, we developed an optically tracked, lightweight, passive display (magic lens) that provides elegant three-dimensional exploration of rich datasets. This can either be volumetric, layered, zoomable, or temporal information spaces, which are mapped onto the physical volume above a tabletop. By moving the magic lens through the volume, corresponding data is displayed, thus serving as a window into virtuality. Hereby, various interaction techniques are introduced, which especially utilize the lens' height above a tabletop in a novel way, e.g. for zooming or displaying information layers.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {4771¨C4776},
numpages = {6},
keywords = {data exploration, interactive surface, ir-tracking, magic lens, natural interaction, paper display, passive display, tabletop, tangible interaction, volume slicing, window into virtuality},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}",Exploring information spaces by using tangible magic lenses in a tabletop environment,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving a paper-based display at different height in space for selecting the visualization layer.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Looking up,3D,3D medical volume rendering,The position and rotation of one displaying layer of 3D visualization of medical volume data displayed on the paper-based display.,2D display,Use a plate to lookup a 3D medical volume rendering by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the 3D visualization.
3. The 3D visualization is above the desktop."
1,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1753846.1754229,"Spindler, Martin and Dachselt, Raimund","@inproceedings{10.1145/1753846.1754229,
author = {Spindler, Martin and Dachselt, Raimund},
title = {Exploring information spaces by using tangible magic lenses in a tabletop environment},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1754229},
doi = {10.1145/1753846.1754229},
abstract = {To solve the challenge of exploring large information spaces on interactive surfaces such as tabletops, we developed an optically tracked, lightweight, passive display (magic lens) that provides elegant three-dimensional exploration of rich datasets. This can either be volumetric, layered, zoomable, or temporal information spaces, which are mapped onto the physical volume above a tabletop. By moving the magic lens through the volume, corresponding data is displayed, thus serving as a window into virtuality. Hereby, various interaction techniques are introduced, which especially utilize the lens' height above a tabletop in a novel way, e.g. for zooming or displaying information layers.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {4771¨C4776},
numpages = {6},
keywords = {data exploration, interactive surface, ir-tracking, magic lens, natural interaction, paper display, passive display, tabletop, tangible interaction, volume slicing, window into virtuality},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}",Exploring information spaces by using tangible magic lenses in a tabletop environment,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving a paper-based display in space for navigating (panning and scaling) the 2D map.,above the horizontal surface,Position,Physical widget: 3DOF translation in the plane.,Navigating,2D,2D map,"The viewpoint position, rotation and scale of the 2D map displayed on the paper-based display.",2D display,Use a plate to navigate a 2D map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the 2D map.
3. The 2D map is above the desktop."
1,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1753846.1754229,"Spindler, Martin and Dachselt, Raimund","@inproceedings{10.1145/1753846.1754229,
author = {Spindler, Martin and Dachselt, Raimund},
title = {Exploring information spaces by using tangible magic lenses in a tabletop environment},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1754229},
doi = {10.1145/1753846.1754229},
abstract = {To solve the challenge of exploring large information spaces on interactive surfaces such as tabletops, we developed an optically tracked, lightweight, passive display (magic lens) that provides elegant three-dimensional exploration of rich datasets. This can either be volumetric, layered, zoomable, or temporal information spaces, which are mapped onto the physical volume above a tabletop. By moving the magic lens through the volume, corresponding data is displayed, thus serving as a window into virtuality. Hereby, various interaction techniques are introduced, which especially utilize the lens' height above a tabletop in a novel way, e.g. for zooming or displaying information layers.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {4771¨C4776},
numpages = {6},
keywords = {data exploration, interactive surface, ir-tracking, magic lens, natural interaction, paper display, passive display, tabletop, tangible interaction, volume slicing, window into virtuality},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}",Exploring information spaces by using tangible magic lenses in a tabletop environment,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving a paper-based display in space horizontally for selecting the dataset.,above the horizontal surface,Position,Physical widget: 2DOF translation in the space horizontally.,Looking up,2D,2D video,One frame from one of multiple videos displayed on the paper-based display.,2D display,Use a plate to lookup a 2D video by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the video.
3. The video is above the desktop."
1,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1753846.1754229,"Spindler, Martin and Dachselt, Raimund","@inproceedings{10.1145/1753846.1754229,
author = {Spindler, Martin and Dachselt, Raimund},
title = {Exploring information spaces by using tangible magic lenses in a tabletop environment},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1754229},
doi = {10.1145/1753846.1754229},
abstract = {To solve the challenge of exploring large information spaces on interactive surfaces such as tabletops, we developed an optically tracked, lightweight, passive display (magic lens) that provides elegant three-dimensional exploration of rich datasets. This can either be volumetric, layered, zoomable, or temporal information spaces, which are mapped onto the physical volume above a tabletop. By moving the magic lens through the volume, corresponding data is displayed, thus serving as a window into virtuality. Hereby, various interaction techniques are introduced, which especially utilize the lens' height above a tabletop in a novel way, e.g. for zooming or displaying information layers.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {4771¨C4776},
numpages = {6},
keywords = {data exploration, interactive surface, ir-tracking, magic lens, natural interaction, paper display, passive display, tabletop, tangible interaction, volume slicing, window into virtuality},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}",Exploring information spaces by using tangible magic lenses in a tabletop environment,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving a paper-based display at different height in space for adjusting the value of the time axis.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,2D,2D video,One frame from one of multiple videos displayed on the paper-based display.,2D display,Use a plate to adjust a 2D video by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the video.
3. The video is above the desktop."
2,PubMed - Medicine Meets Virtual Reality,3D Interaction,https://pubmed.ncbi.nlm.nih.gov/21335844/,"Rick, Tobias and von Kapri, Anette and Caspers, Svenja and Amunts, Katrin and Zilles, Karl and Kuhlen, Torsten","@incollection{rick2011visualization,
  title={Visualization of probabilistic fiber tracts in virtual reality},
  author={Rick, Tobias and von Kapri, Anette and Caspers, Svenja and Amunts, Katrin and Zilles, Karl and Kuhlen, Torsten},
  booktitle={Medicine Meets Virtual Reality 18},
  pages={486--492},
  year={2011},
  publisher={IOS Press}
}",Visualization of probabilistic fiber tracts in virtual reality,,Small,Double,A virtual widget+A tangible widget,Fully mapped,Rigid,No use,Slender body (with Non-planar surface),A handheld device (with a cone attached to the distal end of handheld device),Non-planar surface,A cone attached to the distal end of handheld device,One-handed,Casting,Moving a handheld device in space to cast a clipping cone for clipping the 3D visualization.,in the room space,"Position,Rotation","Virtual widget: 3DOF translation and 3DOF rotation in the space.
Physical widget: 3DOF translation and 3DOF rotation in the space.",Clipping,3D,3D medical volume rendering,The position and rotation of the clipping cone within the 3D visualization of medical volume data displayed in the virtual reality (CAVE).,Virtual reality,Use a non-planar surface controlled by a slender body to clip a 3D medical volume rendering by casting.,Reachable,"Virtual: Not impacted within the accessible distance.
Physical: Interaction is possible only if manipulable entity is grabbed by user.",Flexible,Not impacted within the accessible distance.,Crossed,"1. The handheld device is in user's hand.
2. The cutting cone attached to handheld device is crossed over the 3D visualization.
3. The 3D visualization is in the room."
3,VR,3D Interaction,https://ieeexplore.ieee.org/document/8797684,"Khadka, Rajiv and Banic, Amy","@INPROCEEDINGS{8797684,
  author={Khadka, Rajiv and Banic, Amy},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={Body-Prop Interaction: Evaluation of Augmented Open Discs and Egocentric Body-Based Interaction}, 
  year={2019},
  volume={},
  number={},
  pages={1705-1710},
  keywords={Data visualization;Task analysis;Three-dimensional displays;Augmented reality;Headphones;Tracking;Virtual environments;Human-centered computing;Mixed / augmented reality;User studies Human-centered computing;Usability Testing},
  doi={10.1109/VR.2019.8797684}}",Body-Prop Interaction: Evaluation of Augmented Open Discs and Egocentric Body-Based Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Toroid,A circular-shaped 3D open disc,Body,A circular-shaped 3D open disc,One-handed,Positioning,Moving a open disc in space to contact the 3D virtual object for selecting.,in the room space,Position,Physical widget: 3DOF translation in the space.,Looking up,3D,3D graphic,The position and rotation of the 3D virtual object displayed in the augmented reality (HMD).,Augmented reality,Use a toroid to lookup a 3D graphic by positioning.,"Embodied,Reachable",Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The 3D open disc is in user's hand.
2. The 3D open disc is crossed over the 3D graphic.
3. The 3D graphic is in the room."
3,VR,3D Interaction,https://ieeexplore.ieee.org/document/8797684,"Khadka, Rajiv and Banic, Amy","@INPROCEEDINGS{8797684,
  author={Khadka, Rajiv and Banic, Amy},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={Body-Prop Interaction: Evaluation of Augmented Open Discs and Egocentric Body-Based Interaction}, 
  year={2019},
  volume={},
  number={},
  pages={1705-1710},
  keywords={Data visualization;Task analysis;Three-dimensional displays;Augmented reality;Headphones;Tracking;Virtual environments;Human-centered computing;Mixed / augmented reality;User studies Human-centered computing;Usability Testing},
  doi={10.1109/VR.2019.8797684}}",Body-Prop Interaction: Evaluation of Augmented Open Discs and Egocentric Body-Based Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Toroid,A circular-shaped 3D open disc,Body,A circular-shaped 3D open disc,One-handed,Positioning+Rotating,Moving a open disc in space for manipulating the 3D virtual object.,in the room space,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D graphic,The position and rotation of the 3D virtual object displayed in the augmented reality (HMD).,Augmented reality,Use a toroid to translate/rotate/scale a 3D graphic by positioning+rotating.,"Embodied,Reachable",Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The 3D open disc is in user's hand.
2. The 3D open disc is crossed over the 3D graphic.
3. The 3D graphic is in the room."
4,SUI,3D Interaction,https://dl.acm.org/doi/10.1145/2788940.2788941,"Berg\'{e}, Louis-Pierre and Dubois, Emmanuel and Raynal, Mathieu","@inproceedings{10.1145/2788940.2788941,
author = {Berg\'{e}, Louis-Pierre and Dubois, Emmanuel and Raynal, Mathieu},
title = {Design and Evaluation of an ""Around the SmartPhone"" Technique for 3D Manipulations on Distant Display},
year = {2015},
isbn = {9781450337038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2788940.2788941},
doi = {10.1145/2788940.2788941},
abstract = {In this paper, we present the ""Around the SmartPhone"" interaction technique for manipulating 3D elements displayed on a distant screen. The design of the technique is based on the selection of the most appropriate value for characteristics useful to discriminate existing tactile and tangible techniques for 3D manipulations. We perform two user studies to compare this around-device technique for translating and rotating 3D objects, with two existing tangible and tactile solutions, in terms of performance and user's preference. The literature establishes that the tactile technique evaluated is the best tactile technique among the existing tactile techniques for 3D manipulation. Despite this result, our user study reveals that the two others perform significantly better. In addition, when feedback visibility is preserved, the around-device technique offers similar performance results than the tangible one. Finally, the around-device technique is significantly preferred over the two others in every condition.},
booktitle = {Proceedings of the 3rd ACM Symposium on Spatial User Interaction},
pages = {69¨C78},
numpages = {10},
keywords = {manipulation task, around-device interaction, 3d interaction},
location = {Los Angeles, California, USA},
series = {SUI '15}
}","Design and Evaluation of an ""Around the SmartPhone"" Technique for 3D Manipulations on Distant Display",,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A mobile device,Body,A mobile device,One-handed,Positioning+Rotating,Moving a mobile device in space for translating and rotating the 3D graphic.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D graphic,The position and rotation of the 3D virtual object displayed on the screen on the mobile device.,2D display,Use a plate to translate/rotate/scale a 3D graphic by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The mobile device is in user's hand.
2. The mobile device is discrete from the 3D graphic.
3. The 3D graphic is away from the user."
5,VR,3D Interaction,https://ieeexplore.ieee.org/document/8797871,"Nam, Jung Who and McCullough, Krista and Tveite, Joshua and Espinosa, Maria Molina and Perry, Charles H. and Wilson, Barry T. and Keefe, Daniel F.","@INPROCEEDINGS{8797871,
  author={Nam, Jung Who and McCullough, Krista and Tveite, Joshua and Espinosa, Maria Molina and Perry, Charles H. and Wilson, Barry T. and Keefe, Daniel F.},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={Worlds-in-Wedges: Combining Worlds-in-Miniature and Portals to Support Comparative Immersive Visualization of Forestry Data}, 
  year={2019},
  volume={},
  number={},
  pages={747-755},
  keywords={Data visualization;Forestry;Visualization;Three-dimensional displays;Portals;Computer science;Task analysis;worlds-in-miniature;3D user interface;presence;comparative visualization;Human-centered computing¡ªVirtual reality;Human-centered computing¡ªInteraction techniques;Human-centered computing¡ªScientific visualization;Human-centered computing¡ªGeographic visualization},
  doi={10.1109/VR.2019.8797871}}",Worlds-in-Wedges: Combining Worlds-in-Miniature and Portals to Support Comparative Immersive Visualization of Forestry Data,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A handheld VR controller,Straight edge,A casting ray attached to the distal end of handheld VR controller,One-handed,Casting,Moving a handheld VR controller in space to cast a ray on the plane to input a position for creating a WIM/annotation.,in the room space,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,2D,2D map,The position of the WIM displayed in the virtual reality (HMD).,Virtual reality,Use a slender body to modulate a 2D map by casting.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Crossed,"1. The handheld VR controller is in user's hand.
2. The casting ray from handheld VR controller is crossed over the 2D map.
3. The 2D map is in the room."
5,VR,3D Interaction,https://ieeexplore.ieee.org/document/8797871,"Nam, Jung Who and McCullough, Krista and Tveite, Joshua and Espinosa, Maria Molina and Perry, Charles H. and Wilson, Barry T. and Keefe, Daniel F.","@INPROCEEDINGS{8797871,
  author={Nam, Jung Who and McCullough, Krista and Tveite, Joshua and Espinosa, Maria Molina and Perry, Charles H. and Wilson, Barry T. and Keefe, Daniel F.},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={Worlds-in-Wedges: Combining Worlds-in-Miniature and Portals to Support Comparative Immersive Visualization of Forestry Data}, 
  year={2019},
  volume={},
  number={},
  pages={747-755},
  keywords={Data visualization;Forestry;Visualization;Three-dimensional displays;Portals;Computer science;Task analysis;worlds-in-miniature;3D user interface;presence;comparative visualization;Human-centered computing¡ªVirtual reality;Human-centered computing¡ªInteraction techniques;Human-centered computing¡ªScientific visualization;Human-centered computing¡ªGeographic visualization},
  doi={10.1109/VR.2019.8797871}}",Worlds-in-Wedges: Combining Worlds-in-Miniature and Portals to Support Comparative Immersive Visualization of Forestry Data,,Small,Double,A virtual widget+A tangible widget,Partial mapped,Rigid,No use,Slender body (with Body),A handheld VR controller (with a WIM),Body,A WIM,One-handed,Positioning,Moving a handheld VR controller to manipulate the WIM in space for comparing two visualizations.,in the room space,Position,"Virtual widget: 3DOF translation in the space.
Physical widget: 3DOF translation in the space.",Replacing,3D,3D glyph+3D equation,The representation of combining 3D visualization of forest/historical/high-dimensional data displayed in the virtual reality (HMD).,Virtual reality,Use a plate controlled by a slender body to replace a 3D glyph+3D equation by positioning.,Reachable,"Physical: Interaction is possible only if manipulable entity is grabbed by user.
Virtual: Not impacted within the accessible distance.",Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The handheld VR controller is in user's hand.
2. The WIM controlled by the distal end of handheld VR controller is embedded with the 3D visualization.
3. The 3D visualization is in the room."
5,VR,3D Interaction,https://ieeexplore.ieee.org/document/8797871,"Nam, Jung Who and McCullough, Krista and Tveite, Joshua and Espinosa, Maria Molina and Perry, Charles H. and Wilson, Barry T. and Keefe, Daniel F.","@INPROCEEDINGS{8797871,
  author={Nam, Jung Who and McCullough, Krista and Tveite, Joshua and Espinosa, Maria Molina and Perry, Charles H. and Wilson, Barry T. and Keefe, Daniel F.},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={Worlds-in-Wedges: Combining Worlds-in-Miniature and Portals to Support Comparative Immersive Visualization of Forestry Data}, 
  year={2019},
  volume={},
  number={},
  pages={747-755},
  keywords={Data visualization;Forestry;Visualization;Three-dimensional displays;Portals;Computer science;Task analysis;worlds-in-miniature;3D user interface;presence;comparative visualization;Human-centered computing¡ªVirtual reality;Human-centered computing¡ªInteraction techniques;Human-centered computing¡ªScientific visualization;Human-centered computing¡ªGeographic visualization},
  doi={10.1109/VR.2019.8797871}}",Worlds-in-Wedges: Combining Worlds-in-Miniature and Portals to Support Comparative Immersive Visualization of Forestry Data,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A handheld VR controller,Point,The distal end of handheld VR controller,One-handed,Positioning,Moving a handheld VR controller in space to manipulate the WIM for adjusting the angle of wedge displaying the 3D visualization.,in the room space,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,3D,3D glyph+3D equation,The angle and position of the wedge displaying the 3D visualization of forest/historical/high-dimensional data displayed in the virtual reality (HMD).,Virtual reality,Use a slender body to adjust a 3D glyph+3D equation by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Embedded,"1. The handheld VR controller is in user's hand.
2. The tip of handheld VR controller is embedded with the 3D visualization.
3. The 3D visualization is in the room."
6,3DUI,3D Interaction,https://ieeexplore.ieee.org/document/5444707,"Tawara, Takehiro and Ono, Kenji","@INPROCEEDINGS{5444707,
  author={Tawara, Takehiro and Ono, Kenji},
  booktitle={2010 IEEE Symposium on 3D User Interfaces (3DUI)}, 
  title={A framework for volume segmentation and visualization using Augmented Reality}, 
  year={2010},
  volume={},
  number={},
  pages={121-122},
  keywords={Augmented reality;Data visualization;Data mining;Magnetic resonance imaging;Tracking;Humans;Motion control;Control systems;Shape control;Needles},
  doi={10.1109/3DUI.2010.5444707}}",A framework for volume segmentation and visualization using Augmented Reality,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A sheet of square cardboard,Planar surface,A sheet of square cardboard,One-handed,Positioning+Rotating,Moving a sheet of square cardboard in space for manipulating the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D medical volume rendering,The position and rotation of a 3D visualization of medical volume data displayed in the augmented reality (HMD).,Augmented reality,Use a plate to translate/rotate/scale a 3D medical volume rendering by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The cardboard is in user's hand. 
2. The cardboard is aligned with the 3D visualization.
3. The 3D visualization is above the desktop."
6,3DUI,3D Interaction,https://ieeexplore.ieee.org/document/5444707,"Tawara, Takehiro and Ono, Kenji","@INPROCEEDINGS{5444707,
  author={Tawara, Takehiro and Ono, Kenji},
  booktitle={2010 IEEE Symposium on 3D User Interfaces (3DUI)}, 
  title={A framework for volume segmentation and visualization using Augmented Reality}, 
  year={2010},
  volume={},
  number={},
  pages={121-122},
  keywords={Augmented reality;Data visualization;Data mining;Magnetic resonance imaging;Tracking;Humans;Motion control;Control systems;Shape control;Needles},
  doi={10.1109/3DUI.2010.5444707}}",A framework for volume segmentation and visualization using Augmented Reality,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A handheld wii remote controller,Point,The distal end of handheld wii remote controller,One-handed,Positioning,"1. Locating the distal end of handheld wii remote controller in space to input a position as a seed point of selection.
 2. Locating the distal end of handheld wii remote controller in space to input a position to calculate the distance from seed point for extracting desired shape.",above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Locating,3D,3D medical volume rendering,"The position of the seed point, the distance between the seed point and the handheld controller and the extraction shape on the 3D visualization of medical volume data displayed in the augmented reality (HMD).",Augmented reality,Use a slender body to locate a 3D medical volume rendering by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The handheld wii remote controller is in user's hand.
2. The distal end of handheld wii remote controller is embedded with the 3D visualization.
3. The 3D visualization is above the desktop."
7,CHI EA,3D Interaction,https://dl.acm.org/doi/abs/10.1145/2559206.2581340,"Chakraborty, Arpan and Gross, Ryan and McIntee, Shea and Hong, Kyung Wha and Lee, Jae Yeol and St. Amant, Robert","@inproceedings{10.1145/2559206.2581340,
author = {Chakraborty, Arpan and Gross, Ryan and McIntee, Shea and Hong, Kyung Wha and Lee, Jae Yeol and St. Amant, Robert},
title = {CAPTIVE: a cube with augmented physical tools},
year = {2014},
isbn = {9781450324748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2559206.2581340},
doi = {10.1145/2559206.2581340},
abstract = {This paper describes a tangible 3D user interface called CAPTIVE, a Cube with Augmented Physical Tools, for exploration of 3D information. The design of CAPTIVE is founded on the concept of tool use, in which handheld tool objects are used to modify the properties or appearance of target objects. The user of CAPTIVE holds a physical wireframe cube that contains virtual objects in one hand, in the other a pointing device, its tip visually augmented to reflect its function as a tool. On the display the user watches the immediate, direct effects of actions with the tool. In the current prototype, routines for handling cube manipulation and an augmented haptic pointing device have been separately implemented, but integration and refinement remain to be done. In this paper we describe our vision of the system and preliminary testing carried out to date.},
booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
pages = {1315¨C1320},
numpages = {6},
keywords = {3d user interfaces, augmented reality, tangible computing, tool-based interaction},
location = {Toronto, Ontario, Canada},
series = {CHI EA '14}
}",CAPTIVE: a cube with augmented physical tools,,Medium,Single,A tangible widget,N/A,"Rigid, Reconfigurable",No use,Skeletal body,A cubic frame,Body,A cubic frame,One-handed,Positioning+Rotating,Moving a cubic frame in space for manipulating the 3D model.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D graphic,The position and rotation of a 3D visualization of 3D heart model displayed in the augmented reality (screen).,Augmented reality,Use a skeletal body to translate/rotate/scale a 3D graphic by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Embedded,"1. The frame is in user's hand.
2. The 3D visualization is embedded with the frame.
3. The 3D visualization is above the desktop."
8,3DUI,3D Interaction,https://ieeexplore.ieee.org/document/6798839,"Issartel, Paul and Gu¨¦niat, Florimond and Ammi, Mehdi","@INPROCEEDINGS{6798839,
  author={Issartel, Paul and Gu¨¦niat, Florimond and Ammi, Mehdi},
  booktitle={2014 IEEE Symposium on 3D User Interfaces (3DUI)}, 
  title={Slicing techniques for handheld augmented reality}, 
  year={2014},
  volume={},
  number={},
  pages={39-42},
  keywords={Mice;Three-dimensional displays;Augmented reality;Trajectory;Visualization;Tracking;Handheld computers;Augmented reality;3D interaction;tangible user interface;scientific visualization},
  doi={10.1109/3DUI.2014.6798839}}",Slicing techniques for handheld augmented reality,,Small,Double,A virtual widget+A tangible widget,Fully mapped,Rigid,No use,Slender body (with Planar surface),A stylus (with a cutting plane attached to the tip of stylus),Planar surface,A virtual cutting plane attached to the tip of stylus,One-handed,Positioning+Rotating,Moving a virtual cutting plane attached to the tip of stylus in space for slicing the 3D visualization.,above the horizontal surface,"Position,Rotation","Virtual widget: 3DOF translation and 3DOF rotation in the space.
Physical widget: 3DOF translation and 3DOF rotation in the space.",Clipping,3D,3D medical volume rendering,"1. The position and rotation of the cutting plane within the 3D visualization of medical volume data displayed in the augmented reality (screen).
2. The image, position and rotation of the slice from the 3D visualization of medical volume data displayed in the augmented reality (screen).",Augmented reality,Use a planar surface controlled by a slender body to clip a 3D medical volume rendering by positioning+rotating.,Reachable,"Virtual: Not impacted within the accessible distance.
Physical: Interaction is possible only if manipulable entity is grabbed by user.",Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The stylus is in user's hand. 
2. The cutting plane attached to the tip of stylus is crossed over the 3D visualization.
2. The 3D visualization is on the desktop. "
8,3DUI,3D Interaction,https://ieeexplore.ieee.org/document/6798839,"Issartel, Paul and Gu¨¦niat, Florimond and Ammi, Mehdi","@INPROCEEDINGS{6798839,
  author={Issartel, Paul and Gu¨¦niat, Florimond and Ammi, Mehdi},
  booktitle={2014 IEEE Symposium on 3D User Interfaces (3DUI)}, 
  title={Slicing techniques for handheld augmented reality}, 
  year={2014},
  volume={},
  number={},
  pages={39-42},
  keywords={Mice;Three-dimensional displays;Augmented reality;Trajectory;Visualization;Tracking;Handheld computers;Augmented reality;3D interaction;tangible user interface;scientific visualization},
  doi={10.1109/3DUI.2014.6798839}}",Slicing techniques for handheld augmented reality,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A handheld tablet,Planar surface,A surface of handheld tablet,Symmetric,Positioning+Rotating,Moving a surface of handheld tablet in space for slicing the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Clipping,3D,3D medical volume rendering,"The image, position and rotation of the slice from the 3D visualization of medical volume data displayed in the augmented reality (screen).",Augmented reality,Use a plate to clip a 3D medical volume rendering by two-handed positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The handheld tablet is in user's hand. 
2. The cutting plane attached to the surface of handheld tablet is crossed over the 3D visualization.
3. The 3D visualization is on the desktop. "
9,CHI,3D Interaction,https://dl.acm.org/doi/10.1145/2470654.2466191,"Leithinger, Daniel and Follmer, Sean and Olwal, Alex and Luescher, Samuel and Hogge, Akimitsu and Lee, Jinha and Ishii, Hiroshi","@inproceedings{10.1145/2470654.2466191,
author = {Leithinger, Daniel and Follmer, Sean and Olwal, Alex and Luescher, Samuel and Hogge, Akimitsu and Lee, Jinha and Ishii, Hiroshi},
title = {Sublimate: state-changing virtual and physical rendering to augment interaction with shape displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466191},
doi = {10.1145/2470654.2466191},
abstract = {Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and deposition, as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed two systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video seethrough AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how freehand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1441¨C1450},
numpages = {10},
keywords = {spatial augmented reality, shape display, actuated tangibles, 3d interaction},
location = {Paris, France},
series = {CHI '13}
}",Sublimate: state-changing virtual and physical rendering to augment interaction with shape displays,,Large,Multiple,A set of tangible widgets,N/A,Stretchable,Stretchable,Constrained body,Columns,Straight edge,The tips of columns,One-handed,Positioning,Sliding columns on desktop for adjusting the shape of NURBS surface.,on the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Adjusting,3D,3D equation,The shape of NURBS surface displayed in the augmented reality (screen).,Augmented reality,Use multiple slender body to adjust a 3D equation by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The array of columns is on the desktop.
2. The tips of the array of columns are aligned with the 3D visualization.
3. The 3D visualization is above the desktop."
9,CHI,3D Interaction,https://dl.acm.org/doi/10.1145/2470654.2466191,"Leithinger, Daniel and Follmer, Sean and Olwal, Alex and Luescher, Samuel and Hogge, Akimitsu and Lee, Jinha and Ishii, Hiroshi","@inproceedings{10.1145/2470654.2466191,
author = {Leithinger, Daniel and Follmer, Sean and Olwal, Alex and Luescher, Samuel and Hogge, Akimitsu and Lee, Jinha and Ishii, Hiroshi},
title = {Sublimate: state-changing virtual and physical rendering to augment interaction with shape displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466191},
doi = {10.1145/2470654.2466191},
abstract = {Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and deposition, as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed two systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video seethrough AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how freehand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1441¨C1450},
numpages = {10},
keywords = {spatial augmented reality, shape display, actuated tangibles, 3d interaction},
location = {Paris, France},
series = {CHI '13}
}",Sublimate: state-changing virtual and physical rendering to augment interaction with shape displays,,Large,Multiple,A virtual widget+A set of tangible widgets,Partial mapped,Stretchable,Stretchable,Slender body (with Non-planar surface),An array of columns (with a curved cutting plane attached to the tips of the array of columns),Non-planar surface,The non-planar surface formed by tips of an array of columns,One-handed,Positioning,Moving an array of columns on desktop to control a curved cutting plane for clipping the 3D visualization.,on the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Clipping,3D,3D medical volume rendering,"The image, position and rotation of the slice from the 3D visualization of medical volume data displayed in the augmented reality (screen).",Augmented reality,Use a non-planar surface controlled by multiple slender body to clip a 3D medical volume rendering by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The array of columns is on the desktop.
2. The curved cutting plane attached to the tips of the array of columns is crossed over the 3D visualization.
3. The 3D visualization is above the desktop."
10,VRST,3D Interaction,https://dl.acm.org/doi/10.1145/2671015.2671130,"Issartel, Paul and Gu\'{e}niat, Florimond and Ammi, Mehdi","@inproceedings{10.1145/2671015.2671130,
author = {Issartel, Paul and Gu\'{e}niat, Florimond and Ammi, Mehdi},
title = {A portable interface for tangible exploration of volumetric data},
year = {2014},
isbn = {9781450332538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2671015.2671130},
doi = {10.1145/2671015.2671130},
abstract = {Exploration of volumetric data is an essential task in many scientific fields. However, the use of standard devices, such as the 2D mouse, leads to suboptimal interaction mappings. Several VR systems provide better interaction capabilities, but they remain dedicated and expensive solutions. In this work, we propose an interface that combines tangible tools and a handheld device. This configuration allows natural and full 6 DOF interaction in a convenient, fully portable and affordable system. This paper presents our design choices for this interface and associated tangible exploration techniques.},
booktitle = {Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology},
pages = {209¨C210},
numpages = {2},
keywords = {3D interaction, scientific visualization, tangible user interface},
location = {Edinburgh, Scotland},
series = {VRST '14}
}",A portable interface for tangible exploration of volumetric data,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A stylus,Point,The tip of the stylus,One-handed,Positioning,Locating the tip of stylus in space to input a position for generating an iso-surface.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Locating,3D,3D medical volume rendering,The position of input point with an iso-surface of 3D visualization of volume data displayed in the augmented reality (screen).,Augmented reality,Use a slender body to locate a 3D medical volume rendering by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The stylus is in user's hand.
2. The tip of stylus is embedded with the 3D visualization.
3. The 3D visualization is on the desktop. "
10,VRST,3D Interaction,https://dl.acm.org/doi/10.1145/2671015.2671130,"Issartel, Paul and Gu\'{e}niat, Florimond and Ammi, Mehdi","@inproceedings{10.1145/2671015.2671130,
author = {Issartel, Paul and Gu\'{e}niat, Florimond and Ammi, Mehdi},
title = {A portable interface for tangible exploration of volumetric data},
year = {2014},
isbn = {9781450332538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2671015.2671130},
doi = {10.1145/2671015.2671130},
abstract = {Exploration of volumetric data is an essential task in many scientific fields. However, the use of standard devices, such as the 2D mouse, leads to suboptimal interaction mappings. Several VR systems provide better interaction capabilities, but they remain dedicated and expensive solutions. In this work, we propose an interface that combines tangible tools and a handheld device. This configuration allows natural and full 6 DOF interaction in a convenient, fully portable and affordable system. This paper presents our design choices for this interface and associated tangible exploration techniques.},
booktitle = {Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology},
pages = {209¨C210},
numpages = {2},
keywords = {3D interaction, scientific visualization, tangible user interface},
location = {Edinburgh, Scotland},
series = {VRST '14}
}",A portable interface for tangible exploration of volumetric data,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A stylus,Point,The tip of the stylus,One-handed,Positioning,Locating the tip of stylus in space to input a position for generating a seed.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Browsing,3D,3D medical volume rendering,The position of generating a seed of 3D visualization of volume data displayed in the augmented reality (screen).,Augmented reality,Use a slender body to browse a 3D medical volume rendering by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The stylus is in user's hand.
2. The tip of stylus is embedded with the 3D visualization.
3. The 3D visualization is on the desktop. "
11,ISVC,3D Interaction,https://link.springer.com/chapter/10.1007/978-3-642-17274-8_37,"Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H.","@InProceedings{10.1007/978-3-642-17274-8_37,
author=""Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H."",
editor=""Bebis, George
and Boyle, Richard
and Parvin, Bahram
and Koracin, Darko
and Chung, Ronald
and Hammound, Riad
and Hussain, Muhammad
and Kar-Han, Tan
and Crawfis, Roger
and Thalmann, Daniel
and Kao, David
and Avila, Lisa"",
title=""A Fiducial-Based Tangible User Interface for White Matter Tractography"",
booktitle=""Advances in Visual Computing"",
year=""2010"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""373--381"",
abstract=""We present a method for interacting with 3D brain tract visualizations using a webcam and a fiducial marker that can be constructed cheaply in any home or office. Our contributions are a fiducial-based tracking architecture in the context of white matter tractography, and a preliminary evaluation with domain scientists providing usability and design insights. Expert feedback indicates that model positioning in our system is easier than in previous methods using traditional input devices or two-dimensional input interfaces, and that tract selection may be faster to execute using our tool, given training and practice."",
isbn=""978-3-642-17274-8""
}",A Fiducial-Based Tangible User Interface for White Matter Tractography,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A cube or a decahedron,Body,A cube or a decahedron,One-handed,Positioning+Rotating,Moving a cube or a decahedron in space for manipulating the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D medical volume rendering,The position and rotation of the 3D visualization of medical volume data displayed on the screen.,2D display,Use a polyhedron to translate/rotate/scale a 3D medical volume rendering by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The cube or decahedron is in user's hand.
2. The cube or decahedron is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
11,ISVC,3D Interaction,https://link.springer.com/chapter/10.1007/978-3-642-17274-8_37,"Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H.","@InProceedings{10.1007/978-3-642-17274-8_37,
author=""Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H."",
editor=""Bebis, George
and Boyle, Richard
and Parvin, Bahram
and Koracin, Darko
and Chung, Ronald
and Hammound, Riad
and Hussain, Muhammad
and Kar-Han, Tan
and Crawfis, Roger
and Thalmann, Daniel
and Kao, David
and Avila, Lisa"",
title=""A Fiducial-Based Tangible User Interface for White Matter Tractography"",
booktitle=""Advances in Visual Computing"",
year=""2010"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""373--381"",
abstract=""We present a method for interacting with 3D brain tract visualizations using a webcam and a fiducial marker that can be constructed cheaply in any home or office. Our contributions are a fiducial-based tracking architecture in the context of white matter tractography, and a preliminary evaluation with domain scientists providing usability and design insights. Expert feedback indicates that model positioning in our system is easier than in previous methods using traditional input devices or two-dimensional input interfaces, and that tract selection may be faster to execute using our tool, given training and practice."",
isbn=""978-3-642-17274-8""
}",A Fiducial-Based Tangible User Interface for White Matter Tractography,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A cube or a decahedron,Body,A cube or a decahedron,One-handed,Shaking,Shaking a cube or a decahedron in space for adjusting the mode of manipulating or freezing the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Adjusting,3D,3D medical volume rendering,The mode of manipulating or freezing the 3D visualization displayed on the screen.,2D display,Use a polyhedron to adjust a 3D medical volume rendering by shaking.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The cube or decahedron is in user's hand.
2. The cube or decahedron is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
11,ISVC,3D Interaction,https://link.springer.com/chapter/10.1007/978-3-642-17274-8_37,"Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H.","@InProceedings{10.1007/978-3-642-17274-8_37,
author=""Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H."",
editor=""Bebis, George
and Boyle, Richard
and Parvin, Bahram
and Koracin, Darko
and Chung, Ronald
and Hammound, Riad
and Hussain, Muhammad
and Kar-Han, Tan
and Crawfis, Roger
and Thalmann, Daniel
and Kao, David
and Avila, Lisa"",
title=""A Fiducial-Based Tangible User Interface for White Matter Tractography"",
booktitle=""Advances in Visual Computing"",
year=""2010"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""373--381"",
abstract=""We present a method for interacting with 3D brain tract visualizations using a webcam and a fiducial marker that can be constructed cheaply in any home or office. Our contributions are a fiducial-based tracking architecture in the context of white matter tractography, and a preliminary evaluation with domain scientists providing usability and design insights. Expert feedback indicates that model positioning in our system is easier than in previous methods using traditional input devices or two-dimensional input interfaces, and that tract selection may be faster to execute using our tool, given training and practice."",
isbn=""978-3-642-17274-8""
}",A Fiducial-Based Tangible User Interface for White Matter Tractography,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A stick-shaped handle,Point,The distal end of stick-shaped handle,One-handed,Rotating,"Rotating a stick-shaped handle in space for adjusting the mode of adding, removing and intersecting the selection.",above the horizontal surface,Rotation,Physical widget: 1DOF rotation at the plane of the surface attached to the stick in the space.,Adjusting,3D,3D medical volume rendering,"The mode of adding, removing and intersecting the selection of the 3D visualization displayed on the screen.",2D display,Use a slender body to adjust a 3D medical volume rendering by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The stick is in user's hand.
2. The stick is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
11,ISVC,3D Interaction,https://link.springer.com/chapter/10.1007/978-3-642-17274-8_37,"Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H.","@InProceedings{10.1007/978-3-642-17274-8_37,
author=""Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H."",
editor=""Bebis, George
and Boyle, Richard
and Parvin, Bahram
and Koracin, Darko
and Chung, Ronald
and Hammound, Riad
and Hussain, Muhammad
and Kar-Han, Tan
and Crawfis, Roger
and Thalmann, Daniel
and Kao, David
and Avila, Lisa"",
title=""A Fiducial-Based Tangible User Interface for White Matter Tractography"",
booktitle=""Advances in Visual Computing"",
year=""2010"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""373--381"",
abstract=""We present a method for interacting with 3D brain tract visualizations using a webcam and a fiducial marker that can be constructed cheaply in any home or office. Our contributions are a fiducial-based tracking architecture in the context of white matter tractography, and a preliminary evaluation with domain scientists providing usability and design insights. Expert feedback indicates that model positioning in our system is easier than in previous methods using traditional input devices or two-dimensional input interfaces, and that tract selection may be faster to execute using our tool, given training and practice."",
isbn=""978-3-642-17274-8""
}",A Fiducial-Based Tangible User Interface for White Matter Tractography,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A stick-shaped handle,Point,The distal end of stick-shaped handle,One-handed,Tracing,Moving a stick-shaped handle in space to create a circular motion for adjusting the selection sphere radius.,above the horizontal surface,Position,Physical widget: 2DOF translation in the space.,Adjusting,3D,3D medical volume rendering,The scale of the selection sphere in the 3D visualization of medical volume data displayed on the screen.,2D display,Use a slender body to adjust a 3D medical volume rendering by tracing.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The stick is in user's hand.
2. The stick is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
11,ISVC,3D Interaction,https://link.springer.com/chapter/10.1007/978-3-642-17274-8_37,"Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H.","@InProceedings{10.1007/978-3-642-17274-8_37,
author=""Gomez, Steven R.
and Jianu, Radu
and Laidlaw, David H."",
editor=""Bebis, George
and Boyle, Richard
and Parvin, Bahram
and Koracin, Darko
and Chung, Ronald
and Hammound, Riad
and Hussain, Muhammad
and Kar-Han, Tan
and Crawfis, Roger
and Thalmann, Daniel
and Kao, David
and Avila, Lisa"",
title=""A Fiducial-Based Tangible User Interface for White Matter Tractography"",
booktitle=""Advances in Visual Computing"",
year=""2010"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""373--381"",
abstract=""We present a method for interacting with 3D brain tract visualizations using a webcam and a fiducial marker that can be constructed cheaply in any home or office. Our contributions are a fiducial-based tracking architecture in the context of white matter tractography, and a preliminary evaluation with domain scientists providing usability and design insights. Expert feedback indicates that model positioning in our system is easier than in previous methods using traditional input devices or two-dimensional input interfaces, and that tract selection may be faster to execute using our tool, given training and practice."",
isbn=""978-3-642-17274-8""
}",A Fiducial-Based Tangible User Interface for White Matter Tractography,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A stick-shaped handle,Point,A virtual point controlled by the tip of stick-shaped handle,One-handed,Tracing,Moving the tip of stick-shaped handle in space to control a virtual sphere to intersect with the 3D visualization.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Locating,3D,3D medical volume rendering,"1. The position of the virtual sphere displayed on the screen.
2. The selected ROI of the 3D visualization of medical volume data displayed on the screen.",2D display,Use a slender body to locate a 3D medical volume rendering by tracing.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The stick-shaped handle is in user's hand.
2. The virtual sphere controlled by handle is embedded with the 3D visualization.
3. The 3D visualization is away from the user."
12,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/6651934,"Jackson, Bret and Lau, Tung Yuen and Schroeder, David and Toussaint, Kimani C. and Keefe, Daniel F.","@ARTICLE{6651934,
  author={Jackson, Bret and Lau, Tung Yuen and Schroeder, David and Toussaint, Kimani C. and Keefe, Daniel F.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={A Lightweight Tangible 3D Interface for Interactive Visualization of Thin Fiber Structures}, 
  year={2013},
  volume={19},
  number={12},
  pages={2802-2809},
  keywords={Three dimensional displays;Data visualization;Microscopy;Three dimensional displays;Data visualization;Microscopy;microscopy visualization;Scientific visualization;3D interaction;tangible interaction},
  doi={10.1109/TVCG.2013.121}}",A Lightweight Tangible 3D Interface for Interactive Visualization of Thin Fiber Structures,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A pen-shaped rolled paper (pen-shaped and lightweight handheld prop),Straight edge,The line along pen-shaped rolled paper (pen-shaped and lightweight handheld prop),One-handed,Rotating,Moving a pen-shaped rolled paper (pen-shaped and lightweight handheld prop) in space to change the orientation for filtering the 3D visualization.,above the horizontal surface,Rotation,Physical widget: 3DOF rotation in the space.,Modulating,3D,3D fiber volume rendering,The 3D visualization of filtered fiber volume data displayed in the stereoscopic screen.,Stereoscopic screen,Use a slender body to modulate a 3D fiber volume rendering by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Discrete,"1. The pen-shaped rolled paper (pen-shaped and lightweight handheld prop) is in user's hand.
2. The pen-shaped rolled paper (pen-shaped and lightweight handheld prop) is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
12,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/6651934,"Jackson, Bret and Lau, Tung Yuen and Schroeder, David and Toussaint, Kimani C. and Keefe, Daniel F.","@ARTICLE{6651934,
  author={Jackson, Bret and Lau, Tung Yuen and Schroeder, David and Toussaint, Kimani C. and Keefe, Daniel F.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={A Lightweight Tangible 3D Interface for Interactive Visualization of Thin Fiber Structures}, 
  year={2013},
  volume={19},
  number={12},
  pages={2802-2809},
  keywords={Three dimensional displays;Data visualization;Microscopy;Three dimensional displays;Data visualization;Microscopy;microscopy visualization;Scientific visualization;3D interaction;tangible interaction},
  doi={10.1109/TVCG.2013.121}}",A Lightweight Tangible 3D Interface for Interactive Visualization of Thin Fiber Structures,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A pen-shaped rolled paper (pen-shaped and lightweight handheld prop),Body,A pen-shaped rolled paper (pen-shaped and lightweight handheld prop),Symmetric,Positioning+Rotating,Moving a pen-shaped rolled paper (pen-shaped and lightweight handheld prop) in space using two hands for manipulating the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D fiber volume rendering,The position and rotation of the 3D visualization of fiber volume data displayed in the stereoscopic screen.,Stereoscopic screen,Use a slender body to translate/rotate/scale a 3D fiber volume rendering by two-handed positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Discrete,"1. The pen-shaped rolled paper (pen-shaped and lightweight handheld prop) is in user's hand.
2. The pen-shaped rolled paper (pen-shaped and lightweight handheld prop) is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
13,CHI,3D Interaction,https://dl.acm.org/doi/10.1145/1978942.1979140,"Song, Peng and Goh, Wooi Boon and Fu, Chi-Wing and Meng, Qiang and Heng, Pheng-Ann","@inproceedings{10.1145/1978942.1979140,
author = {Song, Peng and Goh, Wooi Boon and Fu, Chi-Wing and Meng, Qiang and Heng, Pheng-Ann},
title = {WYSIWYF: exploring and annotating volume data with a tangible handheld device},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979140},
doi = {10.1145/1978942.1979140},
abstract = {Visual exploration of volume data often requires the user to manipulate the orientation and position of a slicing plane in order to observe, annotate or measure its internal structures. Such operations, with its many degrees of freedom in 3D space, map poorly into interaction modalities afforded by mouse-keyboard interfaces or flat multi-touch displays alone. We addressed this problem using a what-you-see-is-what-you-feel (WYSIWYF) approach, which integrates the natural user interface of a multi-touch wall display with the untethered physical dexterity provided by a handheld device with multi-touch and 3D-tilt sensing capabilities. A slicing plane can be directly and intuitively manipulated at any desired position within the displayed volume data using a commonly available mobile device such as the iPod touch. 2D image slices can be transferred wirelessly to this small touch screen device, where a novel fast fat finger annotation technique (F3AT) is proposed to perform accurate and speedy contour drawings. Our user studies support the efficacy of our proposed visual exploration and annotation interaction designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1333¨C1342},
numpages = {10},
keywords = {accelerometer, data exploration, handheld devices, multi-touch, user interaction, visual annotation, volume data},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}",WYSIWYF: exploring and annotating volume data with a tangible handheld device,,Small,Double,A virtual widget+A tangible widget,Fully mapped,Rigid,No use,Plate (with Planar surface),A mobile device (with a virtual cutting plane),Planar surface,A virtual cutting plane,One-handed,Positioning+Rotating,Moving a mobile device in space to control a virtual cutting plane for slicing the 3D visualization.,in the room space,"Position,Rotation","Virtual widget: 3DOF translation and 3DOF rotation in the space.
Physical widget: 3DOF translation and 3DOF rotation in the space.",Clipping,3D,3D medical volume rendering,"The image, position and rotation of the slice from the 3D visualization of medical volume data displayed on the mobile device/wall screen.",2D display,Use a planar surface controlled by a plate to clip a 3D medical volume rendering by positioning+rotating.,Reachable,"Virtual: Not impacted within the accessible distance.
Physical: Interaction is possible only if manipulable entity is grabbed by user.",Reachable,Not impacted within the accessible distance.,Crossed,"1. The handheld mobile device is in user's hand.
2. The virtual cutting plane controlled by the handheld mobile device is crossed over the 3D visualization.
3. The 3D visualization is away from the user."
14,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3544549.3585797,"Satriadi, Kadek Ananta and Ens, Barrett and Goodwin, Sarah and Dwyer, Tim","@inproceedings{10.1145/3544549.3585797,
author = {Satriadi, Kadek Ananta and Ens, Barrett and Goodwin, Sarah and Dwyer, Tim},
title = {Active Proxy Dashboard: Binding Physical Referents and Abstract Data Representations in Situated Visualization through Tangible Interaction},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585797},
doi = {10.1145/3544549.3585797},
abstract = {Myriad systems have been proposed in recent years involving situated visualization with tangible scale models as proxies for physical referents. Most of these focus on static placements of scale models that mimic their real-world arrangement. While such static placement is useful to show the spatial context of referents, it does not take full advantage of the potential interaction affordances of the proxies. Our approach, Active Proxy, binds the data representation and referent through physical manipulations of scale models. We introduce a conceptual design space defining four quadrants as combinations of two dimensions: spatial to abstract representation; and passive to active proxy. Our focus is the novel quadrant defined by active proxies and abstract representations. Designing active proxy techniques is non-trivial as users are accustomed to common interaction modalities. This paper presents an initial exploration toward a better understanding of the active proxy concept, and designs of active proxy systems.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {23},
numpages = {7},
keywords = {active proxy, data exploration, proxsituated visualization, situated visualization, tangible interaction},
location = {Hamburg, Germany},
series = {CHI EA '23}
}",Active Proxy Dashboard: Binding Physical Referents and Abstract Data Representations in Situated Visualization through Tangible Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of buildings,Body,The point represented by low-fidelity model of buildings,One-handed,Positioning,Moving a low-fidelity model of buildings in space to get closer to the 2D chart for selecting the 2D chart.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Looking up,2D,2D bar chart+ 2D line chart,The information of the 2D visualization of buildings energy usage data displayed on the screen.,2D display,Use an other to lookup a 2D bar chart+2D line chart by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Discrete,"1. The low-fidelity model of buildings is on the desktop or in user's hand.
2. The low-fidelity model of buildings is discrete from the 2D visualization.
3. The 2D visualization is on the desktop."
14,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3544549.3585797,"Satriadi, Kadek Ananta and Ens, Barrett and Goodwin, Sarah and Dwyer, Tim","@inproceedings{10.1145/3544549.3585797,
author = {Satriadi, Kadek Ananta and Ens, Barrett and Goodwin, Sarah and Dwyer, Tim},
title = {Active Proxy Dashboard: Binding Physical Referents and Abstract Data Representations in Situated Visualization through Tangible Interaction},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585797},
doi = {10.1145/3544549.3585797},
abstract = {Myriad systems have been proposed in recent years involving situated visualization with tangible scale models as proxies for physical referents. Most of these focus on static placements of scale models that mimic their real-world arrangement. While such static placement is useful to show the spatial context of referents, it does not take full advantage of the potential interaction affordances of the proxies. Our approach, Active Proxy, binds the data representation and referent through physical manipulations of scale models. We introduce a conceptual design space defining four quadrants as combinations of two dimensions: spatial to abstract representation; and passive to active proxy. Our focus is the novel quadrant defined by active proxies and abstract representations. Designing active proxy techniques is non-trivial as users are accustomed to common interaction modalities. This paper presents an initial exploration toward a better understanding of the active proxy concept, and designs of active proxy systems.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {23},
numpages = {7},
keywords = {active proxy, data exploration, proxsituated visualization, situated visualization, tangible interaction},
location = {Hamburg, Germany},
series = {CHI EA '23}
}",Active Proxy Dashboard: Binding Physical Referents and Abstract Data Representations in Situated Visualization through Tangible Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of buildings,Body,The point represented by low-fidelity model of buildings,One-handed,Positioning,Moving a low-fidelity model of buildings in space to get closer to the 2D chart for focusing on the 2D chart.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Navigating,2D,2D bar chart+ 2D line chart,The scale of the 2D visualization of buildings energy usage data displayed on the screen.,2D display,Use an other to navigate a 2D bar chart+2D line chart by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Discrete,"1. The low-fidelity model of buildings is on the desktop or in user's hand.
2. The low-fidelity model of buildings is discrete from the 2D visualization.
3. The 2D visualization is on the desktop."
14,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3544549.3585797,"Satriadi, Kadek Ananta and Ens, Barrett and Goodwin, Sarah and Dwyer, Tim","@inproceedings{10.1145/3544549.3585797,
author = {Satriadi, Kadek Ananta and Ens, Barrett and Goodwin, Sarah and Dwyer, Tim},
title = {Active Proxy Dashboard: Binding Physical Referents and Abstract Data Representations in Situated Visualization through Tangible Interaction},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585797},
doi = {10.1145/3544549.3585797},
abstract = {Myriad systems have been proposed in recent years involving situated visualization with tangible scale models as proxies for physical referents. Most of these focus on static placements of scale models that mimic their real-world arrangement. While such static placement is useful to show the spatial context of referents, it does not take full advantage of the potential interaction affordances of the proxies. Our approach, Active Proxy, binds the data representation and referent through physical manipulations of scale models. We introduce a conceptual design space defining four quadrants as combinations of two dimensions: spatial to abstract representation; and passive to active proxy. Our focus is the novel quadrant defined by active proxies and abstract representations. Designing active proxy techniques is non-trivial as users are accustomed to common interaction modalities. This paper presents an initial exploration toward a better understanding of the active proxy concept, and designs of active proxy systems.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {23},
numpages = {7},
keywords = {active proxy, data exploration, proxsituated visualization, situated visualization, tangible interaction},
location = {Hamburg, Germany},
series = {CHI EA '23}
}",Active Proxy Dashboard: Binding Physical Referents and Abstract Data Representations in Situated Visualization through Tangible Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of buildings,Body,A low-fidelity model of buildings,One-handed,Positioning,Picking up a low-fidelity model of buildings or placing low-fidelity models on small pedestals on desktop for filtering and comparing the 2D chart.,on the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Modulating,2D,2D bar chart+ 2D line chart,The information of the 2D visualization of buildings energy usage data displayed on the screen.,2D display,Use an other to modulate a 2D bar chart+2D line chart by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Discrete,"1. The low-fidelity model of buildings is on the desktop or in user's hand.
2. The low-fidelity model of buildings is discrete from the 2D visualization.
3. The 2D visualization is on the desktop."
15,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3313831.3376490,"Neate, Timothy and Roper, Abi and Wilson, Stephanie and Marshall, Jane and Cruice, Madeline","@inproceedings{10.1145/3313831.3376490,
author = {Neate, Timothy and Roper, Abi and Wilson, Stephanie and Marshall, Jane and Cruice, Madeline},
title = {CreaTable Content and Tangible Interaction in Aphasia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376490},
doi = {10.1145/3313831.3376490},
abstract = {Multimedia digital content (combining pictures, text and music) is ubiquitous. The process of creating such content using existing tools typically requires complex, language-laden interactions which pose a challenge for users with aphasia (a language impairment following brain injury). Tangible interactions offer a potential means to address this challenge, however, there has been little work exploring their potential for this purpose. In this paper, we present CreaTable a platform that enables us to explore tangible interaction as a means of supporting digital content creation for people with aphasia. We report details of the co-design of CreaTable and findings from a digital creativity workshop. Workshop findings indicated that CreaTable enabled people with aphasia to create something they would not otherwise have been able to. We report how users' aphasia profiles affected their experience, describe tensions in collaborative content creation and provide insight into more accessible content creation using tangibles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C14},
numpages = {14},
keywords = {accessibility, aphasia, co-design, content creation, creativity, creativity support, multimedia, tangibles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}",CreaTable Content and Tangible Interaction in Aphasia,,Small,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",No use,Plate,A sheet of printed paper,Planar surface,A sheet of printed paper,One-handed,Positioning,Locating a sheet of printed paper on desktop for adding content at a position on the screen.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D graphic,The position of the added content displayed on the screen.,2D display,Use a plate to modulate a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Discrete,"1. The sheet of printed paper is on the desktop.
2. The sheet of printed paper is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
15,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3313831.3376490,"Neate, Timothy and Roper, Abi and Wilson, Stephanie and Marshall, Jane and Cruice, Madeline","@inproceedings{10.1145/3313831.3376490,
author = {Neate, Timothy and Roper, Abi and Wilson, Stephanie and Marshall, Jane and Cruice, Madeline},
title = {CreaTable Content and Tangible Interaction in Aphasia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376490},
doi = {10.1145/3313831.3376490},
abstract = {Multimedia digital content (combining pictures, text and music) is ubiquitous. The process of creating such content using existing tools typically requires complex, language-laden interactions which pose a challenge for users with aphasia (a language impairment following brain injury). Tangible interactions offer a potential means to address this challenge, however, there has been little work exploring their potential for this purpose. In this paper, we present CreaTable a platform that enables us to explore tangible interaction as a means of supporting digital content creation for people with aphasia. We report details of the co-design of CreaTable and findings from a digital creativity workshop. Workshop findings indicated that CreaTable enabled people with aphasia to create something they would not otherwise have been able to. We report how users' aphasia profiles affected their experience, describe tensions in collaborative content creation and provide insight into more accessible content creation using tangibles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C14},
numpages = {14},
keywords = {accessibility, aphasia, co-design, content creation, creativity, creativity support, multimedia, tangibles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}",CreaTable Content and Tangible Interaction in Aphasia,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A 5-sided object,Planar surface,The bottom surface of 5-sided object,One-handed,Rotating,Rotating a 5-sided object orientation on desktop for selecting the word or image in list for adding.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Looking up,2D,2D graphic,The word or image used to add content displayed on the screen.,2D display,Use a plate to lookup a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Discrete,"1. The 5-sided object is on the desktop.
2. The 5-sided object is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
16,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3544548.3581449,"Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo","@inproceedings{10.1145/3544548.3581449,
author = {Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo},
title = {Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581449},
doi = {10.1145/3544548.3581449},
abstract = {This paper introduces Teachable Reality, an augmented reality (AR) prototyping tool for creating interactive tangible AR applications with arbitrary everyday objects. Teachable Reality leverages vision-based interactive machine teaching (e.g., Teachable Machine), which captures real-world interactions for AR prototyping. It identifies the user-defined tangible and gestural interactions using an on-demand computer vision model. Based on this, the user can easily create functional AR prototypes without programming, enabled by a trigger-action authoring interface. Therefore, our approach allows the flexibility, customizability, and generalizability of tangible AR applications that can address the limitation of current marker-based approaches. We explore the design space and demonstrate various AR prototypes, which include tangible and deformable interfaces, context-aware assistants, and body-driven AR applications. The results of our user study and expert interviews confirm that our approach can lower the barrier to creating functional AR prototypes while also allowing flexible and general-purpose prototyping experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {15},
keywords = {Augmented Reality, Everyday Objects, Human-Centered Machine Learning;, Interactive Machine Teaching, Mixed Reality, Prototyping Tools, Tangible Interactions},
location = {Hamburg, Germany},
series = {CHI '23}
}",Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A card,Planar surface,The bottom surface of card,One-handed,Rotating,Rotating a card orientation in space for changing the displayed information.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation at the plane of the card surface in the space.,Replacing,2D,2D text,The information of the 2D visualization of the card displayed in the augmented reality (screen).,Augmented reality,Use a plate to replace a 2D text by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The card is in user's hand.
2. The 2D graphic is aligned with the card.
3. The 2D graphic is above the desktop."
16,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3544548.3581449,"Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo","@inproceedings{10.1145/3544548.3581449,
author = {Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo},
title = {Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581449},
doi = {10.1145/3544548.3581449},
abstract = {This paper introduces Teachable Reality, an augmented reality (AR) prototyping tool for creating interactive tangible AR applications with arbitrary everyday objects. Teachable Reality leverages vision-based interactive machine teaching (e.g., Teachable Machine), which captures real-world interactions for AR prototyping. It identifies the user-defined tangible and gestural interactions using an on-demand computer vision model. Based on this, the user can easily create functional AR prototypes without programming, enabled by a trigger-action authoring interface. Therefore, our approach allows the flexibility, customizability, and generalizability of tangible AR applications that can address the limitation of current marker-based approaches. We explore the design space and demonstrate various AR prototypes, which include tangible and deformable interfaces, context-aware assistants, and body-driven AR applications. The results of our user study and expert interviews confirm that our approach can lower the barrier to creating functional AR prototypes while also allowing flexible and general-purpose prototyping experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {15},
keywords = {Augmented Reality, Everyday Objects, Human-Centered Machine Learning;, Interactive Machine Teaching, Mixed Reality, Prototyping Tools, Tangible Interactions},
location = {Hamburg, Germany},
series = {CHI '23}
}",Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A lid of a cup,Body,A lid of a cup,One-handed,Positioning,Opening or closing the cup lid on desktop for adjusting the state of playing audio.,on the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,Other,Audio,The status of the audio played by the system.,Augmented reality,Use a spheroid to adjust an audio by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The lid is in user's hand.
2. The lid is discrete from the audio player.
3. The audio player is on the desktop."
16,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3544548.3581449,"Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo","@inproceedings{10.1145/3544548.3581449,
author = {Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo},
title = {Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581449},
doi = {10.1145/3544548.3581449},
abstract = {This paper introduces Teachable Reality, an augmented reality (AR) prototyping tool for creating interactive tangible AR applications with arbitrary everyday objects. Teachable Reality leverages vision-based interactive machine teaching (e.g., Teachable Machine), which captures real-world interactions for AR prototyping. It identifies the user-defined tangible and gestural interactions using an on-demand computer vision model. Based on this, the user can easily create functional AR prototypes without programming, enabled by a trigger-action authoring interface. Therefore, our approach allows the flexibility, customizability, and generalizability of tangible AR applications that can address the limitation of current marker-based approaches. We explore the design space and demonstrate various AR prototypes, which include tangible and deformable interfaces, context-aware assistants, and body-driven AR applications. The results of our user study and expert interviews confirm that our approach can lower the barrier to creating functional AR prototypes while also allowing flexible and general-purpose prototyping experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {15},
keywords = {Augmented Reality, Everyday Objects, Human-Centered Machine Learning;, Interactive Machine Teaching, Mixed Reality, Prototyping Tools, Tangible Interactions},
location = {Hamburg, Germany},
series = {CHI '23}
}",Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching,,Small,Single,A tangible widget,N/A,Rigid,No use,Constrained body,A stick with a slider,Straight edge,The slider's motion path along the stick,Symmetric,Positioning,Sliding the slider in space for manipulating the 3D graphic in the plane along a direction.,above the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Translating/Rotating/Scaling,3D,3D graphic,The position of the 3D graphic of model displayed in the augmented reality (screen).,Augmented reality,Use a constrained body to translate/rotate/scale a 3D graphic by two-handed positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The stick with a slider is in user's hand.
2. The stick with a slider is discrete from the 3D graphic.
2. The 3D graphic is on the desktop."
16,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3544548.3581449,"Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo","@inproceedings{10.1145/3544548.3581449,
author = {Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo},
title = {Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581449},
doi = {10.1145/3544548.3581449},
abstract = {This paper introduces Teachable Reality, an augmented reality (AR) prototyping tool for creating interactive tangible AR applications with arbitrary everyday objects. Teachable Reality leverages vision-based interactive machine teaching (e.g., Teachable Machine), which captures real-world interactions for AR prototyping. It identifies the user-defined tangible and gestural interactions using an on-demand computer vision model. Based on this, the user can easily create functional AR prototypes without programming, enabled by a trigger-action authoring interface. Therefore, our approach allows the flexibility, customizability, and generalizability of tangible AR applications that can address the limitation of current marker-based approaches. We explore the design space and demonstrate various AR prototypes, which include tangible and deformable interfaces, context-aware assistants, and body-driven AR applications. The results of our user study and expert interviews confirm that our approach can lower the barrier to creating functional AR prototypes while also allowing flexible and general-purpose prototyping experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {15},
keywords = {Augmented Reality, Everyday Objects, Human-Centered Machine Learning;, Interactive Machine Teaching, Mixed Reality, Prototyping Tools, Tangible Interactions},
location = {Hamburg, Germany},
series = {CHI '23}
}",Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A mobile device,Body,A mobile device,One-handed,Rotating,Flipping a mobile device on desktop for adjusting the state of silent mode.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the space.,Adjusting,Other,System,The mode of mobile device notification.,Augmented reality,Use a plate to adjust a system by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Other,N/A.,Other,N/A.
16,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3544548.3581449,"Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo","@inproceedings{10.1145/3544548.3581449,
author = {Monteiro, Kyzyl and Vatsal, Ritik and Chulpongsatorn, Neil and Parnami, Aman and Suzuki, Ryo},
title = {Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581449},
doi = {10.1145/3544548.3581449},
abstract = {This paper introduces Teachable Reality, an augmented reality (AR) prototyping tool for creating interactive tangible AR applications with arbitrary everyday objects. Teachable Reality leverages vision-based interactive machine teaching (e.g., Teachable Machine), which captures real-world interactions for AR prototyping. It identifies the user-defined tangible and gestural interactions using an on-demand computer vision model. Based on this, the user can easily create functional AR prototypes without programming, enabled by a trigger-action authoring interface. Therefore, our approach allows the flexibility, customizability, and generalizability of tangible AR applications that can address the limitation of current marker-based approaches. We explore the design space and demonstrate various AR prototypes, which include tangible and deformable interfaces, context-aware assistants, and body-driven AR applications. The results of our user study and expert interviews confirm that our approach can lower the barrier to creating functional AR prototypes while also allowing flexible and general-purpose prototyping experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {459},
numpages = {15},
keywords = {Augmented Reality, Everyday Objects, Human-Centered Machine Learning;, Interactive Machine Teaching, Mixed Reality, Prototyping Tools, Tangible Interactions},
location = {Hamburg, Germany},
series = {CHI '23}
}",Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A disk,Body,A disk,Symmetric,Rotating,Rotating the disk orientation in space for changing the forward direction of RC car as a controller.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation at the plane of the card underside in the space.,Adjusting,Other,Artifact,The forward direction of RC car.,Augmented reality,Use a plate to adjust an artifact by two-handed rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The disk is in user's hand.
2. The disk is discrete from the car.
3. The car is on the desktop."
17,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3491102.3517567,"Mahieux, Pierre and Biannic, Romain and Kubicki, S\'{e}bastien and Querrec, Ronan","@inproceedings{10.1145/3491102.3517567,
author = {Mahieux, Pierre and Biannic, Romain and Kubicki, S\'{e}bastien and Querrec, Ronan},
title = {SABLIER?: a Tangible Interactor to Navigate through Space and Time},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517567},
doi = {10.1145/3491102.3517567},
abstract = {Historians use spatio-temporal navigation for their models and studies of historical evolutions and events. Their findings can then be exhibited in cultural mediation centers or museums. The latter, both to facilitate the transmission of knowledge and to make their exhibitions more attractive, are now exploiting new technologies. Indeed, digital systems allow, among other things, visitors to navigate spatially and temporally in virtual reconstructions of historical environments. We propose to combine these virtual representations with a tangible interface to provide visitors with an immersive experience and engaging interactions. To do so, we have set up a co-design process involving cultural mediation actors (museum directors, historians, etc.). The result is SABLIER, a tangible interactor to navigate through space and time based on the interaction metaphors and natural affordance of an hourglass. Finally, we have conducted an evaluation of the acceptability of our interactor, whose results are positive.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {503},
numpages = {12},
keywords = {Virtual Reality, Tangible User Interface, Cultural Mediation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}",SABLIER : a Tangible Interactor to Navigate through Space and Time,,Medium,Single,A tangible widget,N/A,Rigid,No use,Other,A hourglass,Body,A hourglass,One-handed,Rotating,Tilting the hourglass in space for adjusting the speed of time flow.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation in the space.,Adjusting,3D,3D map,The speed of time flow of the 3D map of cultural heritage context displayed in the virtual reality (CAVE).,Virtual reality,Use an other to adjust a 3D map by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Discrete,"1. The hourglass is in user's hand.
2. The hourglass is discrete from the 3D map.
3. The 3D map is in the room."
17,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3491102.3517567,"Mahieux, Pierre and Biannic, Romain and Kubicki, S\'{e}bastien and Querrec, Ronan","@inproceedings{10.1145/3491102.3517567,
author = {Mahieux, Pierre and Biannic, Romain and Kubicki, S\'{e}bastien and Querrec, Ronan},
title = {SABLIER?: a Tangible Interactor to Navigate through Space and Time},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517567},
doi = {10.1145/3491102.3517567},
abstract = {Historians use spatio-temporal navigation for their models and studies of historical evolutions and events. Their findings can then be exhibited in cultural mediation centers or museums. The latter, both to facilitate the transmission of knowledge and to make their exhibitions more attractive, are now exploiting new technologies. Indeed, digital systems allow, among other things, visitors to navigate spatially and temporally in virtual reconstructions of historical environments. We propose to combine these virtual representations with a tangible interface to provide visitors with an immersive experience and engaging interactions. To do so, we have set up a co-design process involving cultural mediation actors (museum directors, historians, etc.). The result is SABLIER, a tangible interactor to navigate through space and time based on the interaction metaphors and natural affordance of an hourglass. Finally, we have conducted an evaluation of the acceptability of our interactor, whose results are positive.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {503},
numpages = {12},
keywords = {Virtual Reality, Tangible User Interface, Cultural Mediation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}",SABLIER : a Tangible Interactor to Navigate through Space and Time,,Medium,Single,A tangible widget,N/A,Rigid,No use,Other,A hourglass,Planar surface,The bottom surface of hourglass,One-handed,Positioning,Moving the hourglass on desktop for navigating spatially within a fixed landscape.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Navigating,3D,3D map,The viewpoint position of the 3D map of cultural heritage context displayed in the virtual reality (CAVE).,Virtual reality,Use an other to navigate a 3D map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Discrete,"1. The hourglass is in user's hand.
2. The hourglass is discrete from the 3D map.
3. The 3D map is in the room."
17,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3491102.3517567,"Mahieux, Pierre and Biannic, Romain and Kubicki, S\'{e}bastien and Querrec, Ronan","@inproceedings{10.1145/3491102.3517567,
author = {Mahieux, Pierre and Biannic, Romain and Kubicki, S\'{e}bastien and Querrec, Ronan},
title = {SABLIER?: a Tangible Interactor to Navigate through Space and Time},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517567},
doi = {10.1145/3491102.3517567},
abstract = {Historians use spatio-temporal navigation for their models and studies of historical evolutions and events. Their findings can then be exhibited in cultural mediation centers or museums. The latter, both to facilitate the transmission of knowledge and to make their exhibitions more attractive, are now exploiting new technologies. Indeed, digital systems allow, among other things, visitors to navigate spatially and temporally in virtual reconstructions of historical environments. We propose to combine these virtual representations with a tangible interface to provide visitors with an immersive experience and engaging interactions. To do so, we have set up a co-design process involving cultural mediation actors (museum directors, historians, etc.). The result is SABLIER, a tangible interactor to navigate through space and time based on the interaction metaphors and natural affordance of an hourglass. Finally, we have conducted an evaluation of the acceptability of our interactor, whose results are positive.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {503},
numpages = {12},
keywords = {Virtual Reality, Tangible User Interface, Cultural Mediation},
location = {New Orleans, LA, USA},
series = {CHI '22}
}",SABLIER : a Tangible Interactor to Navigate through Space and Time,,Medium,Single,A tangible widget,N/A,Rigid,No use,Other,A hourglass,Planar surface,The bottom surface of hourglass,One-handed,Positioning,Moving the hourglass on desktop to place on a option for selecting the procedure or action or the state of execution.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Looking up,3D,3D map,The procedure or action or the state of execution of the 3D map of cultural heritage context displayed in the virtual reality (CAVE).,Virtual reality,Use an other to lookup a 3D map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Discrete,"1. The hourglass is in user's hand.
2. The hourglass is discrete from the 3D map.
3. The 3D map is in the room."
18,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1978942.1979386,"Yu, Neng-Hao and Chan, Li-Wei and Lau, Seng Yong and Tsai, Sung-Sheng and Hsiao, I-Chun and Tsai, Dian-Je and Hsiao, Fang-I and Cheng, Lung-Pan and Chen, Mike and Huang, Polly and Hung, Yi-Ping","@inproceedings{10.1145/1978942.1979386,
author = {Yu, Neng-Hao and Chan, Li-Wei and Lau, Seng Yong and Tsai, Sung-Sheng and Hsiao, I-Chun and Tsai, Dian-Je and Hsiao, Fang-I and Cheng, Lung-Pan and Chen, Mike and Huang, Polly and Hung, Yi-Ping},
title = {TUIC: enabling tangible interaction on capacitive multi-touch displays},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979386},
doi = {10.1145/1978942.1979386},
abstract = {We present TUIC, a technology that enables tangible interaction on capacitive multi-touch devices, such as iPad, iPhone, and 3M's multi-touch displays, without requiring any hardware modifications. TUIC simulates finger touches on capacitive displays using passive materials and active modulation circuits embedded inside tangible objects, and can be used with multi-touch gestures simultaneously. TUIC consists of three approaches to sense and track objects: spatial, frequency, and hybrid (spatial plus frequency). The spatial approach, also known as 2D markers, uses geometric, multi-point touch patterns to encode object IDs. Spatial tags are straightforward to construct and are easily tracked when moved, but require sufficient spacing between the multiple touch points. The frequency approach uses modulation circuits to generate high-frequency touches to encode object IDs in the time domain. It requires fewer touch points and allows smaller tags to be built. The hybrid approach combines both spatial and frequency tags to construct small tags that can be reliably tracked when moved and rotated. We show three applications demonstrating the above approaches on iPads and 3M's multi-touch displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2995¨C3004},
numpages = {10},
keywords = {2d marker, frequency tag, interactive surface, multi-touch, physical interaction, tags, tangible, tui},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}",TUIC: enabling tangible interaction on capacitive multi-touch displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A tile,Planar surface,The bottom surface of tile,One-handed,Positioning,Locating the tile on desktop for displaying a painting graphic at a position in the plane.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D graphic,The image of the 2D graphic displayed on the desktop screen.,2D display,Use a plate to modulate a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The tile is on the desktop.
2. The tile is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
18,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1978942.1979386,"Yu, Neng-Hao and Chan, Li-Wei and Lau, Seng Yong and Tsai, Sung-Sheng and Hsiao, I-Chun and Tsai, Dian-Je and Hsiao, Fang-I and Cheng, Lung-Pan and Chen, Mike and Huang, Polly and Hung, Yi-Ping","@inproceedings{10.1145/1978942.1979386,
author = {Yu, Neng-Hao and Chan, Li-Wei and Lau, Seng Yong and Tsai, Sung-Sheng and Hsiao, I-Chun and Tsai, Dian-Je and Hsiao, Fang-I and Cheng, Lung-Pan and Chen, Mike and Huang, Polly and Hung, Yi-Ping},
title = {TUIC: enabling tangible interaction on capacitive multi-touch displays},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979386},
doi = {10.1145/1978942.1979386},
abstract = {We present TUIC, a technology that enables tangible interaction on capacitive multi-touch devices, such as iPad, iPhone, and 3M's multi-touch displays, without requiring any hardware modifications. TUIC simulates finger touches on capacitive displays using passive materials and active modulation circuits embedded inside tangible objects, and can be used with multi-touch gestures simultaneously. TUIC consists of three approaches to sense and track objects: spatial, frequency, and hybrid (spatial plus frequency). The spatial approach, also known as 2D markers, uses geometric, multi-point touch patterns to encode object IDs. Spatial tags are straightforward to construct and are easily tracked when moved, but require sufficient spacing between the multiple touch points. The frequency approach uses modulation circuits to generate high-frequency touches to encode object IDs in the time domain. It requires fewer touch points and allows smaller tags to be built. The hybrid approach combines both spatial and frequency tags to construct small tags that can be reliably tracked when moved and rotated. We show three applications demonstrating the above approaches on iPads and 3M's multi-touch displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2995¨C3004},
numpages = {10},
keywords = {2d marker, frequency tag, interactive surface, multi-touch, physical interaction, tags, tangible, tui},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}",TUIC: enabling tangible interaction on capacitive multi-touch displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A tile,Planar surface,The bottom surface of tile,One-handed,Rotating,Rotating the tile orientation on desktop for adjusting the period of chronicle.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D graphic,The image of the 2D graphic displayed on the desktop screen.,2D display,Use a plate to adjust a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The tile is on the desktop.
2. The tile is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
19,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2470654.2466185,"Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu","@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391¨C1400},
numpages = {10},
keywords = {tangible interactions, portable, occlusion-free, near-surface tracking, magnetism},
location = {Paris, France},
series = {CHI '13}
}",GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A small cylinder,Planar surface,The bottom surface of small cylinder,One-handed,Rotating,"Rotating the small cylinder orientation on desktop for adjusting the time.
 ",on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D graphic,The information of the 2D graphic of time displayed on the desktop screen.,2D display,Use a plate to adjust a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The small cylinder is on the desktop.
2. The small cylinder is aligned with the 2D graphic.
2. The 2D graphic is on the desktop."
19,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2470654.2466185,"Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu","@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391¨C1400},
numpages = {10},
keywords = {tangible interactions, portable, occlusion-free, near-surface tracking, magnetism},
location = {Paris, France},
series = {CHI '13}
}",GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A small cylinder,Body,The point represented by small cylinder,One-handed,Positioning,Moving the small cylinder at different height in space for selecting the currently selected time indicator.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Looking up,2D,2D graphic,The selected indicator of the 2D graphic of time displayed on the desktop screen.,2D display,Use a plate to lookup a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Discrete,"1. The small cylinder is in user's hand.
2. The small cylinder is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
19,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2470654.2466185,"Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu","@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391¨C1400},
numpages = {10},
keywords = {tangible interactions, portable, occlusion-free, near-surface tracking, magnetism},
location = {Paris, France},
series = {CHI '13}
}",GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions,,Small,Single,A tangible widget,N/A,Rigid,No use,Toroid,A handheld ring,Planar surface,The bottom surface of handheld ring,One-handed,Positioning,Locating the handheld ring on desktop to input a position for displaying the information of interest and context.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D map,The information of interest and context displayed on the desktop screen.,2D display,Use a toroid to modulate a 2D map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Discrete,"1. The handheld ring is above the desktop in user's hand.
2. The handheld ring is discrete from the 2D map.
3. The 2D map is on the desktop."
19,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2470654.2466185,"Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu","@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391¨C1400},
numpages = {10},
keywords = {tangible interactions, portable, occlusion-free, near-surface tracking, magnetism},
location = {Paris, France},
series = {CHI '13}
}",GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions,,Small,Single,A tangible widget,N/A,Rigid,No use,Toroid,A handheld ring,Body,A handheld ring,One-handed,Positioning,Moving the handheld ring horizontally in space to translate the 2D map for navigating.,above the horizontal surface,Position,Physical widget: 2DOF translation in the space horizontally.,Navigating,2D,2D map,The viewpoint position and scale of the 2D map displayed on the desktop screen.,2D display,Use a toroid to navigate a 2D map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The handheld ring is above the desktop in user's hand.
2. The handheld ring is discrete from the 2D map.
3. The 2D map is on the desktop."
19,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2470654.2466185,"Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu","@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391¨C1400},
numpages = {10},
keywords = {tangible interactions, portable, occlusion-free, near-surface tracking, magnetism},
location = {Paris, France},
series = {CHI '13}
}",GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions,,Small,Single,A tangible widget,N/A,Rigid,No use,Toroid,A handheld ring,Body,A handheld ring,One-handed,Rotating,Flipping the handheld ring in space for adjusting the mode of scaling.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation in the space.,Adjusting,2D,2D map,The mode of scaling the 2D map displayed on the desktop screen.,2D display,Use a toroid to adjust a 2D map by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The handheld ring is above the desktop in user's hand.
2. The handheld ring is discrete from the 2D map.
3. The 2D map is on the desktop."
20,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2470654.2466185,"Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu","@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391¨C1400},
numpages = {10},
keywords = {tangible interactions, portable, occlusion-free, near-surface tracking, magnetism},
location = {Paris, France},
series = {CHI '13}
}",GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions,,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of 2D graphic,Body,A low-fidelity model of 2D graphic,One-handed,Rotating,Tilting the low-fidelity model in space to translate the 2D graphic for manipulating.,above the horizontal surface,Rotation,Physical widget: 3DOF rotation in the space.,Translating/Rotating/Scaling,2D,2D graphic,The position of the 2D graphic displayed on the screen on the desktop.,2D display,Use an other to translate/rotate/scale a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The low-fidelity model is above the desktop in user's hand.
2. The low-fidelity model is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
20,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2470654.2466185,"Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu","@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391¨C1400},
numpages = {10},
keywords = {tangible interactions, portable, occlusion-free, near-surface tracking, magnetism},
location = {Paris, France},
series = {CHI '13}
}",GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions,,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of 2D graphic,Planar surface,The bottom surface of low-fidelity model of 2D graphic,One-handed,Positioning,Locating the low-fidelity model of 2D graphic on desktop for pickup at a position in the plane.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Browsing,2D,2D graphic,The image of the 2D graphic displayed on the desktop screen.,2D display,Use an other to browse a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The low-fidelity model is on the desktop.
2. The low-fidelity model is aligned with the 2D graphic.
3. The 2D graphic is on the desktop."
21,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3173574.3173647,"Homaeian, Leila and Goyal, Nippun and Wallace, James R. and Scott, Stacey D.","@inproceedings{10.1145/3173574.3173647,
author = {Homaeian, Leila and Goyal, Nippun and Wallace, James R. and Scott, Stacey D.},
title = {Group vs Individual: Impact of TOUCH and TILT Cross-Device Interactions on Mixed-Focus Collaboration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173647},
doi = {10.1145/3173574.3173647},
abstract = {Cross-device environments (XDEs) have been developed to support a multitude of collaborative activities. Yet, little is known about how different cross-device interaction techniques impact group collaboration, including how their impact on independent and joint work that often occurs during group work. In this work, we explore the impact of two XDE data browsing techniques: TOUCH and TILT. Through a mixed-methods study of a collaborative sensemaking task, we show that TOUCH and TILT have distinct impacts on how groups accomplish, and shift between, independent and joint work. Finally, we reflect on these findings and how they can more generally inform the design of XDEs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C13},
numpages = {13},
keywords = {touch, tilt, mixed-focus collaboration, cross-device},
location = {Montreal QC, Canada},
series = {CHI '18}
}",Group vs Individual: Impact of TOUCH and TILT Cross-Device Interactions on Mixed-Focus Collaboration,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A handheld tablet,Body,A handheld tablet,Symmetric,Rotating,Tilting the handheld tablet in space to translate the ROI for manipulating.,above the horizontal surface,Rotation,Physical widget: 3DOF rotation in the space.,Translating/Rotating/Scaling,2D,2D map,The position of ROI of the 2D map displayed on the desktop screen.,2D display,Use a plate to translate/rotate/scale a 2D map by two-handed rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Discrete,"1. The handheld tablet is in user's hand.
2. The handheld tablet is discrete from the 2D map.
3. The 2D map is on the desktop."
22,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1753326.1753671,"Boring, Sebastian and Baur, Dominikus and Butz, Andreas and Gustafson, Sean and Baudisch, Patrick","@inproceedings{10.1145/1753326.1753671,
author = {Boring, Sebastian and Baur, Dominikus and Butz, Andreas and Gustafson, Sean and Baudisch, Patrick},
title = {Touch projector: mobile interaction through video},
year = {2010},
isbn = {9781605589299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753326.1753671},
doi = {10.1145/1753326.1753671},
abstract = {In 1992, Tani et al. proposed remotely operating machines in a factory by manipulating a live video image on a computer screen. In this paper we revisit this metaphor and investigate its suitability for mobile use. We present Touch Projector, a system that enables users to interact with remote screens through a live video image on their mobile device. The handheld device tracks itself with respect to the surrounding displays. Touch on the video image is ""projected"" onto the target display in view, as if it had occurred there. This literal adaptation of Tani's idea, however, fails because handheld video does not offer enough stability and control to enable precise manipulation. We address this with a series of improvements, including zooming and freezing the video image. In a user study, participants selected targets and dragged targets between displays using the literal and three improved versions. We found that participants achieved highest performance with automatic zooming and temporary image freezing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2287¨C2296},
numpages = {10},
keywords = {multi-touch, multi-display environments, mobile device, interaction techniques, input device, augmented reality},
location = {Atlanta, Georgia, USA},
series = {CHI '10}
}",Touch projector: mobile interaction through video,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A mobile device,Straight edge,A ray casted from the handheld mobile device,One-handed,Casting,Moving the handheld mobile device in space to aim at a display for selecting targeted equipment.,in the room space,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Looking up,Other,Artifact,The targeted equipment of the system.,2D display,Use a plate to lookup an artifact by casting.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Crossed,"1. The handheld mobile device is in user's hand.
2. The casting ray attached to the mobile device is crossed over the equipments.
3. The equipments are in the room."
23,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3025453.3025661,"Saidi, Houssem and Serrano, Marcos and Irani, Pourang and Dubois, Emmanuel","@inproceedings{10.1145/3025453.3025661,
author = {Saidi, Houssem and Serrano, Marcos and Irani, Pourang and Dubois, Emmanuel},
title = {TDome: A Touch-Enabled 6DOF Interactive Device for Multi-Display Environments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025661},
doi = {10.1145/3025453.3025661},
abstract = {The rapid evolution of multi-display environments (MDEs) has created a vacuum in need of novel input devices to optimize interaction in MDEs. In this paper, we propose TDome, a novel touch-enabled 6DOF input and output device to facilitate interactions in MDEs. TDome offers a private display as output, and multiple degrees of freedom as input by combining touch gestures on the display with physical rotation, roll and translation manipulations of the device. TDome allows versatile interactions that address major MDE tasks, which we illustrate through various proof-of-concept implementations: detect surrounding displays, select one display, transfer data across displays, reach distant displays and perform private interactions. We explore TDome's usability and suitability for MDEs through three user studies. First we explore combined physical+touch gestures from which we discard uncomfortable combinations. We experimentally validate their feasibility and come up with a set of 71 combined gestures that are comfortable and ensure a high success rate, i.e. that can be easily performed and efficiently detected. Finally, we collect user feedback to identify natural mappings between gestures and MDE interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5892¨C5904},
numpages = {13},
keywords = {input device, multi-display environments, rolling device, touch input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}",TDome: A Touch-Enabled 6DOF Interactive Device for Multi-Display Environments,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A dome-shaped mouse,Body,A dome-shaped mouse,One-handed,Rotating,Rolling the dome-shaped mouse on desktop to aim at targeted equipment for selecting.,on the horizontal surface,"Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane.,Looking up,Other,Artifact,The targeted equipment of the system.,2D display,Use a spheroid to lookup an artifact by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Discrete,"1. The dome-shaped mouse is on the desktop.
2. The dome-shaped mouse is discrete from the equipments.
3. The equipments are in the room."
23,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3025453.3025661,"Saidi, Houssem and Serrano, Marcos and Irani, Pourang and Dubois, Emmanuel","@inproceedings{10.1145/3025453.3025661,
author = {Saidi, Houssem and Serrano, Marcos and Irani, Pourang and Dubois, Emmanuel},
title = {TDome: A Touch-Enabled 6DOF Interactive Device for Multi-Display Environments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025661},
doi = {10.1145/3025453.3025661},
abstract = {The rapid evolution of multi-display environments (MDEs) has created a vacuum in need of novel input devices to optimize interaction in MDEs. In this paper, we propose TDome, a novel touch-enabled 6DOF input and output device to facilitate interactions in MDEs. TDome offers a private display as output, and multiple degrees of freedom as input by combining touch gestures on the display with physical rotation, roll and translation manipulations of the device. TDome allows versatile interactions that address major MDE tasks, which we illustrate through various proof-of-concept implementations: detect surrounding displays, select one display, transfer data across displays, reach distant displays and perform private interactions. We explore TDome's usability and suitability for MDEs through three user studies. First we explore combined physical+touch gestures from which we discard uncomfortable combinations. We experimentally validate their feasibility and come up with a set of 71 combined gestures that are comfortable and ensure a high success rate, i.e. that can be easily performed and efficiently detected. Finally, we collect user feedback to identify natural mappings between gestures and MDE interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5892¨C5904},
numpages = {13},
keywords = {input device, multi-display environments, rolling device, touch input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}",TDome: A Touch-Enabled 6DOF Interactive Device for Multi-Display Environments,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A dome-shaped mouse,Body,A dome-shaped mouse,One-handed,Rotating,Rotating the dome-shaped mouse in space to rotate the virtual object for manipulating.,above the horizontal surface,Rotation,Physical widget: 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D graphic,The rotation of the 3D graphic of the virtual object displayed on the wall projection.,2D display,Use a spheroid to translate/rotate/scale a 3D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Discrete,"1. The dome-shaped mouse is in user's hand.
2. The dome-shaped mouse is discrete from the 3D graphic.
3. The 3D graphic is away from the user."
24,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3173225.3173252,"de Siqueira, Alexandre G. and Ullmer, Brygg and Delarosa, Mark and Branton, Chris and Konkel, Miriam K.","@inproceedings{10.1145/3173225.3173252,
author = {de Siqueira, Alexandre G. and Ullmer, Brygg and Delarosa, Mark and Branton, Chris and Konkel, Miriam K.},
title = {Hard and Soft Tangibles: Mixing Multi-touch and Tangible Interaction in Scientific Poster Scenarios},
year = {2018},
isbn = {9781450355681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173225.3173252},
doi = {10.1145/3173225.3173252},
abstract = {Research on tangible user interfaces commonly focuses on tangible interfaces acting alone or in comparison with multi-touch or graphical interfaces. In contrast, hybrid approaches can be seen as the norm for established ""mainstream"" interaction paradigms. This paper proposes interfaces that support complementary use of physical and virtual interaction modalities with tangible and multi-touch interactions. We describe prototypes involving capacitively-sensed surfaces combined with laser-cut and 3D-printed dial-like tangibles. We employ them in the context of several computationally-mediated scientific poster scenarios, which we argue to have a number of attractions for such deployments. We present two platforms: one templated, the other highly customizable, supporting both tangible and multi-touch interactions across horizontal and vertical displays. We explore users' interaction modality choice among the options presented, draw lessons and challenges from posters developed by students, and consider future directions.},
booktitle = {Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {476¨C486},
numpages = {11},
keywords = {tangible user interfaces, tangible interaction, poster presentation, passive tokens, multi-touch interaction, hard and soft tangibles., cyberphysical interfaces, computationally-mediated scientific poster},
location = {Stockholm, Sweden},
series = {TEI '18}
}",Hard and Soft Tangibles: Mixing Multi-touch and Tangible Interaction in Scientific Poster Scenarios,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A puck with 60 mm diameter,Planar surface,The bottom surface of knob with 60 mm diameter,One-handed,Rotating,Rotating the puck to rotate the 3D model around an axis on desktop for manipulating.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Translating/Rotating/Scaling,3D,3D graphic,The rotation of the 3D visualization of the 3D model displayed on the desktop screen.,2D display,Use a plate to translate/rotate/scale a 3D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The puck is on the screen near the 2D graphic.
2. The puck is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
24,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3173225.3173252,"de Siqueira, Alexandre G. and Ullmer, Brygg and Delarosa, Mark and Branton, Chris and Konkel, Miriam K.","@inproceedings{10.1145/3173225.3173252,
author = {de Siqueira, Alexandre G. and Ullmer, Brygg and Delarosa, Mark and Branton, Chris and Konkel, Miriam K.},
title = {Hard and Soft Tangibles: Mixing Multi-touch and Tangible Interaction in Scientific Poster Scenarios},
year = {2018},
isbn = {9781450355681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173225.3173252},
doi = {10.1145/3173225.3173252},
abstract = {Research on tangible user interfaces commonly focuses on tangible interfaces acting alone or in comparison with multi-touch or graphical interfaces. In contrast, hybrid approaches can be seen as the norm for established ""mainstream"" interaction paradigms. This paper proposes interfaces that support complementary use of physical and virtual interaction modalities with tangible and multi-touch interactions. We describe prototypes involving capacitively-sensed surfaces combined with laser-cut and 3D-printed dial-like tangibles. We employ them in the context of several computationally-mediated scientific poster scenarios, which we argue to have a number of attractions for such deployments. We present two platforms: one templated, the other highly customizable, supporting both tangible and multi-touch interactions across horizontal and vertical displays. We explore users' interaction modality choice among the options presented, draw lessons and challenges from posters developed by students, and consider future directions.},
booktitle = {Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {476¨C486},
numpages = {11},
keywords = {tangible user interfaces, tangible interaction, poster presentation, passive tokens, multi-touch interaction, hard and soft tangibles., cyberphysical interfaces, computationally-mediated scientific poster},
location = {Stockholm, Sweden},
series = {TEI '18}
}",Hard and Soft Tangibles: Mixing Multi-touch and Tangible Interaction in Scientific Poster Scenarios,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A puck with 60 mm diameter,Planar surface,The bottom surface of knob with 60 mm diameter,One-handed,Positioning,Moving the puck on desktop for manipulating the 2D graphic.,on the horizontal surface,"Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane.,Translating/Rotating/Scaling,2D,2D graphic,The position and rotation of the 2D graphic displayed on the screen.,2D display,Use a plate to translate/rotate/scale a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The puck is on the screen.
2. The puck is aligned with the 2D graphic.
3. The 2D graphic is in front of the user."
24,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3173225.3173252,"de Siqueira, Alexandre G. and Ullmer, Brygg and Delarosa, Mark and Branton, Chris and Konkel, Miriam K.","@inproceedings{10.1145/3173225.3173252,
author = {de Siqueira, Alexandre G. and Ullmer, Brygg and Delarosa, Mark and Branton, Chris and Konkel, Miriam K.},
title = {Hard and Soft Tangibles: Mixing Multi-touch and Tangible Interaction in Scientific Poster Scenarios},
year = {2018},
isbn = {9781450355681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173225.3173252},
doi = {10.1145/3173225.3173252},
abstract = {Research on tangible user interfaces commonly focuses on tangible interfaces acting alone or in comparison with multi-touch or graphical interfaces. In contrast, hybrid approaches can be seen as the norm for established ""mainstream"" interaction paradigms. This paper proposes interfaces that support complementary use of physical and virtual interaction modalities with tangible and multi-touch interactions. We describe prototypes involving capacitively-sensed surfaces combined with laser-cut and 3D-printed dial-like tangibles. We employ them in the context of several computationally-mediated scientific poster scenarios, which we argue to have a number of attractions for such deployments. We present two platforms: one templated, the other highly customizable, supporting both tangible and multi-touch interactions across horizontal and vertical displays. We explore users' interaction modality choice among the options presented, draw lessons and challenges from posters developed by students, and consider future directions.},
booktitle = {Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {476¨C486},
numpages = {11},
keywords = {tangible user interfaces, tangible interaction, poster presentation, passive tokens, multi-touch interaction, hard and soft tangibles., cyberphysical interfaces, computationally-mediated scientific poster},
location = {Stockholm, Sweden},
series = {TEI '18}
}",Hard and Soft Tangibles: Mixing Multi-touch and Tangible Interaction in Scientific Poster Scenarios,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A puck with 60 mm diameter,Planar surface,The bottom surface of knob with 60 mm diameter,One-handed,Positioning,Locating the puck on the screen on wall for displaying textual information at a position in the plane.,on the vertical surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D graphic,The textual information displayed on the screen.,2D display,Use a plate to modulate a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The puck is on the screen.
2. The puck is aligned with the 2D graphic.
3. The 2D graphic is in front of the user."
24,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3173225.3173252,"de Siqueira, Alexandre G. and Ullmer, Brygg and Delarosa, Mark and Branton, Chris and Konkel, Miriam K.","@inproceedings{10.1145/3173225.3173252,
author = {de Siqueira, Alexandre G. and Ullmer, Brygg and Delarosa, Mark and Branton, Chris and Konkel, Miriam K.},
title = {Hard and Soft Tangibles: Mixing Multi-touch and Tangible Interaction in Scientific Poster Scenarios},
year = {2018},
isbn = {9781450355681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173225.3173252},
doi = {10.1145/3173225.3173252},
abstract = {Research on tangible user interfaces commonly focuses on tangible interfaces acting alone or in comparison with multi-touch or graphical interfaces. In contrast, hybrid approaches can be seen as the norm for established ""mainstream"" interaction paradigms. This paper proposes interfaces that support complementary use of physical and virtual interaction modalities with tangible and multi-touch interactions. We describe prototypes involving capacitively-sensed surfaces combined with laser-cut and 3D-printed dial-like tangibles. We employ them in the context of several computationally-mediated scientific poster scenarios, which we argue to have a number of attractions for such deployments. We present two platforms: one templated, the other highly customizable, supporting both tangible and multi-touch interactions across horizontal and vertical displays. We explore users' interaction modality choice among the options presented, draw lessons and challenges from posters developed by students, and consider future directions.},
booktitle = {Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {476¨C486},
numpages = {11},
keywords = {tangible user interfaces, tangible interaction, poster presentation, passive tokens, multi-touch interaction, hard and soft tangibles., cyberphysical interfaces, computationally-mediated scientific poster},
location = {Stockholm, Sweden},
series = {TEI '18}
}",Hard and Soft Tangibles: Mixing Multi-touch and Tangible Interaction in Scientific Poster Scenarios,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A puck with 60 mm diameter,Planar surface,The bottom surface of knob with 60 mm diameter,One-handed,Rotating,Rotating the puck orientation on the screen on wall for adjusting the currently displayed image.,on the vertical surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D graphic,The image displayed on the screen.,2D display,Use a plate to adjust a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The puck is on the screen.
2. The puck is aligned with the 2D graphic.
3. The 2D graphic is in front of the user."
25,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1935701.1935777,"Israel, Johann Habakuk and Belaifa, Oliver and Gispen, Adrienne and Stark, Rainer","@inproceedings{10.1145/1935701.1935777,
author = {Israel, Johann Habakuk and Belaifa, Oliver and Gispen, Adrienne and Stark, Rainer},
title = {An object-centric interaction framework for tangible interfaces in virtual environments},
year = {2010},
isbn = {9781450304788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935701.1935777},
doi = {10.1145/1935701.1935777},
abstract = {The spatial and semantic integration of tangible user interfaces (TUI) into virtual environments is a promising approach to enhance mixed reality-applications with dynamic three-dimensional graphics and graspable controls. Although various software frameworks for virtual reality periphery and tangible interaction exist, a novel framework which provides a high-level TUI-object-centric interface (instead of device-centric interface) and duplex access to important physical properties of TUI-objects, e.g. three-dimensional position, sensor states, force actuators could foster the development of such mixed-reality applications.This paper describes a TUI-VR-framework whose aim is to support the development of physically enriched VR-applications. It focuses on the spatial and manipulative properties of TUI-objects, leaving it to the application to implement interaction techniques, semantics and expressive physical/digital couplings [cf. 10, 27].On the programming side, the primary goals of the framework are the integration of a device abstraction layer, a lightweight application programming interface and full duplex communication between the TUI-application and interaction devices. The framework allows for a distributed system configuration and is highly customizable. Various virtual reality tracking frameworks and devices (e.g. VRPN, Ascension MotionStar, force-feedback devices) and physical toolkits (e.g. Phidgets) are already integrated. Further adapters can also easily be integrated.The capabilities and flexibility of the framework are illustrated at the end of the paper by means of two use cases.},
booktitle = {Proceedings of the Fifth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {325¨C332},
numpages = {8},
keywords = {virtual reality, tangible user interfaces, object centric interaction framework, mixed reality, event-driven architecture, device abstraction layer, client-server architecture},
location = {Funchal, Portugal},
series = {TEI '11}
}",An object-centric interaction framework for tangible interfaces in virtual environments,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A stylus,Point,The tip of the stylus,One-handed,Tracing,Locating the tip of the stylus in space to input a spatial curve.,in the room space,Position,Physical widget: 3DOF translation in the space.,Modulating,3D,3D graphic,The position of the 3D graphic displayed in the virtual reality (CAVE).,Virtual reality,Use a slender body to modulate a 3D graphic by tracing.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The stylus is in user's hand.
2. The tip of the stylus is embedded with the 3D graphic.
3. The 3D graphic is in the room."
25,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1935701.1935777,"Israel, Johann Habakuk and Belaifa, Oliver and Gispen, Adrienne and Stark, Rainer","@inproceedings{10.1145/1935701.1935777,
author = {Israel, Johann Habakuk and Belaifa, Oliver and Gispen, Adrienne and Stark, Rainer},
title = {An object-centric interaction framework for tangible interfaces in virtual environments},
year = {2010},
isbn = {9781450304788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935701.1935777},
doi = {10.1145/1935701.1935777},
abstract = {The spatial and semantic integration of tangible user interfaces (TUI) into virtual environments is a promising approach to enhance mixed reality-applications with dynamic three-dimensional graphics and graspable controls. Although various software frameworks for virtual reality periphery and tangible interaction exist, a novel framework which provides a high-level TUI-object-centric interface (instead of device-centric interface) and duplex access to important physical properties of TUI-objects, e.g. three-dimensional position, sensor states, force actuators could foster the development of such mixed-reality applications.This paper describes a TUI-VR-framework whose aim is to support the development of physically enriched VR-applications. It focuses on the spatial and manipulative properties of TUI-objects, leaving it to the application to implement interaction techniques, semantics and expressive physical/digital couplings [cf. 10, 27].On the programming side, the primary goals of the framework are the integration of a device abstraction layer, a lightweight application programming interface and full duplex communication between the TUI-application and interaction devices. The framework allows for a distributed system configuration and is highly customizable. Various virtual reality tracking frameworks and devices (e.g. VRPN, Ascension MotionStar, force-feedback devices) and physical toolkits (e.g. Phidgets) are already integrated. Further adapters can also easily be integrated.The capabilities and flexibility of the framework are illustrated at the end of the paper by means of two use cases.},
booktitle = {Proceedings of the Fifth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {325¨C332},
numpages = {8},
keywords = {virtual reality, tangible user interfaces, object centric interaction framework, mixed reality, event-driven architecture, device abstraction layer, client-server architecture},
location = {Funchal, Portugal},
series = {TEI '11}
}",An object-centric interaction framework for tangible interfaces in virtual environments,,Small,Double,Two tangible widgets,N/A,Rigid,No use,Slender body,Two cylindrical handles,Point,Two distal ends of handle,Asymmetric,Positioning+Rotating,Locating two distal ends of handles as a combination in space for creating the 3D graphic controlled by two spatial curve control points.,in the room space,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,3D,3D graphic,The position of the 3D graphic displayed in the virtual reality (CAVE).,Virtual reality,Use two slender bodies to modulate a 3D graphic by coordinated positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. Two stylus are in user's hand.
2. Two distal ends of handles are embedded with the 3D graphic.
3. The 3D graphic is in the room."
26,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2148131.2148156,"Forsslund, Jonas and Ioannou, Ioanna","@inproceedings{10.1145/2148131.2148156,
author = {Forsslund, Jonas and Ioannou, Ioanna},
title = {Tangible sketching of interactive haptic materials},
year = {2012},
isbn = {9781450311748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2148131.2148156},
doi = {10.1145/2148131.2148156},
abstract = {The activity of sketching can be highly beneficial when applied to the design of haptic material interaction. To illustrate this approach we created a design tool with a tangible hardware interface to facilitate the act of haptic material sketching and used this tool to design an anatomy exploration application. We found this approach particularly efficient in designing non-visual properties of haptic materials. The design tool enabled instant tactile perception of changes in material properties combined with the ability to make on-the-fly adjustments, thus creating a sense of pliability.},
booktitle = {Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction},
pages = {111¨C114},
numpages = {4},
keywords = {design, haptics, interaction design, sketching, tangible interfaces},
location = {Kingston, Ontario, Canada},
series = {TEI '12}
}",Tangible sketching of interactive haptic materials,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A pen-shaped input device,Point,The tip of pen-shaped input device,One-handed,Positioning,Locating the tip of pen-shaped input device in space to input a position in the 3D visualization.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Browsing,3D,3D graphic,The information of 3D model at the input position displayed on the screen.,2D display,Use a slender body to browse a 3D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Embedded,"1. The tip of pen-shaped input device is in user's hand.
2. The virtual input controlled by the  tip of pen-shaped input device is embedded with the 3D visualization.
3. The 3D visualization is away from the user."
27,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2677199.2680592,"Nunes, Rafael and Rito, Fabio and Duarte, Carlos","@inproceedings{10.1145/2677199.2680592,
author = {Nunes, Rafael and Rito, Fabio and Duarte, Carlos},
title = {TACTIC: An API for Touch and Tangible Interaction},
year = {2015},
isbn = {9781450333054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677199.2680592},
doi = {10.1145/2677199.2680592},
abstract = {Interactive surfaces, gesture recognition, object tracking, tangible interaction are increasingly moving from the research arena to the domain of commercial applications. However, the effort required to combine all these technologies is still a barrier preventing a wider adoption. In this paper, we present TACTIC, an API combining touch surfaces, tangibles, and the interaction space above the surface, in a way that allows developers to easily combine all these features, and distribute interfaces across multiple devices if required. Additionally, we present the results of a developer study showing how TACTIC is easy to learn and use.},
booktitle = {Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {125¨C132},
numpages = {8},
keywords = {touch interaction, tangible interfaces, mobile devices, distributed interfaces, continuous interaction space, api},
location = {Stanford, California, USA},
series = {TEI '15}
}",TACTIC: An API for Touch and Tangible Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A mobile device/cube,Planar surface,The bottom surface of mobile device/cube,One-handed,Rotating,"Rotating the mobile device/cube orientation on desktop for adjusting the text size.
 ",on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D text,The textual information displayed on the desktop screen.,2D display,Use a plate to adjust a 2D text by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The mobile device/cube is on the screen.
2. The mobile device/cube is aligned with the 2D graphic.
3. The 2D graphic is on the desktop."
27,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2677199.2680592,"Nunes, Rafael and Rito, Fabio and Duarte, Carlos","@inproceedings{10.1145/2677199.2680592,
author = {Nunes, Rafael and Rito, Fabio and Duarte, Carlos},
title = {TACTIC: An API for Touch and Tangible Interaction},
year = {2015},
isbn = {9781450333054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677199.2680592},
doi = {10.1145/2677199.2680592},
abstract = {Interactive surfaces, gesture recognition, object tracking, tangible interaction are increasingly moving from the research arena to the domain of commercial applications. However, the effort required to combine all these technologies is still a barrier preventing a wider adoption. In this paper, we present TACTIC, an API combining touch surfaces, tangibles, and the interaction space above the surface, in a way that allows developers to easily combine all these features, and distribute interfaces across multiple devices if required. Additionally, we present the results of a developer study showing how TACTIC is easy to learn and use.},
booktitle = {Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {125¨C132},
numpages = {8},
keywords = {touch interaction, tangible interfaces, mobile devices, distributed interfaces, continuous interaction space, api},
location = {Stanford, California, USA},
series = {TEI '15}
}",TACTIC: An API for Touch and Tangible Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A mobile device,Body,A mobile device,One-handed,Tracing,Hovering the mobile device in space above the desktop to input a planar curve.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Modulating,2D,2D graphic,The position of the 2D graphic displayed on the desktop screen.,2D display,Use a plate to modulate a 2D graphic by tracing.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Discrete,"1. The mobile device is in user's hand.
2. The mobile device is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
27,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2677199.2680592,"Nunes, Rafael and Rito, Fabio and Duarte, Carlos","@inproceedings{10.1145/2677199.2680592,
author = {Nunes, Rafael and Rito, Fabio and Duarte, Carlos},
title = {TACTIC: An API for Touch and Tangible Interaction},
year = {2015},
isbn = {9781450333054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677199.2680592},
doi = {10.1145/2677199.2680592},
abstract = {Interactive surfaces, gesture recognition, object tracking, tangible interaction are increasingly moving from the research arena to the domain of commercial applications. However, the effort required to combine all these technologies is still a barrier preventing a wider adoption. In this paper, we present TACTIC, an API combining touch surfaces, tangibles, and the interaction space above the surface, in a way that allows developers to easily combine all these features, and distribute interfaces across multiple devices if required. Additionally, we present the results of a developer study showing how TACTIC is easy to learn and use.},
booktitle = {Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {125¨C132},
numpages = {8},
keywords = {touch interaction, tangible interfaces, mobile devices, distributed interfaces, continuous interaction space, api},
location = {Stanford, California, USA},
series = {TEI '15}
}",TACTIC: An API for Touch and Tangible Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A cube,Body,A cube,One-handed,Tracing,Hovering the cube in space above the desktop to input a planar curve.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Modulating,2D,2D graphic,The position of the 2D graphic displayed on the desktop screen.,2D display,Use a polyhedron to modulate a 2D graphic by tracing.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Discrete,"1. The cube is in user's hand.
2. The cube is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
28,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2540930.2540936,"Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin","@inproceedings{10.1145/2540930.2540936,
author = {Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin},
title = {PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system},
year = {2014},
isbn = {9781450326353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2540930.2540936},
doi = {10.1145/2540930.2540936},
abstract = {Persons with a neurological disorder are confronted with significantly reduced physical abilities during their daily activities. Physiotherapy, for these patients mainly provided in rehabilitation centres, utilizes tangible, real-world objects in training for the upper limbs. Only by intensely and frequently exercising, patients have a chance to sustain or enhance their functional performance. Our research explores pervasive technologies and tangible objects to provide motivating, technology-supported training systems in a residential environment for independent use by these patients. In this paper, we describe our pervasive training system 'PhysiCube', consisting of prototypes 'LiftACube' and 'ReachACube'. PhysiCube takes advantage of tangible interactions and games to provide motivating physical training for the upper limbs. An evaluation with therapists showed great appreciation for our prototypes. Reflections on the technical setup and use of tangible interaction for these pervasive rehabilitation systems in a residential setting are elaborated upon.},
booktitle = {Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction},
pages = {85¨C92},
numpages = {8},
keywords = {upper extremity, tangible interaction, physical therapy, pervasive healthcare, neurorehabilitation, motor training},
location = {Munich, Germany},
series = {TEI '14}
}",PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A Sifteo Cube,Body,A Sifteo Cube,One-handed,Positioning,Lifting the Sifteo Cube in space for adjusting the mode of game.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,2D,2D graphic,The mode of the game displayed on the mobile device screen.,2D display,Use a polyhedron to adjust a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The Sifteo Cube is in user's hand.
2. The Sifteo Cube is aligned with the 2D graphic.
3. The 2D graphic is above the desktop."
28,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2540930.2540936,"Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin","@inproceedings{10.1145/2540930.2540936,
author = {Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin},
title = {PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system},
year = {2014},
isbn = {9781450326353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2540930.2540936},
doi = {10.1145/2540930.2540936},
abstract = {Persons with a neurological disorder are confronted with significantly reduced physical abilities during their daily activities. Physiotherapy, for these patients mainly provided in rehabilitation centres, utilizes tangible, real-world objects in training for the upper limbs. Only by intensely and frequently exercising, patients have a chance to sustain or enhance their functional performance. Our research explores pervasive technologies and tangible objects to provide motivating, technology-supported training systems in a residential environment for independent use by these patients. In this paper, we describe our pervasive training system 'PhysiCube', consisting of prototypes 'LiftACube' and 'ReachACube'. PhysiCube takes advantage of tangible interactions and games to provide motivating physical training for the upper limbs. An evaluation with therapists showed great appreciation for our prototypes. Reflections on the technical setup and use of tangible interaction for these pervasive rehabilitation systems in a residential setting are elaborated upon.},
booktitle = {Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction},
pages = {85¨C92},
numpages = {8},
keywords = {upper extremity, tangible interaction, physical therapy, pervasive healthcare, neurorehabilitation, motor training},
location = {Munich, Germany},
series = {TEI '14}
}",PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A Sifteo Cube,Body,A Sifteo Cube,One-handed,Shaking,Shaking the Sifteo Cube in space for adjusting the mode of game.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Adjusting,2D,2D graphic,The mode of the game displayed on the mobile device screen.,2D display,Use a polyhedron to adjust a 2D graphic by shaking.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The Sifteo Cube is in user's hand.
2. The Sifteo Cube is aligned with the 2D graphic.
3. The 2D graphic is above the desktop."
28,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2540930.2540936,"Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin","@inproceedings{10.1145/2540930.2540936,
author = {Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin},
title = {PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system},
year = {2014},
isbn = {9781450326353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2540930.2540936},
doi = {10.1145/2540930.2540936},
abstract = {Persons with a neurological disorder are confronted with significantly reduced physical abilities during their daily activities. Physiotherapy, for these patients mainly provided in rehabilitation centres, utilizes tangible, real-world objects in training for the upper limbs. Only by intensely and frequently exercising, patients have a chance to sustain or enhance their functional performance. Our research explores pervasive technologies and tangible objects to provide motivating, technology-supported training systems in a residential environment for independent use by these patients. In this paper, we describe our pervasive training system 'PhysiCube', consisting of prototypes 'LiftACube' and 'ReachACube'. PhysiCube takes advantage of tangible interactions and games to provide motivating physical training for the upper limbs. An evaluation with therapists showed great appreciation for our prototypes. Reflections on the technical setup and use of tangible interaction for these pervasive rehabilitation systems in a residential setting are elaborated upon.},
booktitle = {Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction},
pages = {85¨C92},
numpages = {8},
keywords = {upper extremity, tangible interaction, physical therapy, pervasive healthcare, neurorehabilitation, motor training},
location = {Munich, Germany},
series = {TEI '14}
}",PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A Sifteo Cube,Body,A Sifteo Cube,One-handed,Rotating,Flipping the Sifteo Cube in space for adjusting the mode of game.,above the horizontal surface,Rotation,Physical widget: 3DOF rotation in the space.,Adjusting,2D,2D graphic,The mode of the game displayed on the mobile device screen.,2D display,Use a polyhedron to adjust a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The Sifteo Cube is in user's hand.
2. The Sifteo Cube is aligned with the 2D graphic.
3. The 2D graphic is above the desktop."
28,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2540930.2540936,"Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin","@inproceedings{10.1145/2540930.2540936,
author = {Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin},
title = {PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system},
year = {2014},
isbn = {9781450326353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2540930.2540936},
doi = {10.1145/2540930.2540936},
abstract = {Persons with a neurological disorder are confronted with significantly reduced physical abilities during their daily activities. Physiotherapy, for these patients mainly provided in rehabilitation centres, utilizes tangible, real-world objects in training for the upper limbs. Only by intensely and frequently exercising, patients have a chance to sustain or enhance their functional performance. Our research explores pervasive technologies and tangible objects to provide motivating, technology-supported training systems in a residential environment for independent use by these patients. In this paper, we describe our pervasive training system 'PhysiCube', consisting of prototypes 'LiftACube' and 'ReachACube'. PhysiCube takes advantage of tangible interactions and games to provide motivating physical training for the upper limbs. An evaluation with therapists showed great appreciation for our prototypes. Reflections on the technical setup and use of tangible interaction for these pervasive rehabilitation systems in a residential setting are elaborated upon.},
booktitle = {Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction},
pages = {85¨C92},
numpages = {8},
keywords = {upper extremity, tangible interaction, physical therapy, pervasive healthcare, neurorehabilitation, motor training},
location = {Munich, Germany},
series = {TEI '14}
}",PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system,,Small,Double,Two tangible widgets,N/A,Rigid,No use,Polyhedron,Two Sifteo Cubes,Planar surface,Two bottom surfaces of Sifteo Cube,Asymmetric,Positioning,Moving two Sifteo Cubes on desktop to neighbor for adjusting the mode of game.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Adjusting,2D,2D graphic,The mode of the game displayed on the mobile device screen.,2D display,Use two polyhedrons to adjust a 2D graphic by coordinated positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The Sifteo Cube is in user's hand.
2. The Sifteo Cube is aligned with the 2D graphic.
3. The 2D graphic is above the desktop."
28,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2540930.2540936,"Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin","@inproceedings{10.1145/2540930.2540936,
author = {Vandermaesen, Marijke and de Weyer, Tom and Luyten, Kris and Coninx, Karin},
title = {PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system},
year = {2014},
isbn = {9781450326353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2540930.2540936},
doi = {10.1145/2540930.2540936},
abstract = {Persons with a neurological disorder are confronted with significantly reduced physical abilities during their daily activities. Physiotherapy, for these patients mainly provided in rehabilitation centres, utilizes tangible, real-world objects in training for the upper limbs. Only by intensely and frequently exercising, patients have a chance to sustain or enhance their functional performance. Our research explores pervasive technologies and tangible objects to provide motivating, technology-supported training systems in a residential environment for independent use by these patients. In this paper, we describe our pervasive training system 'PhysiCube', consisting of prototypes 'LiftACube' and 'ReachACube'. PhysiCube takes advantage of tangible interactions and games to provide motivating physical training for the upper limbs. An evaluation with therapists showed great appreciation for our prototypes. Reflections on the technical setup and use of tangible interaction for these pervasive rehabilitation systems in a residential setting are elaborated upon.},
booktitle = {Proceedings of the 8th International Conference on Tangible, Embedded and Embodied Interaction},
pages = {85¨C92},
numpages = {8},
keywords = {upper extremity, tangible interaction, physical therapy, pervasive healthcare, neurorehabilitation, motor training},
location = {Munich, Germany},
series = {TEI '14}
}",PhysiCube: providing tangible interaction in a pervasive upper-limb rehabilitation system,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A wooden handle with a Sifteo Cube,Body,A wooden handle with a Sifteo Cube,One-handed,Positioning+Rotating,Moving a wooden handle with a Sifteo Cube in space to keep the cube on top of a target cube.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Adjusting,2D,2D graphic,The mode of the game displayed on the mobile device screen.,2D display,Use a slender body to adjust a 2D graphic by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The handle is in user's hand.
2. The Sifteo Cube on the handle is aligned with the 2D graphic.
3. The 2D graphic is above the desktop."
29,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2839462.2839500,"Arif, Ahmed Sabbir and Manshaei, Roozbeh and Delong, Sean and East, Brien and Kyan, Matthew and Mazalek, Ali","@inproceedings{10.1145/2839462.2839500,
author = {Arif, Ahmed Sabbir and Manshaei, Roozbeh and Delong, Sean and East, Brien and Kyan, Matthew and Mazalek, Ali},
title = {Sparse Tangibles: Collaborative Exploration of Gene Networks using Active Tangibles and Interactive Tabletops},
year = {2016},
isbn = {9781450335829},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2839462.2839500},
doi = {10.1145/2839462.2839500},
abstract = {We present Sparse Tangibles, a tabletop and active tangible-based framework to support cross-platform, collaborative gene network exploration using a Web interface. It uses smartwatches as active tangibles to allow query construction on- and off-the-table. We expand their interaction vocabulary using inertial sensors and a custom case. We also introduce a new metric for measuring the ""confidence level"" of protein and genetic interactions. Three expert biologists evaluated the system and found it fun, useful, easy to use, and ideal for collaborative explorations.},
booktitle = {Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {287¨C295},
numpages = {9},
keywords = {Systems biology, active tangibles, biomedical engineering, participatory design, sparse network, tabletop, visualization},
location = {Eindhoven, Netherlands},
series = {TEI '16}
}",Sparse Tangibles: Collaborative Exploration of Gene Networks using Active Tangibles and Interactive Tabletops,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A smartwatch without a band,Planar surface,The bottom surface of smartwatch without a band,One-handed,Positioning,Locating the knob on the screen on desktop for displaying gene network information at a position in the plane.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D text,The position of the 2D graphic displayed on the desktop screen.,2D display,Use a plate to modulate a 2D text by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The smartwatch is on the desktop.
2. The smartwatch is aligned with the 2D graphic.
3. The 2D graphic is on the desktop."
29,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2839462.2839500,"Arif, Ahmed Sabbir and Manshaei, Roozbeh and Delong, Sean and East, Brien and Kyan, Matthew and Mazalek, Ali","@inproceedings{10.1145/2839462.2839500,
author = {Arif, Ahmed Sabbir and Manshaei, Roozbeh and Delong, Sean and East, Brien and Kyan, Matthew and Mazalek, Ali},
title = {Sparse Tangibles: Collaborative Exploration of Gene Networks using Active Tangibles and Interactive Tabletops},
year = {2016},
isbn = {9781450335829},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2839462.2839500},
doi = {10.1145/2839462.2839500},
abstract = {We present Sparse Tangibles, a tabletop and active tangible-based framework to support cross-platform, collaborative gene network exploration using a Web interface. It uses smartwatches as active tangibles to allow query construction on- and off-the-table. We expand their interaction vocabulary using inertial sensors and a custom case. We also introduce a new metric for measuring the ""confidence level"" of protein and genetic interactions. Three expert biologists evaluated the system and found it fun, useful, easy to use, and ideal for collaborative explorations.},
booktitle = {Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {287¨C295},
numpages = {9},
keywords = {Systems biology, active tangibles, biomedical engineering, participatory design, sparse network, tabletop, visualization},
location = {Eindhoven, Netherlands},
series = {TEI '16}
}",Sparse Tangibles: Collaborative Exploration of Gene Networks using Active Tangibles and Interactive Tabletops,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A smartwatch without a band,Body,A smartwatch without a band,One-handed,Shaking,Shaking the smartwatch in space for removing the selected parameters.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,2D,2D text,The information of selected parameter of the 2D graphic displayed on the desktop screen.,2D display,Use a plate to modulate a 2D text by shaking.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The smartwatch is in user's hand.
2. The smartwatch is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
30,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3490149.3502260,"Gramlich, Johanna and Pauli, Selina and Huber, Stephan and Baur, Cordula and Hurtienne, J\""{o}rn","@inproceedings{10.1145/3490149.3502260,
author = {Gramlich, Johanna and Pauli, Selina and Huber, Stephan and Baur, Cordula and Hurtienne, J\""{o}rn},
title = {Fin, Whale, Coin and Flatterer: Exploring Tangibles for Air Traffic Control},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3502260},
doi = {10.1145/3490149.3502260},
abstract = {Air traffic control (ATC) is a safety-critical work domain that has a history of applying tangible elements in its workstations. In the past, development was mostly technology-driven, which resulted in usability challenges like handling multiple input and output devices. In this work, we followed a user-centred design approach with air traffic controllers (ATCOs). Starting from the users¡¯ need for haptic feedback, we developed a novel tangible interaction concept for ATC. We iterated a set of tangibles ¨C Fin, Whale, Coin, and Flatterer ¨C based on formative evaluations with 24 ATCOs. From our qualitative results we extracted dimensions relevant to ATCOs¡® user experience including familiarity, efficiency and engagement. Our results can provide guidance and inspiration for the design of future ATC interfaces.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {36},
numpages = {13},
location = {Daejeon, Republic of Korea},
series = {TEI '22}
}","Fin, Whale, Coin and Flatterer: Exploring Tangibles for Air Traffic Control",,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of 2D graphic,Planar surface,The bottom surface of low-fidelity model of 2D graphic,One-handed,Rotating,"Rotating the model orientation on desktop for manipulating the selected aircraft.
 ",on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Translating/Rotating/Scaling,2D,2D graphic,The rotation of the 2D graphic displayed on the screen.,2D display,Use an other to translate/rotate/scale a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The low-fidelity model is on the desktop.
2. The low-fidelity model is discrete from the 2D graphic.
3. The 2D graphic is in front of the user."
30,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3490149.3502260,"Gramlich, Johanna and Pauli, Selina and Huber, Stephan and Baur, Cordula and Hurtienne, J\""{o}rn","@inproceedings{10.1145/3490149.3502260,
author = {Gramlich, Johanna and Pauli, Selina and Huber, Stephan and Baur, Cordula and Hurtienne, J\""{o}rn},
title = {Fin, Whale, Coin and Flatterer: Exploring Tangibles for Air Traffic Control},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3502260},
doi = {10.1145/3490149.3502260},
abstract = {Air traffic control (ATC) is a safety-critical work domain that has a history of applying tangible elements in its workstations. In the past, development was mostly technology-driven, which resulted in usability challenges like handling multiple input and output devices. In this work, we followed a user-centred design approach with air traffic controllers (ATCOs). Starting from the users¡¯ need for haptic feedback, we developed a novel tangible interaction concept for ATC. We iterated a set of tangibles ¨C Fin, Whale, Coin, and Flatterer ¨C based on formative evaluations with 24 ATCOs. From our qualitative results we extracted dimensions relevant to ATCOs¡® user experience including familiarity, efficiency and engagement. Our results can provide guidance and inspiration for the design of future ATC interfaces.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {36},
numpages = {13},
location = {Daejeon, Republic of Korea},
series = {TEI '22}
}","Fin, Whale, Coin and Flatterer: Exploring Tangibles for Air Traffic Control",,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of 2D graphic,Body,A low-fidelity model of 2D graphic,One-handed,Rotating,Tilting the model on desktop for adjusting the speed of the selected aircraft.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D graphic,The speed information of the 2D graphic displayed on the screen.,2D display,Use an other to adjust a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The low-fidelity model is on the desktop.
2. The low-fidelity model is discrete from the 2D graphic.
3. The 2D graphic is in front of the user."
30,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3490149.3502260,"Gramlich, Johanna and Pauli, Selina and Huber, Stephan and Baur, Cordula and Hurtienne, J\""{o}rn","@inproceedings{10.1145/3490149.3502260,
author = {Gramlich, Johanna and Pauli, Selina and Huber, Stephan and Baur, Cordula and Hurtienne, J\""{o}rn},
title = {Fin, Whale, Coin and Flatterer: Exploring Tangibles for Air Traffic Control},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3502260},
doi = {10.1145/3490149.3502260},
abstract = {Air traffic control (ATC) is a safety-critical work domain that has a history of applying tangible elements in its workstations. In the past, development was mostly technology-driven, which resulted in usability challenges like handling multiple input and output devices. In this work, we followed a user-centred design approach with air traffic controllers (ATCOs). Starting from the users¡¯ need for haptic feedback, we developed a novel tangible interaction concept for ATC. We iterated a set of tangibles ¨C Fin, Whale, Coin, and Flatterer ¨C based on formative evaluations with 24 ATCOs. From our qualitative results we extracted dimensions relevant to ATCOs¡® user experience including familiarity, efficiency and engagement. Our results can provide guidance and inspiration for the design of future ATC interfaces.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {36},
numpages = {13},
location = {Daejeon, Republic of Korea},
series = {TEI '22}
}","Fin, Whale, Coin and Flatterer: Exploring Tangibles for Air Traffic Control",,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of 2D graphic,Body,The point represented by low-fidelity model of 2D graphic,One-handed,Positioning,Lifting the model in space for clear the information of lower or higher flight levels.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Modulating,2D,2D graphic,The information at different flight levels of the 2D graphic displayed on the screen.,2D display,Use an other to modulate a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The low-fidelity model is on the desktop.
2. The low-fidelity model is discrete from the 2D graphic.
3. The 2D graphic is in front of the user."
31,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3490149.3501314,"Visschedijk, Aaron and Kim, Hyunyoung and Tejada, Carlos and Ashbrook, Daniel","@inproceedings{10.1145/3490149.3501314,
author = {Visschedijk, Aaron and Kim, Hyunyoung and Tejada, Carlos and Ashbrook, Daniel},
title = {ClipWidgets: 3D-printed Modular Tangible UI Extensions for Smartphones},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3501314},
doi = {10.1145/3490149.3501314},
abstract = {Touchscreens provide a platform for adaptable and versatile user interfaces making them a popular choice for modern smart devices. However, touchscreens lack physicality. Existing solutions to add tangible user interfaces to smart devices often require complicated assembly or occlude part of the touchscreen. We propose ClipWidgets: 3D-printed modular tangible UI extensions for smartphones. ClipWidgets uses a conical mirror and a custom phone case to redirect the field of view of the rear camera of a smartphone to the phone¡¯s periphery. This allows the phone to optically sense input from modular passive 3D-printed widgets that are attached to the phone case. We developed three different widget types (button, dial and slider) that require minimal calibration and minimal assembly. To demonstrate the functionality of ClipWidgets we used it to prototype three different applications: a game controller, a music interface and an interactive graph tool.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {8},
numpages = {11},
keywords = {3D printing, Mobile Computing, Prototyping, User Interfaces},
location = {Daejeon, Republic of Korea},
series = {TEI '22}
}",ClipWidgets 3D-printed Modular Tangible UI Extensions for Smartphones,,Small,Single,A tangible widget,N/A,Rigid,No use,Constrained body,A slider,Straight edge,The slider's motion path,One-handed,Positioning,Sliding the slider on desktop for adjusting the volume of the audio in a constrained direction.,on the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Adjusting,Other,Audio,The volume of the audio.,2D display,Use a constrained body to adjust an audio by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The slider is on the desktop.
2. The slider is discrete from the audio player.
3. The audio player is on the desktop."
31,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3490149.3501314,"Visschedijk, Aaron and Kim, Hyunyoung and Tejada, Carlos and Ashbrook, Daniel","@inproceedings{10.1145/3490149.3501314,
author = {Visschedijk, Aaron and Kim, Hyunyoung and Tejada, Carlos and Ashbrook, Daniel},
title = {ClipWidgets: 3D-printed Modular Tangible UI Extensions for Smartphones},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3501314},
doi = {10.1145/3490149.3501314},
abstract = {Touchscreens provide a platform for adaptable and versatile user interfaces making them a popular choice for modern smart devices. However, touchscreens lack physicality. Existing solutions to add tangible user interfaces to smart devices often require complicated assembly or occlude part of the touchscreen. We propose ClipWidgets: 3D-printed modular tangible UI extensions for smartphones. ClipWidgets uses a conical mirror and a custom phone case to redirect the field of view of the rear camera of a smartphone to the phone¡¯s periphery. This allows the phone to optically sense input from modular passive 3D-printed widgets that are attached to the phone case. We developed three different widget types (button, dial and slider) that require minimal calibration and minimal assembly. To demonstrate the functionality of ClipWidgets we used it to prototype three different applications: a game controller, a music interface and an interactive graph tool.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {8},
numpages = {11},
keywords = {3D printing, Mobile Computing, Prototyping, User Interfaces},
location = {Daejeon, Republic of Korea},
series = {TEI '22}
}",ClipWidgets 3D-printed Modular Tangible UI Extensions for Smartphones,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A dial,Planar surface,The bottom surface of dial,One-handed,Rotating,Rotating the dial orientation on desktop for adjusting the tempo of the audio.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,Other,Audio,The tempo of the audio.,2D display,Use a plate to adjust an audio by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The slider is on the desktop.
2. The slider is discrete from the audio player.
3. The audio player is on the desktop."
31,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3490149.3501314,"Visschedijk, Aaron and Kim, Hyunyoung and Tejada, Carlos and Ashbrook, Daniel","@inproceedings{10.1145/3490149.3501314,
author = {Visschedijk, Aaron and Kim, Hyunyoung and Tejada, Carlos and Ashbrook, Daniel},
title = {ClipWidgets: 3D-printed Modular Tangible UI Extensions for Smartphones},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3501314},
doi = {10.1145/3490149.3501314},
abstract = {Touchscreens provide a platform for adaptable and versatile user interfaces making them a popular choice for modern smart devices. However, touchscreens lack physicality. Existing solutions to add tangible user interfaces to smart devices often require complicated assembly or occlude part of the touchscreen. We propose ClipWidgets: 3D-printed modular tangible UI extensions for smartphones. ClipWidgets uses a conical mirror and a custom phone case to redirect the field of view of the rear camera of a smartphone to the phone¡¯s periphery. This allows the phone to optically sense input from modular passive 3D-printed widgets that are attached to the phone case. We developed three different widget types (button, dial and slider) that require minimal calibration and minimal assembly. To demonstrate the functionality of ClipWidgets we used it to prototype three different applications: a game controller, a music interface and an interactive graph tool.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {8},
numpages = {11},
keywords = {3D printing, Mobile Computing, Prototyping, User Interfaces},
location = {Daejeon, Republic of Korea},
series = {TEI '22}
}",ClipWidgets 3D-printed Modular Tangible UI Extensions for Smartphones,,Small,Single,A tangible widget,N/A,Rigid,No use,Constrained body,A slider,Straight edge,The slider's motion path,One-handed,Positioning,Sliding the slider on desktop for scaling the 2D visualization.,on the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Navigating,2D,2D equation,The function image displayed on the mobile device screen.,2D display,Use a constrained body to navigate a 2D equation by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The slider is near the mobile device.
2. The slider is discrete from the 2D visualization.
3. The 2D visualization is on the mobile device."
31,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3490149.3501314,"Visschedijk, Aaron and Kim, Hyunyoung and Tejada, Carlos and Ashbrook, Daniel","@inproceedings{10.1145/3490149.3501314,
author = {Visschedijk, Aaron and Kim, Hyunyoung and Tejada, Carlos and Ashbrook, Daniel},
title = {ClipWidgets: 3D-printed Modular Tangible UI Extensions for Smartphones},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3501314},
doi = {10.1145/3490149.3501314},
abstract = {Touchscreens provide a platform for adaptable and versatile user interfaces making them a popular choice for modern smart devices. However, touchscreens lack physicality. Existing solutions to add tangible user interfaces to smart devices often require complicated assembly or occlude part of the touchscreen. We propose ClipWidgets: 3D-printed modular tangible UI extensions for smartphones. ClipWidgets uses a conical mirror and a custom phone case to redirect the field of view of the rear camera of a smartphone to the phone¡¯s periphery. This allows the phone to optically sense input from modular passive 3D-printed widgets that are attached to the phone case. We developed three different widget types (button, dial and slider) that require minimal calibration and minimal assembly. To demonstrate the functionality of ClipWidgets we used it to prototype three different applications: a game controller, a music interface and an interactive graph tool.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {8},
numpages = {11},
keywords = {3D printing, Mobile Computing, Prototyping, User Interfaces},
location = {Daejeon, Republic of Korea},
series = {TEI '22}
}",ClipWidgets 3D-printed Modular Tangible UI Extensions for Smartphones,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A dial,Planar surface,The bottom surface of dial,One-handed,Rotating,Rotating the dial orientation on desktop for adjusting the value of variables.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D equation,The function image displayed on the mobile device screen.,2D display,Use a plate to adjust a 2D equation by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The slider is near the mobile device.
2. The slider is discrete from the 2D visualization.
3. The 2D visualization is on the mobile device."
32,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2148131.2148191,"Hausen, Doris and Boring, Sebastian and Lueling, Clara and Rodestock, Simone and Butz, Andreas","@inproceedings{10.1145/2148131.2148191,
author = {Hausen, Doris and Boring, Sebastian and Lueling, Clara and Rodestock, Simone and Butz, Andreas},
title = {StaTube: facilitating state management in instant messaging systems},
year = {2012},
isbn = {9781450311748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2148131.2148191},
doi = {10.1145/2148131.2148191},
abstract = {Instant messaging systems, such as Skype, offer text, audio and video channels for one-on-one and group conversations, both for personal and professional communication. They are commonly used at a distance, i.e., across countries and continents. To avoid disrupting other tasks, they display personal states to signal others when to contact someone and when not. This mechanism, however, heavily relies on users setting their own state correctly. In an online survey with 46 participants we found that neglecting state updates leads to unwanted messages, either because the state is incorrect or others disrespect it because they assume it to be wrong anyway. We address this situation with the StaTube, a tangible object offering (1) peripheral interaction for setting one's own state and (2) peripheral awareness of selected others' state. In an in-situ evaluation we found first indicators that (1) peripheral interaction fosters more frequent state updates and more accurate state information, and (2) that our participants felt more aware of their contacts' states due to the physical ambient representation.},
booktitle = {Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction},
pages = {283¨C290},
numpages = {8},
keywords = {tangible, peripheral interaction, instant messaging, ambient information},
location = {Kingston, Ontario, Canada},
series = {TEI '12}
}",StaTube: facilitating state management in instant messaging systems,,Large,Single,A tangible widget,N/A,Rigid,No use,Plate,A flattened cylinder,Planar surface,The bottom surface of flattened cylinder,One-handed,Rotating,Rotating the flattened cylinder orientation on desktop for adjusting the mode of state.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,Other,System,The state of the system.,Other,Use a plate to adjust a system by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Other,N/A.,Discrete,N/A.
33,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3024969.3025005,"Manshaei, Roozbeh and Baig, Nauman and Delong, Sean and Khayyer, Shahin and East, Brien and Mazalek, Ali","@inproceedings{10.1145/3024969.3025005,
author = {Manshaei, Roozbeh and Baig, Nauman and Delong, Sean and Khayyer, Shahin and East, Brien and Mazalek, Ali},
title = {Tangible mtDNA: A Tangible Tabletop System for Exploring Genetic Mutations on Mitochondrial DNA Cancer Data},
year = {2017},
isbn = {9781450346764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3024969.3025005},
doi = {10.1145/3024969.3025005},
abstract = {Rapid growth in the volume of cancer DNA sequencing data has not been matched by an increase in our ability to understand, explore, and interpret this data. There is a need for new tools that can enhance analyses in order to enable us to interpret the data, discover new or unexpected information, and ultimately form insights. We present Tangible mtDNA, an active tangible and tabletop system that allows multiple users with diverse expertise to collaborate in exploring and understanding mitochondrial DNA sequencing data in breast cancer patients. Five expert biologists evaluated the system and found it to be effective for data exploration and useful in supporting understanding, collaboration and discussion of DNA datasets.},
booktitle = {Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {101¨C110},
numpages = {10},
keywords = {visualization, tangible interaction, tabletop interaction, genetic mutations, exploration., collaboration, clinicopathological features, cancer, bioinformatics, active tangibles},
location = {Yokohama, Japan},
series = {TEI '17}
}",Tangible mtDNA: A Tangible Tabletop System for Exploring Genetic Mutations on Mitochondrial DNA Cancer Data,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A flattened cylinder,Body,A flattened cylinder,One-handed,Shaking,Shaking a flattened cylinder in space for clearing the selected genetic data using for the 2D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,2D,2D doughnut chart,The information of the 2D visualization of selected genetic data displaced on the desktop screen.,2D display,Use a plate to modulate a 2D doughnut chart by shaking.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The flattened cylinder is in user's hand.
2. The flattened cylinder is discrete from the 2D visualization.
3. The 2D visualization is on the desktop."
33,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3024969.3025005,"Manshaei, Roozbeh and Baig, Nauman and Delong, Sean and Khayyer, Shahin and East, Brien and Mazalek, Ali","@inproceedings{10.1145/3024969.3025005,
author = {Manshaei, Roozbeh and Baig, Nauman and Delong, Sean and Khayyer, Shahin and East, Brien and Mazalek, Ali},
title = {Tangible mtDNA: A Tangible Tabletop System for Exploring Genetic Mutations on Mitochondrial DNA Cancer Data},
year = {2017},
isbn = {9781450346764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3024969.3025005},
doi = {10.1145/3024969.3025005},
abstract = {Rapid growth in the volume of cancer DNA sequencing data has not been matched by an increase in our ability to understand, explore, and interpret this data. There is a need for new tools that can enhance analyses in order to enable us to interpret the data, discover new or unexpected information, and ultimately form insights. We present Tangible mtDNA, an active tangible and tabletop system that allows multiple users with diverse expertise to collaborate in exploring and understanding mitochondrial DNA sequencing data in breast cancer patients. Five expert biologists evaluated the system and found it to be effective for data exploration and useful in supporting understanding, collaboration and discussion of DNA datasets.},
booktitle = {Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {101¨C110},
numpages = {10},
keywords = {visualization, tangible interaction, tabletop interaction, genetic mutations, exploration., collaboration, clinicopathological features, cancer, bioinformatics, active tangibles},
location = {Yokohama, Japan},
series = {TEI '17}
}",Tangible mtDNA: A Tangible Tabletop System for Exploring Genetic Mutations on Mitochondrial DNA Cancer Data,,Small,Double,Two tangible widgets,N/A,Rigid,No use,Plate,Two flattened cylinders,Body,Two flattened cylinders,Asymmetric,Positioning,Moving a flattened cylinder to stack on top of another flattened cylinder on desktop for comparing the 2D visualization.,on the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Replacing,2D,2D doughnut chart,The information of the 2D visualization of genetic data for comparison displaced on the desktop screen.,2D display,Use two plates to adjust a 2D doughnut chart by coordinated positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The flattened cylinders are on the desktop.
2. The 2D visualization is aligned with the flattened cylinder.
3. The 2D visualization is on the desktop."
34,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2148131.2148167,"Riedenklau, Eckard and Hermann, Thomas and Ritter, Helge","@inproceedings{10.1145/2148131.2148167,
author = {Riedenklau, Eckard and Hermann, Thomas and Ritter, Helge},
title = {An integrated multi-modal actuated tangible user interface for distributed collaborative planning},
year = {2012},
isbn = {9781450311748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2148131.2148167},
doi = {10.1145/2148131.2148167},
abstract = {In this paper we showcase an integrative approach for our actuated Tangible Active Objects (TAOs), that demonstrates distributed collaboration support to become a versatile and comprehensive dynamic user interface with multi-modal feedback. We incorporated physical actuation, visual projection in 2D and 3D, and vibro-tactile feedback. We demonstrate this approach in a furniture placing scenario where the users can interactively change the furniture model represented by each TAO using a dial-based tangible actuated menu. We demonstrate virtual constraints between our TAOs to automatically maintain spatial relations.},
booktitle = {Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction},
pages = {169¨C174},
numpages = {6},
keywords = {virtual constraints, tangible interaction, remote collaboration, multimodal feedback, mixed-reality, actuated tangible objects},
location = {Kingston, Ontario, Canada},
series = {TEI '12}
}",An integrated multi-modal actuated tangible user interface for distributed collaborative planning,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A flattened cylinder,Planar surface,The bottom surface of flattened cylinder,One-handed,Rotating,Rotating a flattened cylinder orientation on desktop for selecting the furniture in list for adding.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Looking up,2D,2D graphic,The furniture used to add picture displayed on the desktop projection.,2D display,Use a plate to lookup a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The flattened cylinder is on the desktop.
2. The 2D graphic is aligned with the flattened cylinder.
3. The 2D graphic is on the desktop."
35,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2460625.2460677,"Pla, Pol and Maes, Pattie","@inproceedings{10.1145/2460625.2460677,
author = {Pla, Pol and Maes, Pattie},
title = {Display blocks: a set of cubic displays for tangible, multi-perspective data exploration},
year = {2013},
isbn = {9781450318983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460625.2460677},
doi = {10.1145/2460625.2460677},
abstract = {This paper details the design and implementation of a new type of display technology. Display Blocks are a response to two major limitations of current displays: dimensional compression and physical-digital disconnect. Each Display Block consists of six organic light emitting diode (OLED) screens, arranged in a cubic form factor. We explore the possibilities that this type of display holds for data visualization, manipulation and exploration. To this end, we accompany our design with a set of initial applications that leverage the form factor of the displays. We hope that this work shows the promise of display technologies which use their form factor as a cue to understanding their content.},
booktitle = {Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction},
pages = {307¨C314},
numpages = {8},
keywords = {cubic display, data visualization, display technology, physical interaction, tangible exploration},
location = {Barcelona, Spain},
series = {TEI '13}
}","Display blocks: a set of cubic displays for tangible, multi-perspective data exploration",,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A display block,Body,A display block,One-handed,Shaking,Shaking the display block in space for adjusting the currently displayed application.,in the room space,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Adjusting,3D,3D graphic,The projected image of the 3D graphic of currently displayed application displayed on the display block screen.,2D display,Use a polyhedron to adjust a 3D graphic by shaking.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Embedded,"1. The display block is in user's hand.
2. The 3D graphic is embedded with the display block.
3. The 3D graphic is on the mobile device."
36,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2148131.2148174,"Aceituno, Jonathan and Castet, Julien and Desainte-Catherine, Myriam and Hachet, Martin","@inproceedings{10.1145/2148131.2148174,
author = {Aceituno, Jonathan and Castet, Julien and Desainte-Catherine, Myriam and Hachet, Martin},
title = {Improvised interfaces for real-time musical applications},
year = {2012},
isbn = {9781450311748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2148131.2148174},
doi = {10.1145/2148131.2148174},
abstract = {Computers offer a wealth of promises for real-time musical control. One of them is to enable musicians to change the structure of their instruments in the same time they are playing them, allowing them to adapt their tools to their wills and needs. Few interaction styles provide enough freedom to achieve this. Improvised interfaces are tangible interfaces made out of found objects and tailored by their users. We propose to take advantage of these improvised interfaces to turn the surrounding physical environment into a dynamic musical instrument with tremendous possibilities. Methods dealing with design issues are presented and an implementation of this novel approach is described.},
booktitle = {Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction},
pages = {197¨C200},
numpages = {4},
keywords = {augmented reality, dynamic configuration, improvised interfaces, musical control, physical model, tangible interaction},
location = {Kingston, Ontario, Canada},
series = {TEI '12}
}",Improvised interfaces for real-time musical applications,,Small,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",No use,Plate,A card,Body,A card,One-handed,Shaking,Shaking the card in space for adjusting the mode of system.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Adjusting,Other,System,The mode of the system.,2D display,Use a plate to adjust a system by shaking.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Other,N/A.,Discrete,N/A.
37,TEI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2460625.2460661,"Kasahara, Shunichi and Niiyama, Ryuma and Heun, Valentin and Ishii, Hiroshi","@inproceedings{10.1145/2460625.2460661,
author = {Kasahara, Shunichi and Niiyama, Ryuma and Heun, Valentin and Ishii, Hiroshi},
title = {exTouch: spatially-aware embodied manipulation of actuated objects mediated by augmented reality},
year = {2013},
isbn = {9781450318983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460625.2460661},
doi = {10.1145/2460625.2460661},
abstract = {As domestic robots and smart appliances become increasingly common, they require a simple, universal interface to control their motion. Such an interface must support a simple selection of a connected device, highlight its capabilities and allow for an intuitive manipulation. We propose ""exTouch"", an embodied spatially-aware approach to touch and control devices through an augmented reality mediated mobile interface. The ""exTouch"" system extends the users touchscreen interactions into the real world by enabling spatial control over the actuated object. When users touch a device shown in live video on the screen, they can change its position and orientation through multi-touch gestures or by physically moving the screen in relation to the controlled object. We demonstrate that the system can be used for applications such as an omnidirectional vehicle, a drone, and moving furniture for reconfigurable room.},
booktitle = {Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction},
pages = {223¨C228},
numpages = {6},
keywords = {augmented reality, direct manipulation, embodied interactions, spatially aware interface, tangible interfaces},
location = {Barcelona, Spain},
series = {TEI '13}
}",exTouch: spatially-aware embodied manipulation of actuated objects mediated by augmented reality,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A handheld tablet,Body,A handheld tablet,Symmetric,Positioning+Rotating,Moving the handheld tablet in space to translate and rotate the 3D graphic for manipulating.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D graphic,The position and rotation of the 3D graphic displayed in the augmented reality (screen).,Augmented reality,Use a plate to translate/rotate/scale a 3D graphic by two-handed positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The handheld tablet is in user's hand.
2. The handheld tablet is discrete from the 3D graphic.
3. The 3D graphic is on the desktop or in the room."
38,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1753846.1753903,"Jord\`{a}, Sergi","@inproceedings{10.1145/1753846.1753903,
author = {Jord\`{a}, Sergi},
title = {The reactable: tangible and tabletop music performance},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1753903},
doi = {10.1145/1753846.1753903},
abstract = {In this paper we present the Reactable, a new electronic musical instrument with a simple and intuitive tabletop interface that turns music into a tangible and visual experience, enabling musicians to experiment with sound, change its structure, control its parameters and be creative in a direct, refreshing and unseen way.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {2989¨C2994},
numpages = {6},
keywords = {music performance, musical instruments, reactable, reactivision, tabletop interfaces, tangible interaction},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}",The reactable: tangible and tabletop music performance,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,An acrylic puck,Planar surface,The bottom surface of acrylic puck,One-handed,Rotating,Rotating the acrylic puck orientation on desktop for adjusting a music parameter.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,Other,Audio,The music played by the musician.,2D display,Use a plate to adjust an audio by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The puck is on the desktop.
2. The puck is discrete from the audio player.
3. The audio player is in the room."
39,CHI EA,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1753846.1754081,"Lee, Jinha and Ishii, Hiroshi","@inproceedings{10.1145/1753846.1754081,
author = {Lee, Jinha and Ishii, Hiroshi},
title = {Beyond: collapsible tools and gestures for computational design},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1754081},
doi = {10.1145/1753846.1754081},
abstract = {Since the invention of the personal computer, digital media has remained separate from the physical world, blocked by a rigid screen. In this paper, we present Beyond, an interface for 3-D design where users can directly manipulate digital media with physically retractable tools and hand gestures. When pushed onto the screen, these tools physically collapse and project themselves onto the screen, letting users perceive as if they were inserting the tools into the digital space beyond the screen. The aim of Beyond is to make the digital 3-D design process straightforward, and more accessible to general users by extending physical affordances to the digital space beyond the computer screen.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {3931¨C3936},
numpages = {6},
keywords = {3D interaction, augmented reality, haptic UI, pen input, tactile UI, tangible UI},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}",Beyond: collapsible tools and gestures for computational design,,Small,Single,A tangible widget,N/A,Stretchable,Stretchable,Slender body,A collapsible pen or saw,Straight edge,The tip's motion path,One-handed,Shaping,Strecthing the pen or saw on desktop for adjusting the input depth.,on the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,3D,3D graphic,The position of the 3D graphic displayed on the desktop screen.,2D display,Use a slender body to adjust a 3D graphic by shaping.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The pen is in user's hand.
2. The tip's motion path is crossed over the 3D graphic.
3. The 3D graphic is away from the user."
40,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3613904.3642740,"He, Shuqi and Yao, Haonan and Jiang, Luyan and Li, Kaiwen and Xiang, Nan and Li, Yue and Liang, Hai-Ning and Yu, Lingyun","@inproceedings{10.1145/3613904.3642740,
author = {He, Shuqi and Yao, Haonan and Jiang, Luyan and Li, Kaiwen and Xiang, Nan and Li, Yue and Liang, Hai-Ning and Yu, Lingyun},
title = {Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642740},
doi = {10.1145/3613904.3642740},
abstract = {Tangible interfaces in mixed reality (MR) environments allow for intuitive data interactions. Tangible cubes, with their rich interaction affordances, high maneuverability, and stable structure, are particularly well-suited for exploring multi-dimensional data types. However, the design potential of these cubes is underexplored. This study introduces a design space for tangible cubes in MR, focusing on interaction space, visualization space, sizes, and multiplicity. Using spatio-temporal data, we explored the interaction affordances of these cubes in a workshop (N=24). We identified unique interactions like rotating, tapping, and stacking, which are linked to augmented reality (AR) visualization commands. Integrating user-identified interactions, we created a design space for tangible-cube interactions and visualization. A prototype visualizing global health spending with small cubes was developed and evaluated, supporting both individual and combined cube manipulation. This research enhances our grasp of tangible interaction in MR, offering insights for future design and application in diverse data contexts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {209},
numpages = {21},
keywords = {mixed reality, spatio-temporal data, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '24}
}",Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality,,Small,Single,A tangible widget,N/A,"Rigid, Reconfigurable",No use,Polyhedron,A cube (edge lengths around 10 cm),Body,A cube (edge lengths around 10 cm),One-handed,Rotating,Rotating/flipping the cube orientation on desktop for switching visualization types.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Replacing,3D,3D bar chart+3D heatmap,The representation type of the 3D visualization displayed in the augmented reality (HMD).,Augmented reality,Use a polyhedron to replace a 3D bar chart+3D heatmap by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,"Aligned,Discrete","1. The cube is on the desktop.
2. The 3D visualization is aligned with (dynamic)/discrete from (anchored) the cube.
3. The 3D visualizations are above the cube (dynamic) or on the desktop (anchored)."
40,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3613904.3642740,"He, Shuqi and Yao, Haonan and Jiang, Luyan and Li, Kaiwen and Xiang, Nan and Li, Yue and Liang, Hai-Ning and Yu, Lingyun","@inproceedings{10.1145/3613904.3642740,
author = {He, Shuqi and Yao, Haonan and Jiang, Luyan and Li, Kaiwen and Xiang, Nan and Li, Yue and Liang, Hai-Ning and Yu, Lingyun},
title = {Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642740},
doi = {10.1145/3613904.3642740},
abstract = {Tangible interfaces in mixed reality (MR) environments allow for intuitive data interactions. Tangible cubes, with their rich interaction affordances, high maneuverability, and stable structure, are particularly well-suited for exploring multi-dimensional data types. However, the design potential of these cubes is underexplored. This study introduces a design space for tangible cubes in MR, focusing on interaction space, visualization space, sizes, and multiplicity. Using spatio-temporal data, we explored the interaction affordances of these cubes in a workshop (N=24). We identified unique interactions like rotating, tapping, and stacking, which are linked to augmented reality (AR) visualization commands. Integrating user-identified interactions, we created a design space for tangible-cube interactions and visualization. A prototype visualizing global health spending with small cubes was developed and evaluated, supporting both individual and combined cube manipulation. This research enhances our grasp of tangible interaction in MR, offering insights for future design and application in diverse data contexts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {209},
numpages = {21},
keywords = {mixed reality, spatio-temporal data, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '24}
}",Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality,,Small,Double,Two tangible widgets,N/A,"Rigid, Reconfigurable",No use,Polyhedron,Two cubes (edge lengths around 10 cm),Body,Two cubes (edge lengths around 10 cm),Asymmetric,Positioning,Neighboring or stacking the cubes on desktop/in space for combining the visualizations.,"on the horizontal surface,above the horizontal surface","Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane./Physical widget: 3DOF translation and 3DOF rotation in the space.,Replacing,3D,3D bar chart+3D heatmap,The representation of combining data of the 3D visualization displayed in the augmented reality (HMD).,Augmented reality,Use two polyhedrons to replace a 3D bar chart+3D heatmap by coordinated positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,"Aligned,Discrete","1. The cube is on the desktop/in user's hand.
2. The 3D visualization is aligned with (dynamic)/discrete from (anchored) the cube.
3. The 3D visualizations are above the cube (dynamic) or on the desktop (anchored)."
40,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3613904.3642740,"He, Shuqi and Yao, Haonan and Jiang, Luyan and Li, Kaiwen and Xiang, Nan and Li, Yue and Liang, Hai-Ning and Yu, Lingyun","@inproceedings{10.1145/3613904.3642740,
author = {He, Shuqi and Yao, Haonan and Jiang, Luyan and Li, Kaiwen and Xiang, Nan and Li, Yue and Liang, Hai-Ning and Yu, Lingyun},
title = {Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642740},
doi = {10.1145/3613904.3642740},
abstract = {Tangible interfaces in mixed reality (MR) environments allow for intuitive data interactions. Tangible cubes, with their rich interaction affordances, high maneuverability, and stable structure, are particularly well-suited for exploring multi-dimensional data types. However, the design potential of these cubes is underexplored. This study introduces a design space for tangible cubes in MR, focusing on interaction space, visualization space, sizes, and multiplicity. Using spatio-temporal data, we explored the interaction affordances of these cubes in a workshop (N=24). We identified unique interactions like rotating, tapping, and stacking, which are linked to augmented reality (AR) visualization commands. Integrating user-identified interactions, we created a design space for tangible-cube interactions and visualization. A prototype visualizing global health spending with small cubes was developed and evaluated, supporting both individual and combined cube manipulation. This research enhances our grasp of tangible interaction in MR, offering insights for future design and application in diverse data contexts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {209},
numpages = {21},
keywords = {mixed reality, spatio-temporal data, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '24}
}",Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality,,Small,Single,A tangible widget,N/A,"Rigid, Reconfigurable",No use,Polyhedron,A cube (edge lengths around 10 cm),Body,A cube (edge lengths around 10 cm),One-handed,Shaking,Shaking the cube in space for reseting the selected data.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,3D,3D bar chart+3D heatmap,The selected data of the 3D visualization displayed in the augmented reality (HMD).,Augmented reality,Use a polyhedron to modulate a 3D bar chart+3D heatmap by shaking.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,"Aligned,Discrete","1. The cube is in user's hand.
2. The 3D visualization is aligned with (dynamic)/discrete from (anchored) the cube.
3. The 3D visualizations are above the cube (dynamic) or on the desktop (anchored)."
40,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3613904.3642740,"He, Shuqi and Yao, Haonan and Jiang, Luyan and Li, Kaiwen and Xiang, Nan and Li, Yue and Liang, Hai-Ning and Yu, Lingyun","@inproceedings{10.1145/3613904.3642740,
author = {He, Shuqi and Yao, Haonan and Jiang, Luyan and Li, Kaiwen and Xiang, Nan and Li, Yue and Liang, Hai-Ning and Yu, Lingyun},
title = {Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642740},
doi = {10.1145/3613904.3642740},
abstract = {Tangible interfaces in mixed reality (MR) environments allow for intuitive data interactions. Tangible cubes, with their rich interaction affordances, high maneuverability, and stable structure, are particularly well-suited for exploring multi-dimensional data types. However, the design potential of these cubes is underexplored. This study introduces a design space for tangible cubes in MR, focusing on interaction space, visualization space, sizes, and multiplicity. Using spatio-temporal data, we explored the interaction affordances of these cubes in a workshop (N=24). We identified unique interactions like rotating, tapping, and stacking, which are linked to augmented reality (AR) visualization commands. Integrating user-identified interactions, we created a design space for tangible-cube interactions and visualization. A prototype visualizing global health spending with small cubes was developed and evaluated, supporting both individual and combined cube manipulation. This research enhances our grasp of tangible interaction in MR, offering insights for future design and application in diverse data contexts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {209},
numpages = {21},
keywords = {mixed reality, spatio-temporal data, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '24}
}",Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality,,Small,Single,A tangible widget,N/A,"Rigid, Reconfigurable",No use,Polyhedron,A cube (edge lengths around 10 cm),Body,A cube (edge lengths around 10 cm),One-handed,Positioning,Moving the cube on desktop for selecting the data.,on the horizontal surface,"Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane.,Looking up,3D,3D bar chart+3D heatmap,The selected data of the 3D visualization displayed in the augmented reality (HMD).,Augmented reality,Use a polyhedron to lookup a 3D bar chart+3D heatmap by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,"Aligned,Discrete","1. The cube is on the desktop.
2. The 3D visualization is aligned with (dynamic)/discrete from (anchored) the cube.
3. The 3D visualizations are above the cube (dynamic) or on the desktop (anchored)."
41,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3613904.3642734,"Campos Zamora, Daniel and Dogan, Mustafa Doga and Siu, Alexa F and Koh, Eunyee and Xiao, Chang","@inproceedings{10.1145/3613904.3642734,
author = {Campos Zamora, Daniel and Dogan, Mustafa Doga and Siu, Alexa F and Koh, Eunyee and Xiao, Chang},
title = {Moir\'{e}Widgets: High-Precision, Passive Tangible Interfaces via Moir\'{e} Effect},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642734},
doi = {10.1145/3613904.3642734},
abstract = {We introduce Moir\'{e}Widgets, a novel approach for tangible interaction that harnesses the Moir\'{e} effect¡ªa prevalent optical phenomenon¡ªto enable high-precision event detection on physical widgets. Unlike other electronics-free tangible user interfaces which require close coupling with external hardware, Moir\'{e}Widgets can be used at greater distances while maintaining high-resolution sensing of interactions. We define a set of interaction primitives, e.g., buttons, sliders, and dials, which can be used as standalone objects or combined to build complex physical controls. These consist of 3D printed structural mechanisms with patterns printed on two layers¡ªone on paper and the other on a plastic transparency sheet¡ªwhich create a visual signal that amplifies subtle movements, enabling the detection of user inputs. Our technical evaluation shows that our method outperforms standard fiducial markers and maintains sub-millimeter accuracy at 100&nbsp;cm distance and wide viewing angles. We demonstrate our approach by creating an audio console and indicate how our approach could extend to other domains.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {329},
numpages = {10},
keywords = {Fabrication, Moir\'{e} Effect, Moir\'{e} Pattern, Tangible Interaction, Vision-Based Sensing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}","Moir\'eWidgets: High-Precision, Passive Tangible Interfaces via Moir\'e Effect",,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A cubic button,Straight edge,The cubic button's motion path,One-handed,Positioning,Moving the cubic button up or down on desktop for adjusting the state of playing audio.,on the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,Other,Audio,The status of the audio played by the system.,Augmented reality,Use a polyhedron to adjust an audio by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The button is on the desktop.
2. The button is discrete from the audio player.
3. The audio player is in the room."
41,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3613904.3642734,"Campos Zamora, Daniel and Dogan, Mustafa Doga and Siu, Alexa F and Koh, Eunyee and Xiao, Chang","@inproceedings{10.1145/3613904.3642734,
author = {Campos Zamora, Daniel and Dogan, Mustafa Doga and Siu, Alexa F and Koh, Eunyee and Xiao, Chang},
title = {Moir\'{e}Widgets: High-Precision, Passive Tangible Interfaces via Moir\'{e} Effect},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642734},
doi = {10.1145/3613904.3642734},
abstract = {We introduce Moir\'{e}Widgets, a novel approach for tangible interaction that harnesses the Moir\'{e} effect¡ªa prevalent optical phenomenon¡ªto enable high-precision event detection on physical widgets. Unlike other electronics-free tangible user interfaces which require close coupling with external hardware, Moir\'{e}Widgets can be used at greater distances while maintaining high-resolution sensing of interactions. We define a set of interaction primitives, e.g., buttons, sliders, and dials, which can be used as standalone objects or combined to build complex physical controls. These consist of 3D printed structural mechanisms with patterns printed on two layers¡ªone on paper and the other on a plastic transparency sheet¡ªwhich create a visual signal that amplifies subtle movements, enabling the detection of user inputs. Our technical evaluation shows that our method outperforms standard fiducial markers and maintains sub-millimeter accuracy at 100&nbsp;cm distance and wide viewing angles. We demonstrate our approach by creating an audio console and indicate how our approach could extend to other domains.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {329},
numpages = {10},
keywords = {Fabrication, Moir\'{e} Effect, Moir\'{e} Pattern, Tangible Interaction, Vision-Based Sensing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}","Moir\'eWidgets: High-Precision, Passive Tangible Interfaces via Moir\'e Effect",,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A dial,Planar surface,The bottom surface of dial,One-handed,Rotating,Rotating a dial orientation on desktop for adjusting the audio speed.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,Other,Audio,The speed of the audio played by the system.,Augmented reality,Use a plate to adjust an audio by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The dial is on the desktop.
2. The dial is discrete from the audio player.
3. The audio player is in the room."
41,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3613904.3642734,"Campos Zamora, Daniel and Dogan, Mustafa Doga and Siu, Alexa F and Koh, Eunyee and Xiao, Chang","@inproceedings{10.1145/3613904.3642734,
author = {Campos Zamora, Daniel and Dogan, Mustafa Doga and Siu, Alexa F and Koh, Eunyee and Xiao, Chang},
title = {Moir\'{e}Widgets: High-Precision, Passive Tangible Interfaces via Moir\'{e} Effect},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642734},
doi = {10.1145/3613904.3642734},
abstract = {We introduce Moir\'{e}Widgets, a novel approach for tangible interaction that harnesses the Moir\'{e} effect¡ªa prevalent optical phenomenon¡ªto enable high-precision event detection on physical widgets. Unlike other electronics-free tangible user interfaces which require close coupling with external hardware, Moir\'{e}Widgets can be used at greater distances while maintaining high-resolution sensing of interactions. We define a set of interaction primitives, e.g., buttons, sliders, and dials, which can be used as standalone objects or combined to build complex physical controls. These consist of 3D printed structural mechanisms with patterns printed on two layers¡ªone on paper and the other on a plastic transparency sheet¡ªwhich create a visual signal that amplifies subtle movements, enabling the detection of user inputs. Our technical evaluation shows that our method outperforms standard fiducial markers and maintains sub-millimeter accuracy at 100&nbsp;cm distance and wide viewing angles. We demonstrate our approach by creating an audio console and indicate how our approach could extend to other domains.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {329},
numpages = {10},
keywords = {Fabrication, Moir\'{e} Effect, Moir\'{e} Pattern, Tangible Interaction, Vision-Based Sensing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}","Moir\'eWidgets: High-Precision, Passive Tangible Interfaces via Moir\'e Effect",,Small,Single,A tangible widget,N/A,Rigid,No use,Constrained body,A slider,Straight edge,The slider's motion path,One-handed,Positioning,Sliding the slider on desktop for adjusting the audio volume.,on the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Adjusting,Other,Audio,The volume of the audio played by the system.,Augmented reality,Use a constrained body to adjust an audio by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The slider is on the desktop.
2. The slider is discrete from the audio player.
3. The audio player is in the room."
42,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3411764.3445404,"Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier","@inproceedings{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
doi = {10.1145/3411764.3445404},
abstract = {Tangibles can enrich interaction with digital surfaces. Among others, they support eyes-free control or increase awareness of other users¡¯ actions. Tangibles have been studied in combination with horizontal surfaces such as tabletops, but not with vertical screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be placed on such surfaces without falling. We present WallTokens, easy-to-fabricate tangibles to interact with a vertical surface. A WallToken is a passive token whose footprint is recognized on a tactile surface. It is equipped with a push-handle that controls a suction cup. This makes it easy for users to switch between sliding the token or attaching it to the wall. We describe how to build such tokens and how to recognize them on a tactile surface. We report on a study showing the benefits of WallTokens for manipulating virtual objects over multi-touch gestures. This project is a step towards enabling tangible interaction in a wall display context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Fabrication, Tangible Interaction, Tokens, Wall-sized display},
location = {Yokohama, Japan},
series = {CHI '21}
}",WallTokens: Surface Tangibles for Vertical Displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A 3D printed assembly object,Planar surface,The bottom surface of assembly object,One-handed,Positioning,Locating the assembly object on wall for displaying a graphic at a position in the plane.,on the vertical surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D graphic,The image of the 2D graphic displayed on the wall screen.,2D display,Use a spheroid to modulate a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The assembly object is on the wall.
2. The assembly object is aligned with the 2D graphic.
3. The 2D graphic is displayed on the wall."
42,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3411764.3445404,"Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier","@inproceedings{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
doi = {10.1145/3411764.3445404},
abstract = {Tangibles can enrich interaction with digital surfaces. Among others, they support eyes-free control or increase awareness of other users¡¯ actions. Tangibles have been studied in combination with horizontal surfaces such as tabletops, but not with vertical screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be placed on such surfaces without falling. We present WallTokens, easy-to-fabricate tangibles to interact with a vertical surface. A WallToken is a passive token whose footprint is recognized on a tactile surface. It is equipped with a push-handle that controls a suction cup. This makes it easy for users to switch between sliding the token or attaching it to the wall. We describe how to build such tokens and how to recognize them on a tactile surface. We report on a study showing the benefits of WallTokens for manipulating virtual objects over multi-touch gestures. This project is a step towards enabling tangible interaction in a wall display context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Fabrication, Tangible Interaction, Tokens, Wall-sized display},
location = {Yokohama, Japan},
series = {CHI '21}
}",WallTokens: Surface Tangibles for Vertical Displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A 3D printed assembly object,Planar surface,The bottom surface of assembly object,One-handed,Positioning,Locating the assembly object on wall for selecting a graphic at a position in the plane.,on the vertical surface,Position,Physical widget: 2DOF translation in the plane.,Looking up,2D,2D graphic,The image of the 2D graphic displayed on the wall screen.,2D display,Use a spheroid to lookup a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The assembly object is on the wall.
2. The assembly object is aligned with the 2D graphic.
3. The 2D graphic is displayed on the wall."
42,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3411764.3445404,"Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier","@inproceedings{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
doi = {10.1145/3411764.3445404},
abstract = {Tangibles can enrich interaction with digital surfaces. Among others, they support eyes-free control or increase awareness of other users¡¯ actions. Tangibles have been studied in combination with horizontal surfaces such as tabletops, but not with vertical screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be placed on such surfaces without falling. We present WallTokens, easy-to-fabricate tangibles to interact with a vertical surface. A WallToken is a passive token whose footprint is recognized on a tactile surface. It is equipped with a push-handle that controls a suction cup. This makes it easy for users to switch between sliding the token or attaching it to the wall. We describe how to build such tokens and how to recognize them on a tactile surface. We report on a study showing the benefits of WallTokens for manipulating virtual objects over multi-touch gestures. This project is a step towards enabling tangible interaction in a wall display context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Fabrication, Tangible Interaction, Tokens, Wall-sized display},
location = {Yokohama, Japan},
series = {CHI '21}
}",WallTokens: Surface Tangibles for Vertical Displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A 3D printed assembly object,Planar surface,The bottom surface of assembly object,One-handed,Positioning,Moving the assembly object on wall for translating the 2D map.,on the vertical surface,Position,Physical widget: 2DOF translation in the plane.,Navigating,2D,2D map,The viewpoint position of the 2D map displayed on the wall screen.,2D display,Use a spheroid to navigate a 2D map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The assembly object is on the wall.
2. The assembly object is aligned with the 2D map.
3. The 2D map is displayed on the wall."
42,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3411764.3445404,"Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier","@inproceedings{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
doi = {10.1145/3411764.3445404},
abstract = {Tangibles can enrich interaction with digital surfaces. Among others, they support eyes-free control or increase awareness of other users¡¯ actions. Tangibles have been studied in combination with horizontal surfaces such as tabletops, but not with vertical screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be placed on such surfaces without falling. We present WallTokens, easy-to-fabricate tangibles to interact with a vertical surface. A WallToken is a passive token whose footprint is recognized on a tactile surface. It is equipped with a push-handle that controls a suction cup. This makes it easy for users to switch between sliding the token or attaching it to the wall. We describe how to build such tokens and how to recognize them on a tactile surface. We report on a study showing the benefits of WallTokens for manipulating virtual objects over multi-touch gestures. This project is a step towards enabling tangible interaction in a wall display context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Fabrication, Tangible Interaction, Tokens, Wall-sized display},
location = {Yokohama, Japan},
series = {CHI '21}
}",WallTokens: Surface Tangibles for Vertical Displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A 3D printed assembly object,Planar surface,The bottom surface of assembly object,One-handed,Rotating,Rotating the assembly object on wall for scaling the 2D map.,on the vertical surface,Rotation,Physical widget: 1DOF rotation in the plane.,Navigating,2D,2D map,The viewpoint scale of the 2D map displayed on the wall screen.,2D display,Use a spheroid to navigate a 2D map by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The assembly object is on the wall.
2. The assembly object is aligned with the 2D map.
3. The 2D map is displayed on the wall."
42,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3411764.3445404,"Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier","@inproceedings{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
doi = {10.1145/3411764.3445404},
abstract = {Tangibles can enrich interaction with digital surfaces. Among others, they support eyes-free control or increase awareness of other users¡¯ actions. Tangibles have been studied in combination with horizontal surfaces such as tabletops, but not with vertical screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be placed on such surfaces without falling. We present WallTokens, easy-to-fabricate tangibles to interact with a vertical surface. A WallToken is a passive token whose footprint is recognized on a tactile surface. It is equipped with a push-handle that controls a suction cup. This makes it easy for users to switch between sliding the token or attaching it to the wall. We describe how to build such tokens and how to recognize them on a tactile surface. We report on a study showing the benefits of WallTokens for manipulating virtual objects over multi-touch gestures. This project is a step towards enabling tangible interaction in a wall display context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Fabrication, Tangible Interaction, Tokens, Wall-sized display},
location = {Yokohama, Japan},
series = {CHI '21}
}",WallTokens: Surface Tangibles for Vertical Displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A 3D printed assembly object,Planar surface,The bottom surface of assembly object,One-handed,Positioning,Locating the assembly object on wall to input a position for displaying the 2D visualization.,on the vertical surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D simulation,The position of the 2D visualization displayed on the wall screen.,2D display,Use a spheroid to modulate a 2D simulation by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The assembly object is on the wall.
2. The assembly object is aligned with the 2D visualization.
3. The 2D visualization is displayed on the wall."
42,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3411764.3445404,"Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier","@inproceedings{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
doi = {10.1145/3411764.3445404},
abstract = {Tangibles can enrich interaction with digital surfaces. Among others, they support eyes-free control or increase awareness of other users¡¯ actions. Tangibles have been studied in combination with horizontal surfaces such as tabletops, but not with vertical screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be placed on such surfaces without falling. We present WallTokens, easy-to-fabricate tangibles to interact with a vertical surface. A WallToken is a passive token whose footprint is recognized on a tactile surface. It is equipped with a push-handle that controls a suction cup. This makes it easy for users to switch between sliding the token or attaching it to the wall. We describe how to build such tokens and how to recognize them on a tactile surface. We report on a study showing the benefits of WallTokens for manipulating virtual objects over multi-touch gestures. This project is a step towards enabling tangible interaction in a wall display context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Fabrication, Tangible Interaction, Tokens, Wall-sized display},
location = {Yokohama, Japan},
series = {CHI '21}
}",WallTokens: Surface Tangibles for Vertical Displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A 3D printed assembly object,Planar surface,The bottom surface of assembly object,One-handed,Rotating,Rotating the assembly object on wall for adjusting the drops falling frequency of the 2D visualization.,on the vertical surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D simulation,The content of the 2D visualization displayed on the wall screen.,2D display,Use a spheroid to adjust a 2D simulation by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The assembly object is on the wall.
2. The assembly object is aligned with the 2D visualization.
3. The 2D visualization is displayed on the wall."
42,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3411764.3445404,"Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier","@inproceedings{10.1145/3411764.3445404,
author = {Courtoux, Emmanuel and Appert, Caroline and Chapuis, Olivier},
title = {WallTokens: Surface Tangibles for Vertical Displays},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445404},
doi = {10.1145/3411764.3445404},
abstract = {Tangibles can enrich interaction with digital surfaces. Among others, they support eyes-free control or increase awareness of other users¡¯ actions. Tangibles have been studied in combination with horizontal surfaces such as tabletops, but not with vertical screens such as wall displays. The obvious obstacle is gravity: tangibles cannot be placed on such surfaces without falling. We present WallTokens, easy-to-fabricate tangibles to interact with a vertical surface. A WallToken is a passive token whose footprint is recognized on a tactile surface. It is equipped with a push-handle that controls a suction cup. This makes it easy for users to switch between sliding the token or attaching it to the wall. We describe how to build such tokens and how to recognize them on a tactile surface. We report on a study showing the benefits of WallTokens for manipulating virtual objects over multi-touch gestures. This project is a step towards enabling tangible interaction in a wall display context.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {421},
numpages = {13},
keywords = {Fabrication, Tangible Interaction, Tokens, Wall-sized display},
location = {Yokohama, Japan},
series = {CHI '21}
}",WallTokens: Surface Tangibles for Vertical Displays,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A 3D printed assembly object,Planar surface,The bottom surface of assembly object,One-handed,Positioning,Locating the assembly object on wall to input a position for waves simulation.,on the vertical surface,Position,Physical widget: 2DOF translation in the plane.,Browsing,2D,2D simulation,The content of the 2D visualization displayed on the wall screen.,2D display,Use a spheroid to browse a 2D simulation by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The assembly object is on the wall.
2. The assembly object is aligned with the 2D visualization.
3. The 2D visualization is displayed on the wall."
43,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3491102.3501829,"Zheng, Clement and Yong, Zhen Zhou and Lin, Hongnan and Oh, HyunJoo and Yen, Ching Chiuan","@inproceedings{10.1145/3491102.3501829,
author = {Zheng, Clement and Yong, Zhen Zhou and Lin, Hongnan and Oh, HyunJoo and Yen, Ching Chiuan},
title = {Shape-Haptics: Planar \& Passive Force Feedback Mechanisms for Physical Interfaces},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501829},
doi = {10.1145/3491102.3501829},
abstract = {We present Shape-Haptics, an approach for designers to rapidly design and fabricate passive force feedback mechanisms for physical interfaces. Such mechanisms are used in everyday interfaces and tools, and they are challenging to design. Shape-Haptics abstracts and broadens the haptic expression of this class of force feedback systems through 2D laser cut configurations that are simple to fabricate. They leverage the properties of polyoxymethylene plastic and comprise a compliant spring structure that engages with a sliding profile during tangible interaction. By shaping the sliding profile, designers can easily customize the haptic force feedback delivered by the mechanism. We provide a computational design sandbox to facilitate designers to explore and fabricate Shape-Haptics mechanisms. We also propose a series of applications that demonstrate the utility of Shape-Haptics in creating and customizing haptics for different physical interfaces.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {171},
numpages = {15},
keywords = {Digital Fabrication, Passive Haptics, Tangible Interactions},
location = {New Orleans, LA, USA},
series = {CHI '22}
}",Shape-Haptics: Planar & Passive Force Feedback Mechanisms for Physical Interfaces,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A knob,Planar surface,The bottom surface of knob,One-handed,Rotating,Rotating a knob orientation on desktop for adjusting the parameter of electronic input.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,Other,System,The parameter of electronic input.,Other,Use a plate to adjust a system by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Other,N/A.,Other,N/A.
43,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3491102.3501829,"Zheng, Clement and Yong, Zhen Zhou and Lin, Hongnan and Oh, HyunJoo and Yen, Ching Chiuan","@inproceedings{10.1145/3491102.3501829,
author = {Zheng, Clement and Yong, Zhen Zhou and Lin, Hongnan and Oh, HyunJoo and Yen, Ching Chiuan},
title = {Shape-Haptics: Planar \& Passive Force Feedback Mechanisms for Physical Interfaces},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501829},
doi = {10.1145/3491102.3501829},
abstract = {We present Shape-Haptics, an approach for designers to rapidly design and fabricate passive force feedback mechanisms for physical interfaces. Such mechanisms are used in everyday interfaces and tools, and they are challenging to design. Shape-Haptics abstracts and broadens the haptic expression of this class of force feedback systems through 2D laser cut configurations that are simple to fabricate. They leverage the properties of polyoxymethylene plastic and comprise a compliant spring structure that engages with a sliding profile during tangible interaction. By shaping the sliding profile, designers can easily customize the haptic force feedback delivered by the mechanism. We provide a computational design sandbox to facilitate designers to explore and fabricate Shape-Haptics mechanisms. We also propose a series of applications that demonstrate the utility of Shape-Haptics in creating and customizing haptics for different physical interfaces.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {171},
numpages = {15},
keywords = {Digital Fabrication, Passive Haptics, Tangible Interactions},
location = {New Orleans, LA, USA},
series = {CHI '22}
}",Shape-Haptics: Planar & Passive Force Feedback Mechanisms for Physical Interfaces,,Small,Single,A tangible widget,N/A,Rigid,No use,Constrained body,A slider,Straight edge,The slider's motion path,One-handed,Positioning,Sliding the slider on desktop for adjusting the parameter of electronic input.,on the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Adjusting,Other,System,The parameter of electronic input.,Other,Use a constrained body to adjust a system by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Other,N/A.,Other,N/A.
44,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3313831.3376139,"Gupta, Aakar and Lin, Bo Rui and Ji, Siyi and Patel, Arjav and Vogel, Daniel","@inproceedings{10.1145/3313831.3376139,
author = {Gupta, Aakar and Lin, Bo Rui and Ji, Siyi and Patel, Arjav and Vogel, Daniel},
title = {Replicate and Reuse: Tangible Interaction Design for Digitally-Augmented Physical Media Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376139},
doi = {10.1145/3313831.3376139},
abstract = {Technology has transformed our physical interactions into infinitely more scalable and flexible digital ones. We can peruse an infinite number of photos, news articles, and books. However, these digital experiences lack the physical experience of paging through an album, reading a newspaper, or meandering through a bookshelf. Overlaying physical objects with digital content using augmented reality is a promising avenue towards bridging this gap. In this paper, we investigate the interaction design for such digital-overlaid physical objects and their varying levels of tangibility. We first conduct a user evaluation of a physical photo album that uses tangible interactions to support physical and digital operations. We further prototype multiple objects including bookshelves and newspapers and probe users on their usage, capabilities, and interactions. We then conduct a qualitative investigation of three interaction designs with varying tangibility that use three different input modalities. Finally, we discuss the insights from our investigations and recommend design guidelines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C12},
numpages = {12},
keywords = {augmented reality, design, physical objects, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}",Replicate and Reuse: Tangible Interaction Design for Digitally-Augmented Physical Media Objects,,Medium,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",No use,Plate,A sheet of paper,Planar surface,A sheet of paper,One-handed,Rotating,Rotating/tilting a paper orientation in space for changing the displayed graphic.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation at the plane of the paper surface in the space.,Modulating,2D,2D graphic,The content of the 2D graphic displayed on the paper.,Augmented reality,Use a plate to modulate a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper is in user's hand.
2. The paper is aligned with the 2D graphic.
3. The 2D graphic is above the desktop."
44,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3313831.3376139,"Gupta, Aakar and Lin, Bo Rui and Ji, Siyi and Patel, Arjav and Vogel, Daniel","@inproceedings{10.1145/3313831.3376139,
author = {Gupta, Aakar and Lin, Bo Rui and Ji, Siyi and Patel, Arjav and Vogel, Daniel},
title = {Replicate and Reuse: Tangible Interaction Design for Digitally-Augmented Physical Media Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376139},
doi = {10.1145/3313831.3376139},
abstract = {Technology has transformed our physical interactions into infinitely more scalable and flexible digital ones. We can peruse an infinite number of photos, news articles, and books. However, these digital experiences lack the physical experience of paging through an album, reading a newspaper, or meandering through a bookshelf. Overlaying physical objects with digital content using augmented reality is a promising avenue towards bridging this gap. In this paper, we investigate the interaction design for such digital-overlaid physical objects and their varying levels of tangibility. We first conduct a user evaluation of a physical photo album that uses tangible interactions to support physical and digital operations. We further prototype multiple objects including bookshelves and newspapers and probe users on their usage, capabilities, and interactions. We then conduct a qualitative investigation of three interaction designs with varying tangibility that use three different input modalities. Finally, we discuss the insights from our investigations and recommend design guidelines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C12},
numpages = {12},
keywords = {augmented reality, design, physical objects, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}",Replicate and Reuse: Tangible Interaction Design for Digitally-Augmented Physical Media Objects,,Medium,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",No use,Plate,A sheet of paper,Planar surface,A sheet of paper,One-handed,Rotating,Flipping a paper in space for displaying graphic in reverse order.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation in the space.,Replacing,2D,2D graphic,The content of the 2D graphic displayed on the paper.,Augmented reality,Use a plate to replace a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper is in user's hand.
2. The paper is aligned with the 2D graphic.
3. The 2D graphic is above the desktop."
45,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3313831.3376613,"Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim","@inproceedings{10.1145/3313831.3376613,
author = {Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim},
title = {Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376613},
doi = {10.1145/3313831.3376613},
abstract = {We present Embodied Axes, a controller which supports selection operations for 3D imagery and data visualisations in Augmented Reality. The device is an embodied representation of a 3D data space -- each of its three orthogonal arms corresponds to a data axis or domain specific frame of reference. Each axis is composed of a pair of tangible, actuated range sliders for precise data selection, and rotary encoding knobs for additional parameter tuning or menu navigation. The motor actuated sliders support alignment to positions of significant values within the data, or coordination with other input: e.g., mid-air gestures in the data space, touch gestures on the surface below the data, or another Embodied Axes device supporting multi-user scenarios. We conducted expert enquiries in medical imaging which provided formative feedback on domain tasks and refinements to the design. Additionally, a controlled user study was performed and found that the Embodied Axes was overall more accurate than conventional tracked controllers for selection tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C12},
numpages = {12},
keywords = {3d visualisation, actuation, augmented reality, device, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}","Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces",,Large,Single,A tangible widget,N/A,Rigid,No use,Constrained body,A slider,Straight edge,The slider's motion path,One-handed,Positioning,Sliding the slider on desktop for adjusting the parameter of system.,on the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Adjusting,2D,2D text,The parameter of the 2D text displayed in the augmented reality (HMD).,Augmented reality,Use a constrained body to adjust a 2D text by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The stick with a slider is on the desktop.
2. The stick with a slider is discrete from the 3D visualization.
3. The 3D visualization is on the desktop."
45,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3313831.3376613,"Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim","@inproceedings{10.1145/3313831.3376613,
author = {Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim},
title = {Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376613},
doi = {10.1145/3313831.3376613},
abstract = {We present Embodied Axes, a controller which supports selection operations for 3D imagery and data visualisations in Augmented Reality. The device is an embodied representation of a 3D data space -- each of its three orthogonal arms corresponds to a data axis or domain specific frame of reference. Each axis is composed of a pair of tangible, actuated range sliders for precise data selection, and rotary encoding knobs for additional parameter tuning or menu navigation. The motor actuated sliders support alignment to positions of significant values within the data, or coordination with other input: e.g., mid-air gestures in the data space, touch gestures on the surface below the data, or another Embodied Axes device supporting multi-user scenarios. We conducted expert enquiries in medical imaging which provided formative feedback on domain tasks and refinements to the design. Additionally, a controlled user study was performed and found that the Embodied Axes was overall more accurate than conventional tracked controllers for selection tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C12},
numpages = {12},
keywords = {3d visualisation, actuation, augmented reality, device, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}","Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces",,Large,Double,A virtual widget+A tangible widget,Fully mapped,Rigid,No use,Constrained body (with Planar surface),A slider (with a virtual cutting plane),Planar surface,A virtual cutting plane,One-handed,Positioning,Sliding the slider on desktop to control a virtual cutting plane for slicing the 3D visualization.,on the horizontal surface,Position,"Virtual widget: 1DOF translation in a constrained direction.
Physical widget: 1DOF translation in a constrained direction.",Clipping,3D,3D medical volume rendering,The clipped 3D visualization of volume data displayed in the augmented reality (HMD).,Augmented reality,Use a planar surface controlled by a constrained body to clip a 3D medical volume rendering by positioning.,Reachable,"Virtual: Not impacted within the accessible distance.
Physical: Interaction is possible only if manipulable entity is grabbed by user.",Reachable,Not impacted within the accessible distance.,Crossed,"1. The stick with a slider is on the desktop.
2. The virtual cutting plane controlled by the stick with a slider is crossed over the 3D visualization.
3. The 3D visualization is on the desktop."
45,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3313831.3376613,"Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim","@inproceedings{10.1145/3313831.3376613,
author = {Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim},
title = {Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376613},
doi = {10.1145/3313831.3376613},
abstract = {We present Embodied Axes, a controller which supports selection operations for 3D imagery and data visualisations in Augmented Reality. The device is an embodied representation of a 3D data space -- each of its three orthogonal arms corresponds to a data axis or domain specific frame of reference. Each axis is composed of a pair of tangible, actuated range sliders for precise data selection, and rotary encoding knobs for additional parameter tuning or menu navigation. The motor actuated sliders support alignment to positions of significant values within the data, or coordination with other input: e.g., mid-air gestures in the data space, touch gestures on the surface below the data, or another Embodied Axes device supporting multi-user scenarios. We conducted expert enquiries in medical imaging which provided formative feedback on domain tasks and refinements to the design. Additionally, a controlled user study was performed and found that the Embodied Axes was overall more accurate than conventional tracked controllers for selection tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C12},
numpages = {12},
keywords = {3d visualisation, actuation, augmented reality, device, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}","Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces",,Large,Single,A tangible widget,N/A,Rigid,No use,Constrained body,A slider,Straight edge,The slider's motion path,One-handed,Positioning,Sliding the slider on desktop for creating a bounding box.,on the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Browsing,3D,3D scatterplot,The position and scale of the bounding box in the 3D scatterplot displaced in the augmented reality (HMD).,Augmented reality,Use a constrained body to browse a 3D scatterplot by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The stick with a slider is on the desktop.
2. The stick with a slider is discrete from the 3D visualization.
3. The 3D visualization is on the desktop."
46,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3313831.3376452,"Son, Kihoon and Chun, Hwiwon and Park, Sojin and Hyun, Kyung Hoon","@inproceedings{10.1145/3313831.3376452,
author = {Son, Kihoon and Chun, Hwiwon and Park, Sojin and Hyun, Kyung Hoon},
title = {C-Space: An Interactive Prototyping Platform for Collaborative Spatial Design Exploration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376452},
doi = {10.1145/3313831.3376452},
abstract = {C-Space is an interactive prototyping platform for collaborative spatial design exploration. Spatial design projects often begin with conceptualization that includes abstract diagramming, zoning, and massing to provide a foundation for making design decisions. Specifically, abstract diagrams guide designers to explore alternative designs without thinking prematurely about the details. However, complications arise when communicating ambiguous and incomplete designs to collaborators. To overcome this drawback, designers devote considerable amounts of time and resources into searching for design references and creating rough prototypes to explicate their design concepts better. Therefore, this study proposes C-Space, a novel design support system that integrates the abstract diagram with design reference retrieval and prototyping through a tangible user interface and augmented reality. Through a user study with 12 spatial designers, we verify that C-Space promotes rapid and robust spatial design exploration, inducing collaborative discussions and motivating users to interact with designs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C13},
numpages = {13},
keywords = {augmented reality, design collaboration, design support system, human-computer interaction, prototyping, spatial design, tangible user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}",C-Space: An Interactive Prototyping Platform for Collaborative Spatial Design Exploration,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A room marker block (20*20*80mm),Planar surface,The bottom surface of block,One-handed,Positioning,Locating the block on desktop to input a position for displaying a specific room.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D graphic,The position of the 2D graphic displayed on the desktop projection.,2D display,Use a polyhedron to modulate a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The room marker block is on the desktop.
2. The room marker block is aligned with the 2D graphic.
3. The 2D graphic is on the desktop."
47,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3025453.3025863,"Besan\c{c}on, Lonni and Issartel, Paul and Ammi, Mehdi and Isenberg, Tobias","@inproceedings{10.1145/3025453.3025863,
author = {Besan\c{c}on, Lonni and Issartel, Paul and Ammi, Mehdi and Isenberg, Tobias},
title = {Mouse, Tactile, and Tangible Input for 3D Manipulation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025863},
doi = {10.1145/3025453.3025863},
abstract = {We evaluate the performance and usability of mouse-based, touch-based, and tangible interaction for manipulating objects in a 3D virtual environment. This comparison is a step toward a better understanding of the limitations and benefits of these existing interaction techniques, with the ultimate goal of facilitating an easy transition between the different 3D data exploration environments. For this purpose we analyze participants' performance in 3D manipulation using a docking task. We measured completion times, docking accuracy, as well as subjective criteria such as fatigue, workload, and preference. Our results show that the three input modalities provide similar levels of precision but require different completion times. We also discuss our qualitative observations as well as people's preferences and put our findings into context of the application domain of 3D data analysis environments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4727¨C4740},
numpages = {14},
keywords = {3D interaction, TUI, mouse, tactile interaction, tangible interaction, usability study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}","Mouse, Tactile, and Tangible Input for 3D Manipulation",,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A cuboctahedron with 8 triangular faces and 6 square faces,Body,A cuboctahedron with 8 triangular faces and 6 square faces,One-handed,Positioning+Rotating,Moving a cuboctahedron in space for translating and rotating the 3D graphic.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D graphic,The position and rotation of the 3D graphic displayed on the screen.,2D display,Use a polyhedron to translate/rotate/scale a 3D graphic by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The cuboctahedron is in user's hand.
2. The cuboctahedron is discrete from the 3D graphic.
3. The 3D graphic is away from the user."
48,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3025453.3025890,"Besan\c{c}on, Lonni and Ammi, Mehdi and Isenberg, Tobias","@inproceedings{10.1145/3025453.3025890,
author = {Besan\c{c}on, Lonni and Ammi, Mehdi and Isenberg, Tobias},
title = {Pressure-Based Gain Factor Control for Mobile 3D Interaction using Locally-Coupled Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025890},
doi = {10.1145/3025453.3025890},
abstract = {We present the design and evaluation of pressure-based interactive control of 3D navigation precision. Specifically, we examine the control of gain factors in tangible 3D interactions using locally-coupled mobile devices. By focusing on pressure as a separate input channel we can adjust gain factors independently from other input modalities used in 3D navigation, in particular for the exploration of 3D visualisations. We present two experiments. First, we determined that people strongly preferred higher pressures to be mapped to higher gain factors. Using this mapping, we compared pressure with rate control, velocity control, and slider-based control in a second study. Our results show that pressure-based gain control allows people to be more precise in the same amount of time compared to established input modalities. Pressure-based control was also clearly preferred by our participants. In summary, we demonstrate that pressure facilitates effective and efficient precision control for mobile 3D navigation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1831¨C1842},
numpages = {12},
keywords = {3D navigation, TUI, pressure input, tangible interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}",Pressure-Based Gain Factor Control for Mobile 3D Interaction using Locally-Coupled Devices,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A handheld tablet,Body,A handheld tablet,Symmetric,Positioning+Rotating,Moving a tablet in space for translating and rotating the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D medical volume rendering,The position and rotation of the 3D visualization of medical volume data displayed on the screen on the tablet.,2D display,Use a plate to translate/rotate/scale a 3D medical volume rendering by two-handed positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The tablet is in user's hand.
2. The tablet is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
49,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2858036.2858041,"Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel","@inproceedings{10.1145/2858036.2858041,
author = {Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel},
title = {TouchTokens: Guiding Touch Patterns with Passive Tokens},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858041},
doi = {10.1145/2858036.2858041},
abstract = {TouchTokens make it possible to easily build interfaces that combine tangible and gestural input using passive tokens and a regular multi-touch surface. The tokens constrain users' grasp, and thus, the relative spatial configuration of fingers on the surface, theoretically making it possible to design algorithms that can recognize the resulting touch patterns. We performed a formative user study to collect and analyze touch patterns with tokens of varying shape and size. The analysis of this pattern collection showed that individual users have a consistent grasp for each token, but that this grasp is user-dependent and that different grasp strategies can lead to confounding patterns. We thus designed a second set of tokens featuring notches that constrain users' grasp. Our recognition algorithm can classify the resulting patterns with a high level of accuracy (>95\%) without any training, enabling application designers to associate rich touch input vocabularies with command triggers and parameter controls.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4189¨C4202},
numpages = {14},
keywords = {multi-touch input, tangible interaction},
location = {San Jose, California, USA},
series = {CHI '16}
}",TouchTokens: Guiding Touch Patterns with Passive Tokens,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A flattened geometric object,Planar surface,The bottom surface of flattened geometric object,One-handed,Rotating,Rotating a flattened geometric object orientation on desktop for changing the size of scatter points.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Replacing,2D,2D scatterplot,The scatter points' size of the 2D visualization displayed on the desktop screen.,2D display,Use a plate to replace a 2D scatterplot by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The object is on the desktop.
2. The object is discrete from the 2D visualization.
3. The 2D visualization is on the desktop."
49,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2858036.2858041,"Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel","@inproceedings{10.1145/2858036.2858041,
author = {Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel},
title = {TouchTokens: Guiding Touch Patterns with Passive Tokens},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858041},
doi = {10.1145/2858036.2858041},
abstract = {TouchTokens make it possible to easily build interfaces that combine tangible and gestural input using passive tokens and a regular multi-touch surface. The tokens constrain users' grasp, and thus, the relative spatial configuration of fingers on the surface, theoretically making it possible to design algorithms that can recognize the resulting touch patterns. We performed a formative user study to collect and analyze touch patterns with tokens of varying shape and size. The analysis of this pattern collection showed that individual users have a consistent grasp for each token, but that this grasp is user-dependent and that different grasp strategies can lead to confounding patterns. We thus designed a second set of tokens featuring notches that constrain users' grasp. Our recognition algorithm can classify the resulting patterns with a high level of accuracy (>95\%) without any training, enabling application designers to associate rich touch input vocabularies with command triggers and parameter controls.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4189¨C4202},
numpages = {14},
keywords = {multi-touch input, tangible interaction},
location = {San Jose, California, USA},
series = {CHI '16}
}",TouchTokens: Guiding Touch Patterns with Passive Tokens,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A flattened geometric object,Planar surface,The bottom surface of flattened geometric object,One-handed,Positioning+Rotating,Locating a flattened geometric object on desktop to input a position and rotation in the plane for displaying different layers as a magic lens.,on the horizontal surface,"Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane.,Modulating,2D,2D map,The position and rotation of a layer's 2D map displayed on the magic lens.,2D display,Use a plate to modulate a 2D map by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The object is on the desktop.
2. The object is aligned with the 2D map.
3. The 2D map is displayed on the desktop."
49,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2858036.2858041,"Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel","@inproceedings{10.1145/2858036.2858041,
author = {Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel},
title = {TouchTokens: Guiding Touch Patterns with Passive Tokens},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858041},
doi = {10.1145/2858036.2858041},
abstract = {TouchTokens make it possible to easily build interfaces that combine tangible and gestural input using passive tokens and a regular multi-touch surface. The tokens constrain users' grasp, and thus, the relative spatial configuration of fingers on the surface, theoretically making it possible to design algorithms that can recognize the resulting touch patterns. We performed a formative user study to collect and analyze touch patterns with tokens of varying shape and size. The analysis of this pattern collection showed that individual users have a consistent grasp for each token, but that this grasp is user-dependent and that different grasp strategies can lead to confounding patterns. We thus designed a second set of tokens featuring notches that constrain users' grasp. Our recognition algorithm can classify the resulting patterns with a high level of accuracy (>95\%) without any training, enabling application designers to associate rich touch input vocabularies with command triggers and parameter controls.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4189¨C4202},
numpages = {14},
keywords = {multi-touch input, tangible interaction},
location = {San Jose, California, USA},
series = {CHI '16}
}",TouchTokens: Guiding Touch Patterns with Passive Tokens,N/A.,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A flattened geometric object,Planar surface,The bottom surface of flattened geometric object,One-handed,Positioning,Locating a flattened geometric object on desktop for selecting a photo at a position in the plane.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Looking up,2D,2D graphic,The selected 2D graphic displayed on the desktop screen.,2D display,Use a plate to lookup a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The object is on the desktop.
2. The object is aligned with the 2D graphic.
3. The 2D graphic is displayed on the desktop."
49,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2858036.2858041,"Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel","@inproceedings{10.1145/2858036.2858041,
author = {Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel},
title = {TouchTokens: Guiding Touch Patterns with Passive Tokens},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858041},
doi = {10.1145/2858036.2858041},
abstract = {TouchTokens make it possible to easily build interfaces that combine tangible and gestural input using passive tokens and a regular multi-touch surface. The tokens constrain users' grasp, and thus, the relative spatial configuration of fingers on the surface, theoretically making it possible to design algorithms that can recognize the resulting touch patterns. We performed a formative user study to collect and analyze touch patterns with tokens of varying shape and size. The analysis of this pattern collection showed that individual users have a consistent grasp for each token, but that this grasp is user-dependent and that different grasp strategies can lead to confounding patterns. We thus designed a second set of tokens featuring notches that constrain users' grasp. Our recognition algorithm can classify the resulting patterns with a high level of accuracy (>95\%) without any training, enabling application designers to associate rich touch input vocabularies with command triggers and parameter controls.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4189¨C4202},
numpages = {14},
keywords = {multi-touch input, tangible interaction},
location = {San Jose, California, USA},
series = {CHI '16}
}",TouchTokens: Guiding Touch Patterns with Passive Tokens,N/A.,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A flattened geometric object,Planar surface,The bottom surface of flattened geometric object,One-handed,Rotating,Rotating a flattened geometric object orientation on desktop for displaying photos in an album.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Modulating,2D,2D graphic,The content of 2D graphic displayed on the desktop screen.,2D display,Use a plate to modulate a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The object is on the desktop.
2. The object is aligned with the 2D graphic.
3. The 2D graphic is displayed on the desktop."
50,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2525194.2525211,"Agrawal, Mehul and Jain, Minal and Luthra, Vikas and Thariyan, Ashok and Sorathia, Keyur","@inproceedings{10.1145/2525194.2525211,
author = {Agrawal, Mehul and Jain, Minal and Luthra, Vikas and Thariyan, Ashok and Sorathia, Keyur},
title = {ChemicAble: Tangible Interaction Approach for learning Chemical Bonding},
year = {2013},
isbn = {9781450322539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2525194.2525211},
doi = {10.1145/2525194.2525211},
abstract = {In this paper we present ChemicAble, a Tangible User Interface (TUI) for teaching ionic bonding to students of grade 8 to 10. ChemicAble acts as an exercise tool for students to understand better the concepts of ionic bonding by letting them explore and learn. We discuss the instructional content of the system along with its prototyping details. Usability testing conducted with students has been discussed. The system realizes its aim of learning collaboratively with fun.},
booktitle = {Proceedings of the 11th Asia Pacific Conference on Computer Human Interaction},
pages = {416¨C421},
numpages = {6},
keywords = {Tangible User Interface, Tabletop Interaction, Education, Chemical Bonding},
location = {Bangalore, India},
series = {APCHI '13}
}",ChemicAble: Tangible Interaction Approach for learning Chemical Bonding,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A hemispherical token,Planar surface,The bottom surface of hemispherical token,One-handed,Positioning,Locating a hemispherical token on desktop for adding an atom for simulation.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,2D,2D simulation,The content of 2D visualization displayed on the desktop screen.,2D display,Use a spheroid to modulate a 2D simulation by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The hemispherical token is on the desktop.
2. The hemispherical token is aligned with the 2D visualization.
3. The 2D visualization is displayed on the desktop."
51,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3290605.3300243,"Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel","@inproceedings{10.1145/3290605.3300243,
author = {Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel},
title = {TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300243},
doi = {10.1145/3290605.3300243},
abstract = {Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, ""cutting"" objects by using the tablet as a physical ""knife"", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C13},
numpages = {13},
keywords = {interaction techniques, touch interaction, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}",TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A tablet,Point,A corner of tablet,One-handed,Positioning,Moving a tablet in space to contact the 3D virtual object for selecting.,in the room space,Position,Physical widget: 3DOF translation in the space.,Looking up,3D,3D graphic,The selected 3D graphic displayed in the virtual reality (HMD).,Virtual reality,Use a plate to lookup a 3D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The tablet is in user's hand.
2. The corner of tablet is crossed over the 3D virtual object.
3. The 3D virtual object is in the room."
51,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3290605.3300243,"Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel","@inproceedings{10.1145/3290605.3300243,
author = {Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel},
title = {TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300243},
doi = {10.1145/3290605.3300243},
abstract = {Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, ""cutting"" objects by using the tablet as a physical ""knife"", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C13},
numpages = {13},
keywords = {interaction techniques, touch interaction, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}",TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A tablet,Body,A tablet,One-handed,Rotating,Moving a tablet in space to change the orientation for adjust the operated axis.,in the room space,Rotation,Physical widget: 3DOF rotation in the space.,Adjusting,3D,3D graphic,The operated axis of 3D graphic displayed in the virtual reality (HMD).,Virtual reality,Use a plate to adjust a 3D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The tablet is in user's hand.
2. The tablet is discrete from the 3D graphic.
3. The 3D graphic is in the room."
51,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3290605.3300243,"Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel","@inproceedings{10.1145/3290605.3300243,
author = {Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel},
title = {TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300243},
doi = {10.1145/3290605.3300243},
abstract = {Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, ""cutting"" objects by using the tablet as a physical ""knife"", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1¨C13},
numpages = {13},
keywords = {interaction techniques, touch interaction, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}",TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A tablet,Planar surface,A surface of the tablet,One-handed,Positioning+Rotating,Moving a tablet in space for slicing the 3D virtual object.,in the room space,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Clipping,3D,3D graphic,The clipped 3D graphic of virtual object displayed in the virtualreality (HMD).,Virtual reality,Use a plate to clip a 3D graphic by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The tablet is in user's hand. 
2. The cutting plane attached to the surface of handheld tablet is crossed over the 3D graphic.
3. The 3D graphic is in the room."
52,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2556288.2557105,"Liang, Rong-Hao and Chan, Liwei and Tseng, Hung-Yu and Kuo, Han-Chih and Huang, Da-Yuan and Yang, De-Nian and Chen, Bing-Yu","@inproceedings{10.1145/2556288.2557105,
author = {Liang, Rong-Hao and Chan, Liwei and Tseng, Hung-Yu and Kuo, Han-Chih and Huang, Da-Yuan and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBricks: magnetic building blocks for constructive tangible interactions on portable displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557105},
doi = {10.1145/2556288.2557105},
abstract = {This work describes a novel building block system for tangible interaction design, GaussBricks, which enables real-time constructive tangible interactions on portable displays. Given its simplicity, the mechanical design of the magnetic building blocks facilitates the construction of configurable forms. The form constructed by the magnetic building blocks, which are connected by the magnetic joints, allows users to stably manipulate with various elastic force feedback mechanisms. With an analog Hall-sensor grid mounted to its back, a portable display determines the geometrical configuration and detects various user interactions in real time. This work also introduce several methods to enable shape changing, multi-touch input, and display capabilities in the construction. The proposed building block system enriches how individuals interact with the portable displays physically.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3153¨C3162},
numpages = {10},
keywords = {tangible interactions, portable displays, magnetism, constructive assembly},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}",GaussBricks: magnetic building blocks for constructive tangible interactions on portable displays,,Small,Single,A tangible widget,N/A,"Rigid, Reconfigurable",No use,Other,A low-fidelity model of 2D graphic,Body,A low-fidelity model of 2D graphic,One-handed,Rotating,Tilting the low-fidelity model in space to translate the 2D graphic for manipulating.,above the horizontal surface,Rotation,Physical widget: 3DOF rotation in the space.,Translating/Rotating/Scaling,2D,2D graphic,The position of the 2D graphic displayed on the desktop screen.,2D display,Use an other to translate/rotate/scale a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The low-fidelity model is above the desktop in user's hand.
2. The low-fidelity model is discrete from the 2D graphic.
3. The 2D graphic is on the desktop."
53,CHI,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2207676.2208583,"Spindler, Martin and Martsch, Marcel and Dachselt, Raimund","@inproceedings{10.1145/2207676.2208583,
author = {Spindler, Martin and Martsch, Marcel and Dachselt, Raimund},
title = {Going beyond the surface: studying multi-layer interaction above the tabletop},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208583},
doi = {10.1145/2207676.2208583},
abstract = {Lightweight spatially aware displays (Tangible Magic Lenses) are an effective approach for exploring complex information spaces within a tabletop environment. One way of using the 3D space above a horizontal surface is to divide it into discrete parallel layers stacked upon each other. Horizontal and vertical lens movements are essential tasks for the style of multi-layer interaction associated with it. We conducted a comprehensive user study with 18 participants investigating fundamental issues such as optimal number of layers and their thickness, movement and holding accuracies, and physical boundaries of the interaction volume. Findings include a rather limited overall interaction height (44 cm), a different minimal layer thickness for vertical and horizontal search tasks (1 cm/4 cm), a reasonable maximum number of layers depending on the primary task, and a convenience zone in the middle for horizontal search. Derived from that, design guidelines are also presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1277¨C1286},
numpages = {10},
keywords = {above the tabletop, multi-layer interaction, spatially aware displays, tangible magic lens, user study},
location = {Austin, Texas, USA},
series = {CHI '12}
}",Going beyond the surface: studying multi-layer interaction above the tabletop,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display ,One-handed,Positioning,Moving a paper-based display in space for searching target numbers.,above the horizontal surface,Position,Physical widget: 3DOF translation in the space.,Locating,2D,2D text,The content of one of the layered 2D graphics displayed on the paper-based display.,2D display,Use a plate to locate a 2D text by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the 2D graphic.
3. The 2D graphic is above the desktop."
54,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2396636.2396674,"Spindler, Martin and B\""{u}schel, Wolfgang and Dachselt, Raimund","@inproceedings{10.1145/2396636.2396674,
author = {Spindler, Martin and B\""{u}schel, Wolfgang and Dachselt, Raimund},
title = {Use your head: tangible windows for 3D information spaces in a tabletop environment},
year = {2012},
isbn = {9781450312097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396636.2396674},
doi = {10.1145/2396636.2396674},
abstract = {Tangible Windows are a novel concept for interacting with virtual 3D information spaces in a workbench-like multi-display environment. They allow for performing common 3D interaction tasks in a more accessible manner by combining principles of tangible interaction, head-coupled perspective, and multi-touch techniques. Tangible Windows unify the interaction and representation space in a single device. They either act as physical peepholes into a virtual 3D world or as physical containers for parts of that world and are well-suited for the collaborative exploration and manipulation of such information spaces. One important feature of Tangible Windows is that the use of obtrusive hardware, such as HMDs, is strictly avoided. Instead, lightweight paper-based displays are used. We present different techniques for canonical 3D interaction tasks such as viewport control or object selection and manipulation, based on the combination of independent input modalities. We tested these techniques on a self-developed prototype system and received promising early user feedback.},
booktitle = {Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces},
pages = {245¨C254},
numpages = {10},
keywords = {3d interaction, fish tank virtual reality, head interaction, head tracking, head-coupled perspective, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible windows},
location = {Cambridge, Massachusetts, USA},
series = {ITS '12}
}",Use your head: tangible windows for 3D information spaces in a tabletop environment,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Straight edge,A ray casted vertically from the lightweight paper-based display,One-handed,Casting,Moving a paper-based display in space to aim at a 3D virtual object for selecting.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Looking up,3D,3D graphic,The selected 3D graphic of virtual object displayed in the stereoscopic screen.,Stereoscopic screen,Use a plate to lookup a 3D graphic by casting.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Crossed,"1. The paper-based display is in user's hand.
2. The casting ray vertically attached to the paper-based display is crossed over the 3D graphic.
3. The 3D graphic is on the desktop."
54,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2396636.2396674,"Spindler, Martin and B\""{u}schel, Wolfgang and Dachselt, Raimund","@inproceedings{10.1145/2396636.2396674,
author = {Spindler, Martin and B\""{u}schel, Wolfgang and Dachselt, Raimund},
title = {Use your head: tangible windows for 3D information spaces in a tabletop environment},
year = {2012},
isbn = {9781450312097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396636.2396674},
doi = {10.1145/2396636.2396674},
abstract = {Tangible Windows are a novel concept for interacting with virtual 3D information spaces in a workbench-like multi-display environment. They allow for performing common 3D interaction tasks in a more accessible manner by combining principles of tangible interaction, head-coupled perspective, and multi-touch techniques. Tangible Windows unify the interaction and representation space in a single device. They either act as physical peepholes into a virtual 3D world or as physical containers for parts of that world and are well-suited for the collaborative exploration and manipulation of such information spaces. One important feature of Tangible Windows is that the use of obtrusive hardware, such as HMDs, is strictly avoided. Instead, lightweight paper-based displays are used. We present different techniques for canonical 3D interaction tasks such as viewport control or object selection and manipulation, based on the combination of independent input modalities. We tested these techniques on a self-developed prototype system and received promising early user feedback.},
booktitle = {Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces},
pages = {245¨C254},
numpages = {10},
keywords = {3d interaction, fish tank virtual reality, head interaction, head tracking, head-coupled perspective, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible windows},
location = {Cambridge, Massachusetts, USA},
series = {ITS '12}
}",Use your head: tangible windows for 3D information spaces in a tabletop environment,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display ,One-handed,Rotating,Flipping a paper-based display in space for displaying the backside of a 3D virtual object.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation in the space.,Replacing,3D,3D graphic,The content of 3D graphic displayed in the stereoscopic screen.,Stereoscopic screen,Use a plate to replace a 3D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper-based display is in user's hand.
2. The view plane controlled by the paper-based display is aligned with the 3D graphic.
3. The 3D graphic is above the desktop."
54,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2396636.2396674,"Spindler, Martin and B\""{u}schel, Wolfgang and Dachselt, Raimund","@inproceedings{10.1145/2396636.2396674,
author = {Spindler, Martin and B\""{u}schel, Wolfgang and Dachselt, Raimund},
title = {Use your head: tangible windows for 3D information spaces in a tabletop environment},
year = {2012},
isbn = {9781450312097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396636.2396674},
doi = {10.1145/2396636.2396674},
abstract = {Tangible Windows are a novel concept for interacting with virtual 3D information spaces in a workbench-like multi-display environment. They allow for performing common 3D interaction tasks in a more accessible manner by combining principles of tangible interaction, head-coupled perspective, and multi-touch techniques. Tangible Windows unify the interaction and representation space in a single device. They either act as physical peepholes into a virtual 3D world or as physical containers for parts of that world and are well-suited for the collaborative exploration and manipulation of such information spaces. One important feature of Tangible Windows is that the use of obtrusive hardware, such as HMDs, is strictly avoided. Instead, lightweight paper-based displays are used. We present different techniques for canonical 3D interaction tasks such as viewport control or object selection and manipulation, based on the combination of independent input modalities. We tested these techniques on a self-developed prototype system and received promising early user feedback.},
booktitle = {Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces},
pages = {245¨C254},
numpages = {10},
keywords = {3d interaction, fish tank virtual reality, head interaction, head tracking, head-coupled perspective, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible windows},
location = {Cambridge, Massachusetts, USA},
series = {ITS '12}
}",Use your head: tangible windows for 3D information spaces in a tabletop environment,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving the paper-based display in space for translating the 3D map horizontally.,above the horizontal surface,Position,Physical widget: 2DOF translation horizontally in the space.,Navigating,3D,3D map,The viewpoint position of the 3D map displayed in the stereoscopic screen.,Stereoscopic screen,Use a plate to navigate a 3D map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The paper-based display is in user's hand.
2. The paper-based display is discrete from the 3D map.
3. The 3D map is away from the user."
55,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1936652.1936684,"Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund","@inproceedings{10.1145/1936652.1936684,
author = {Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund},
title = {Tangible views for information visualization},
year = {2010},
isbn = {9781450303996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936652.1936684},
doi = {10.1145/1936652.1936684},
abstract = {In information visualization, interaction is commonly carried out by using traditional input devices, and visual feedback is usually given on desktop displays. By contrast, recent advances in interactive surface technology suggest combining interaction and display functionality in a single device for a more direct interaction. With our work, we contribute to the seamless integration of interaction and display devices and introduce new ways of visualizing and directly interacting with information. Rather than restricting the interaction to the display surface alone, we explicitly use the physical three-dimensional space above it for natural interaction with multiple displays. For this purpose, we introduce tangible views as spatially aware lightweight displays that can be interacted with by moving them through the physical space on or above a tabletop display's surface. Tracking the 3D movement of tangible views allows us to control various parameters of a visualization with more degrees of freedom. Tangible views also facilitate making multiple -- previously virtual -- views physically ""graspable"". In this paper, we introduce a number of interaction and visualization patterns for tangible views that constitute the vocabulary for performing a variety of common visualization tasks. Several implemented case studies demonstrate the usefulness of tangible views for widely used information visualization approaches and suggest the high potential of this novel approach to support interaction with complex visualizations.},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces},
pages = {157¨C166},
numpages = {10},
keywords = {focus + context techniques, interaction techniques, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible views},
location = {Saarbr\""{u}cken, Germany},
series = {ITS '10}
}",Tangible views for information visualization,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving a paper-based display at different height in space for adjusting the level of abstraction.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,2D,2D node link,The level of abstraction of the 2D node link displayed on the paper-based display.,2D display,Use a plate to adjust a 2D node link by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
55,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1936652.1936684,"Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund","@inproceedings{10.1145/1936652.1936684,
author = {Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund},
title = {Tangible views for information visualization},
year = {2010},
isbn = {9781450303996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936652.1936684},
doi = {10.1145/1936652.1936684},
abstract = {In information visualization, interaction is commonly carried out by using traditional input devices, and visual feedback is usually given on desktop displays. By contrast, recent advances in interactive surface technology suggest combining interaction and display functionality in a single device for a more direct interaction. With our work, we contribute to the seamless integration of interaction and display devices and introduce new ways of visualizing and directly interacting with information. Rather than restricting the interaction to the display surface alone, we explicitly use the physical three-dimensional space above it for natural interaction with multiple displays. For this purpose, we introduce tangible views as spatially aware lightweight displays that can be interacted with by moving them through the physical space on or above a tabletop display's surface. Tracking the 3D movement of tangible views allows us to control various parameters of a visualization with more degrees of freedom. Tangible views also facilitate making multiple -- previously virtual -- views physically ""graspable"". In this paper, we introduce a number of interaction and visualization patterns for tangible views that constitute the vocabulary for performing a variety of common visualization tasks. Several implemented case studies demonstrate the usefulness of tangible views for widely used information visualization approaches and suggest the high potential of this novel approach to support interaction with complex visualizations.},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces},
pages = {157¨C166},
numpages = {10},
keywords = {focus + context techniques, interaction techniques, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible views},
location = {Saarbr\""{u}cken, Germany},
series = {ITS '10}
}",Tangible views for information visualization,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving a paper-based display at different height in space for adjusting the level of magnification/displacement.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,2D,2D bubble chart,The level of magnification/displacement of the 2D bubble chart displayed on the paper-based display.,2D display,Use a plate to adjust a 2D bubble chart by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
55,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1936652.1936684,"Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund","@inproceedings{10.1145/1936652.1936684,
author = {Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund},
title = {Tangible views for information visualization},
year = {2010},
isbn = {9781450303996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936652.1936684},
doi = {10.1145/1936652.1936684},
abstract = {In information visualization, interaction is commonly carried out by using traditional input devices, and visual feedback is usually given on desktop displays. By contrast, recent advances in interactive surface technology suggest combining interaction and display functionality in a single device for a more direct interaction. With our work, we contribute to the seamless integration of interaction and display devices and introduce new ways of visualizing and directly interacting with information. Rather than restricting the interaction to the display surface alone, we explicitly use the physical three-dimensional space above it for natural interaction with multiple displays. For this purpose, we introduce tangible views as spatially aware lightweight displays that can be interacted with by moving them through the physical space on or above a tabletop display's surface. Tracking the 3D movement of tangible views allows us to control various parameters of a visualization with more degrees of freedom. Tangible views also facilitate making multiple -- previously virtual -- views physically ""graspable"". In this paper, we introduce a number of interaction and visualization patterns for tangible views that constitute the vocabulary for performing a variety of common visualization tasks. Several implemented case studies demonstrate the usefulness of tangible views for widely used information visualization approaches and suggest the high potential of this novel approach to support interaction with complex visualizations.},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces},
pages = {157¨C166},
numpages = {10},
keywords = {focus + context techniques, interaction techniques, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible views},
location = {Saarbr\""{u}cken, Germany},
series = {ITS '10}
}",Tangible views for information visualization,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving a paper-based display at different height in space for adjusting the level of sampling.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,2D,2D parallel coordinate,The level of sampling of the 2D parallel coordinates visualization displayed on the paper-based display.,2D display,Use a plate to adjust a 2D parallel coordinate by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
55,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1936652.1936684,"Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund","@inproceedings{10.1145/1936652.1936684,
author = {Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund},
title = {Tangible views for information visualization},
year = {2010},
isbn = {9781450303996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936652.1936684},
doi = {10.1145/1936652.1936684},
abstract = {In information visualization, interaction is commonly carried out by using traditional input devices, and visual feedback is usually given on desktop displays. By contrast, recent advances in interactive surface technology suggest combining interaction and display functionality in a single device for a more direct interaction. With our work, we contribute to the seamless integration of interaction and display devices and introduce new ways of visualizing and directly interacting with information. Rather than restricting the interaction to the display surface alone, we explicitly use the physical three-dimensional space above it for natural interaction with multiple displays. For this purpose, we introduce tangible views as spatially aware lightweight displays that can be interacted with by moving them through the physical space on or above a tabletop display's surface. Tracking the 3D movement of tangible views allows us to control various parameters of a visualization with more degrees of freedom. Tangible views also facilitate making multiple -- previously virtual -- views physically ""graspable"". In this paper, we introduce a number of interaction and visualization patterns for tangible views that constitute the vocabulary for performing a variety of common visualization tasks. Several implemented case studies demonstrate the usefulness of tangible views for widely used information visualization approaches and suggest the high potential of this novel approach to support interaction with complex visualizations.},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces},
pages = {157¨C166},
numpages = {10},
keywords = {focus + context techniques, interaction techniques, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible views},
location = {Saarbr\""{u}cken, Germany},
series = {ITS '10}
}",Tangible views for information visualization,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Positioning,Moving a paper-based display at different height in space for adjusting the size of matrix subregion.,above the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,2D,2D matrix,The size of matrix subregion of the 2D matrix visualization displayed on the paper-based display.,2D display,Use a plate to adjust a 2D matrix by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
55,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1936652.1936684,"Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund","@inproceedings{10.1145/1936652.1936684,
author = {Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund},
title = {Tangible views for information visualization},
year = {2010},
isbn = {9781450303996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936652.1936684},
doi = {10.1145/1936652.1936684},
abstract = {In information visualization, interaction is commonly carried out by using traditional input devices, and visual feedback is usually given on desktop displays. By contrast, recent advances in interactive surface technology suggest combining interaction and display functionality in a single device for a more direct interaction. With our work, we contribute to the seamless integration of interaction and display devices and introduce new ways of visualizing and directly interacting with information. Rather than restricting the interaction to the display surface alone, we explicitly use the physical three-dimensional space above it for natural interaction with multiple displays. For this purpose, we introduce tangible views as spatially aware lightweight displays that can be interacted with by moving them through the physical space on or above a tabletop display's surface. Tracking the 3D movement of tangible views allows us to control various parameters of a visualization with more degrees of freedom. Tangible views also facilitate making multiple -- previously virtual -- views physically ""graspable"". In this paper, we introduce a number of interaction and visualization patterns for tangible views that constitute the vocabulary for performing a variety of common visualization tasks. Several implemented case studies demonstrate the usefulness of tangible views for widely used information visualization approaches and suggest the high potential of this novel approach to support interaction with complex visualizations.},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces},
pages = {157¨C166},
numpages = {10},
keywords = {focus + context techniques, interaction techniques, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible views},
location = {Saarbr\""{u}cken, Germany},
series = {ITS '10}
}",Tangible views for information visualization,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Shaking,Shaking a paper-based display in space for clearing the created matrix subregion.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,2D,2D matrix,The matrix subregion of the 2D matrix visualization displayed on the paper-based display.,2D display,Use a plate to modulate a 2D matrix by shaking.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper-based display is in user's hand.
2. The paper-based display is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
55,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1936652.1936684,"Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund","@inproceedings{10.1145/1936652.1936684,
author = {Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund},
title = {Tangible views for information visualization},
year = {2010},
isbn = {9781450303996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936652.1936684},
doi = {10.1145/1936652.1936684},
abstract = {In information visualization, interaction is commonly carried out by using traditional input devices, and visual feedback is usually given on desktop displays. By contrast, recent advances in interactive surface technology suggest combining interaction and display functionality in a single device for a more direct interaction. With our work, we contribute to the seamless integration of interaction and display devices and introduce new ways of visualizing and directly interacting with information. Rather than restricting the interaction to the display surface alone, we explicitly use the physical three-dimensional space above it for natural interaction with multiple displays. For this purpose, we introduce tangible views as spatially aware lightweight displays that can be interacted with by moving them through the physical space on or above a tabletop display's surface. Tracking the 3D movement of tangible views allows us to control various parameters of a visualization with more degrees of freedom. Tangible views also facilitate making multiple -- previously virtual -- views physically ""graspable"". In this paper, we introduce a number of interaction and visualization patterns for tangible views that constitute the vocabulary for performing a variety of common visualization tasks. Several implemented case studies demonstrate the usefulness of tangible views for widely used information visualization approaches and suggest the high potential of this novel approach to support interaction with complex visualizations.},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces},
pages = {157¨C166},
numpages = {10},
keywords = {focus + context techniques, interaction techniques, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible views},
location = {Saarbr\""{u}cken, Germany},
series = {ITS '10}
}",Tangible views for information visualization,,Medium,Double,Two tangible widgets,N/A,Rigid,No use,Plate,Two lightweight paper-based displays,Planar surface,Two surfaces of the paper-based displays,Asymmetric,Positioning,Neighboring two paper-based displays on desktop/in space for displaying the similarity of two matrix subregions.,"on the horizontal surface,above the horizontal surface","Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane./Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,2D,2D matrix,The color indicated the similarity of two matrix subregions of the 2D matrix visualization displayed on the paper-based display.,2D display,Use two plates to modulate a 2D matrix by coordinated positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper-based display is on the desktop/in user's hand.
2. The paper-based display is aligned with the 2D visualization.
3. The 2D visualization is on the desktop."
55,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1936652.1936684,"Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund","@inproceedings{10.1145/1936652.1936684,
author = {Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund},
title = {Tangible views for information visualization},
year = {2010},
isbn = {9781450303996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936652.1936684},
doi = {10.1145/1936652.1936684},
abstract = {In information visualization, interaction is commonly carried out by using traditional input devices, and visual feedback is usually given on desktop displays. By contrast, recent advances in interactive surface technology suggest combining interaction and display functionality in a single device for a more direct interaction. With our work, we contribute to the seamless integration of interaction and display devices and introduce new ways of visualizing and directly interacting with information. Rather than restricting the interaction to the display surface alone, we explicitly use the physical three-dimensional space above it for natural interaction with multiple displays. For this purpose, we introduce tangible views as spatially aware lightweight displays that can be interacted with by moving them through the physical space on or above a tabletop display's surface. Tracking the 3D movement of tangible views allows us to control various parameters of a visualization with more degrees of freedom. Tangible views also facilitate making multiple -- previously virtual -- views physically ""graspable"". In this paper, we introduce a number of interaction and visualization patterns for tangible views that constitute the vocabulary for performing a variety of common visualization tasks. Several implemented case studies demonstrate the usefulness of tangible views for widely used information visualization approaches and suggest the high potential of this novel approach to support interaction with complex visualizations.},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces},
pages = {157¨C166},
numpages = {10},
keywords = {focus + context techniques, interaction techniques, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible views},
location = {Saarbr\""{u}cken, Germany},
series = {ITS '10}
}",Tangible views for information visualization,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Rotating,Rotating a paper-based display orientation in space for changing the time range using to display.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation at the plane of the display surface in the space.,Modulating,3D,3D stacked choropleth map,The time range of the space-time cube visualization displayed on the paper-based display.,2D display,Use a plate to modulate a 3D stacked choropleth map by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The paper-based display is in user's hand.
2. The paper-based display is crossed over the 3D visualization.
3. The 3D visualization is on the desktop."
55,ISS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/1936652.1936684,"Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund","@inproceedings{10.1145/1936652.1936684,
author = {Spindler, Martin and Tominski, Christian and Schumann, Heidrun and Dachselt, Raimund},
title = {Tangible views for information visualization},
year = {2010},
isbn = {9781450303996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936652.1936684},
doi = {10.1145/1936652.1936684},
abstract = {In information visualization, interaction is commonly carried out by using traditional input devices, and visual feedback is usually given on desktop displays. By contrast, recent advances in interactive surface technology suggest combining interaction and display functionality in a single device for a more direct interaction. With our work, we contribute to the seamless integration of interaction and display devices and introduce new ways of visualizing and directly interacting with information. Rather than restricting the interaction to the display surface alone, we explicitly use the physical three-dimensional space above it for natural interaction with multiple displays. For this purpose, we introduce tangible views as spatially aware lightweight displays that can be interacted with by moving them through the physical space on or above a tabletop display's surface. Tracking the 3D movement of tangible views allows us to control various parameters of a visualization with more degrees of freedom. Tangible views also facilitate making multiple -- previously virtual -- views physically ""graspable"". In this paper, we introduce a number of interaction and visualization patterns for tangible views that constitute the vocabulary for performing a variety of common visualization tasks. Several implemented case studies demonstrate the usefulness of tangible views for widely used information visualization approaches and suggest the high potential of this novel approach to support interaction with complex visualizations.},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces},
pages = {157¨C166},
numpages = {10},
keywords = {focus + context techniques, interaction techniques, magic lenses, multi-surface user interfaces, multiple views, tabletop displays, tangible views},
location = {Saarbr\""{u}cken, Germany},
series = {ITS '10}
}",Tangible views for information visualization,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A lightweight paper-based display,Planar surface,A surface of the paper-based display,One-handed,Rotating,Flipping a paper-based display in space for switching the color encoding.,above the horizontal surface,Rotation,Physical widget: 3DOF rotation in the space.,Replacing,3D,3D stacked choropleth map,The color encoding of the space-time cube visualization displayed on the paper-based display.,2D display,Use a plate to replace a 3D stacked choropleth map by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The paper-based display is in user's hand.
2. The paper-based display is crossed over the 3D visualization.
3. The 3D visualization is on the desktop."
56,DIS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3563657.3596032,"Gong, Weilun and Santosa, Stephanie and Grossman, Tovi and Glueck, Michael and Clarke, Daniel and Lai, Frances","@inproceedings{10.1145/3563657.3596032,
author = {Gong, Weilun and Santosa, Stephanie and Grossman, Tovi and Glueck, Michael and Clarke, Daniel and Lai, Frances},
title = {Affordance-Based and User-Defined Gestures for Spatial Tangible Interaction},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596032},
doi = {10.1145/3563657.3596032},
abstract = {Although mid-air hand gestures have been widely adopted by VR/AR products (e.g., Quest 2 and HoloLens), some drawbacks remain due to their lack of tangibility and tactile feedback. Opportunistic Tangible User Interfaces could address these shortcomings by repurposing existing objects in one's physical environment. However, there has yet to be a systematic investigation of the gestures that would be desirable when using opportunistic objects or how such gestures would be impacted by such objects. In this work, we conducted an elicitation study to investigate the desirability of object and gesture combinations across a variety of interactions. The results contribute (1) an opportunistic tangible UI gesture set for spatial interfaces, and (2) an Affordance-Based Object Selector Scheme that identifies ideal objects for tangible input given a desired input gesture, based on that object's physical affordances. Arising from these findings is the vision of the Adaptive Tangible User Interface, which supports the on-the-fly composition of tangible interfaces based on the affordances found in the physical environment and a user's input task.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {1500¨C1514},
numpages = {15},
keywords = {Embodied Interaction, Input Technique, Tangible User Interface},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}",Affordance-Based and User-Defined Gestures for Spatial Tangible Interaction,,Small,Single,A tangible widget,N/A,Elastic,No use,Slender body,A cup,Body,A cup,One-handed,Positioning+Rotating,Moving a cup in space for translating and rotating the 3D graphic.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D graphic,The position and rotation of the 3D graphic displayed in the augmented reality (HMD).,Augmented reality,Use a slender body to translate/rotate/scale a 3D graphic by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The cup is in user's hand.
2. The cup is discrete from the 3D graphic.
3. The 3D graphic is above the desktop."
56,DIS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3563657.3596032,"Gong, Weilun and Santosa, Stephanie and Grossman, Tovi and Glueck, Michael and Clarke, Daniel and Lai, Frances","@inproceedings{10.1145/3563657.3596032,
author = {Gong, Weilun and Santosa, Stephanie and Grossman, Tovi and Glueck, Michael and Clarke, Daniel and Lai, Frances},
title = {Affordance-Based and User-Defined Gestures for Spatial Tangible Interaction},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596032},
doi = {10.1145/3563657.3596032},
abstract = {Although mid-air hand gestures have been widely adopted by VR/AR products (e.g., Quest 2 and HoloLens), some drawbacks remain due to their lack of tangibility and tactile feedback. Opportunistic Tangible User Interfaces could address these shortcomings by repurposing existing objects in one's physical environment. However, there has yet to be a systematic investigation of the gestures that would be desirable when using opportunistic objects or how such gestures would be impacted by such objects. In this work, we conducted an elicitation study to investigate the desirability of object and gesture combinations across a variety of interactions. The results contribute (1) an opportunistic tangible UI gesture set for spatial interfaces, and (2) an Affordance-Based Object Selector Scheme that identifies ideal objects for tangible input given a desired input gesture, based on that object's physical affordances. Arising from these findings is the vision of the Adaptive Tangible User Interface, which supports the on-the-fly composition of tangible interfaces based on the affordances found in the physical environment and a user's input task.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {1500¨C1514},
numpages = {15},
keywords = {Embodied Interaction, Input Technique, Tangible User Interface},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}",Affordance-Based and User-Defined Gestures for Spatial Tangible Interaction,,Small,Single,A tangible widget,N/A,Elastic,Elastic,Slender body,A cup,Body,A cup,One-handed,Shaping,Squeezing a cup in space for adjusting the status of virtual car.,above the horizontal surface,Scale,Physical widget: 1DOF scale in the space.,Adjusting,3D,3D graphic,The status of the virtual car displayed in the augmented reality (HMD).,Augmented reality,Use a slender body to adjust a 3D graphic by shaping.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The cup is in user's hand.
2. The cup is discrete from the 3D graphic.
3. The 3D graphic is above the desktop."
56,DIS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3563657.3596032,"Gong, Weilun and Santosa, Stephanie and Grossman, Tovi and Glueck, Michael and Clarke, Daniel and Lai, Frances","@inproceedings{10.1145/3563657.3596032,
author = {Gong, Weilun and Santosa, Stephanie and Grossman, Tovi and Glueck, Michael and Clarke, Daniel and Lai, Frances},
title = {Affordance-Based and User-Defined Gestures for Spatial Tangible Interaction},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596032},
doi = {10.1145/3563657.3596032},
abstract = {Although mid-air hand gestures have been widely adopted by VR/AR products (e.g., Quest 2 and HoloLens), some drawbacks remain due to their lack of tangibility and tactile feedback. Opportunistic Tangible User Interfaces could address these shortcomings by repurposing existing objects in one's physical environment. However, there has yet to be a systematic investigation of the gestures that would be desirable when using opportunistic objects or how such gestures would be impacted by such objects. In this work, we conducted an elicitation study to investigate the desirability of object and gesture combinations across a variety of interactions. The results contribute (1) an opportunistic tangible UI gesture set for spatial interfaces, and (2) an Affordance-Based Object Selector Scheme that identifies ideal objects for tangible input given a desired input gesture, based on that object's physical affordances. Arising from these findings is the vision of the Adaptive Tangible User Interface, which supports the on-the-fly composition of tangible interfaces based on the affordances found in the physical environment and a user's input task.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {1500¨C1514},
numpages = {15},
keywords = {Embodied Interaction, Input Technique, Tangible User Interface},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}",Affordance-Based and User-Defined Gestures for Spatial Tangible Interaction,,Small,Single,A tangible widget,N/A,Elastic,No use,Slender body,A cup,Body,A cup,One-handed,Rotating,Rotating a cup orientation in space for changing the forward direction of virtual car as a controller.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation around the axis of cylinder in the space.,Adjusting,3D,3D graphic,The forward direction of the virtual car displayed in the augmented reality (HMD).,Augmented reality,Use a slender body to adjust a 3D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The cup is in user's hand.
2. The cup is discrete from the 3D graphic.
3. The 3D graphic is above the desktop."
57,DIS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/3322276.3322280,"Chang, Jack Shen-Kuen and Doucette, Alison and Yeboah, Georgina and Welsh, Timothy and Nitsche, Michael and Mazalek, Ali","@inproceedings{10.1145/3322276.3322280,
author = {Chang, Jack Shen-Kuen and Doucette, Alison and Yeboah, Georgina and Welsh, Timothy and Nitsche, Michael and Mazalek, Ali},
title = {Keep the Ball Rolling: Designing Game-Based Tangible VR for Spatial Penetrative Thinking Ability},
year = {2019},
isbn = {9781450358507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3322276.3322280},
doi = {10.1145/3322276.3322280},
abstract = {Spatial abilities are grounded in the way we interact with and understand the world through our physical body. However, existing spatial ability training materials are largely paper- or screen-based; they rarely engage or encourage the use of the body. Tangible and Virtual Reality (VR) technologies provide opportunities to re-imagine designing for spatial ability. We present a game-based system that combines embodiment in VR with tangible interfaces, and is designed around a specific spatial ability known as penetrative thinking. This spatial ability is the capacity to imagine the internal structure of objects based on external cues. This ability is important in areas like design, geosciences, medicine, and engineering. We describe the iterative design, implementation, and testing of our system, including the user study of the final design. The user evaluation results showed that participants had positive experiences when they solved the penetrative thinking puzzles in the tangible VR system.},
booktitle = {Proceedings of the 2019 on Designing Interactive Systems Conference},
pages = {215¨C226},
numpages = {12},
keywords = {embodied cognition, games, spatial ability, tangible interaction, virtual environments, virtual reality},
location = {San Diego, CA, USA},
series = {DIS '19}
}",Keep the Ball Rolling: Designing Game-Based Tangible VR for Spatial Penetrative Thinking Ability,,Large,Single,A tangible widget,N/A,Rigid,No use,Plate,A board,Planar surface,A surface of the board,One-handed,Positioning+Rotating,Moving a surface of board in space for slicing the 3D virtual object.,above the horizontal surface,"Position,Rotation",Physical widget: 1DOF translation and 1DOF rotation in the space.,Clipping,3D,3D graphic,The position and rotation of the cutting plane and the image of the slice from the 3D graphic displayed in the virtual reality (HMD).,Augmented reality,Use a plate to clip a 3D graphic by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The board is in user's hand. 
2. The cutting plane attached to the surface of board is crossed over the 3D graphic.
3. The 3D graphic is on the desktop. "
58,DIS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2317956.2318016,"Goh, Wooi Boon and Kasun, L. L. Chamara and Fitriani and Tan, Jacquelyn and Shou, Wei","@inproceedings{10.1145/2317956.2318016,
author = {Goh, Wooi Boon and Kasun, L. L. Chamara and Fitriani and Tan, Jacquelyn and Shou, Wei},
title = {The i-Cube: design considerations for block-based digital manipulatives and their applications},
year = {2012},
isbn = {9781450312103},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2317956.2318016},
doi = {10.1145/2317956.2318016},
abstract = {Manipulatives are tangible objects designed to support learning through exploratory arrangement and manipulation. The i-Cube is a cube-shaped digital manipulative that provides unique 3-D spatial awareness of the facets and orientation of neighboring i-Cubes. This paper discusses the considerations adopted in its design and the advantages of the proposed design to that of other cube-based tangible user interfaces. The i-Cubes are then employed in the design of two applications. MusiCube Arranger is a tangible music composition and layering system and Spelling Cube is an interactive system for learning spelling. These applications are used to illustrate how the unique features of the i-Cube can be exploited to implement novel tangible interactions such as free-form 3D stacking, interactive control through block orientation change and context-aware feedback.},
booktitle = {Proceedings of the Designing Interactive Systems Conference},
pages = {398¨C407},
numpages = {10},
keywords = {child-computer Interaction, digital manipulatives, education, tangible user interfaces},
location = {Newcastle Upon Tyne, United Kingdom},
series = {DIS '12}
}",The i-Cube: design considerations for block-based digital manipulatives and their applications,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A plastic cube (55*55*55mm),Body,A plastic cube (55*55*55mm),One-handed,Rotating,Flipping a cube on desktop for adjusting the operation mode/sound.,on the horizontal surface,Rotation,Physical widget: 3DOF rotation in the space.,Adjusting,Other,Audio,The operation mode/sound for adding of the music application.,Other,Use a polyhedron to adjust an audio by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The cube is on the desktop.
2. The cube is discrete from the audio player.
3. The audio player is in the room."
58,DIS,Tangible & Interaction,https://dl.acm.org/doi/10.1145/2317956.2318016,"Goh, Wooi Boon and Kasun, L. L. Chamara and Fitriani and Tan, Jacquelyn and Shou, Wei","@inproceedings{10.1145/2317956.2318016,
author = {Goh, Wooi Boon and Kasun, L. L. Chamara and Fitriani and Tan, Jacquelyn and Shou, Wei},
title = {The i-Cube: design considerations for block-based digital manipulatives and their applications},
year = {2012},
isbn = {9781450312103},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2317956.2318016},
doi = {10.1145/2317956.2318016},
abstract = {Manipulatives are tangible objects designed to support learning through exploratory arrangement and manipulation. The i-Cube is a cube-shaped digital manipulative that provides unique 3-D spatial awareness of the facets and orientation of neighboring i-Cubes. This paper discusses the considerations adopted in its design and the advantages of the proposed design to that of other cube-based tangible user interfaces. The i-Cubes are then employed in the design of two applications. MusiCube Arranger is a tangible music composition and layering system and Spelling Cube is an interactive system for learning spelling. These applications are used to illustrate how the unique features of the i-Cube can be exploited to implement novel tangible interactions such as free-form 3D stacking, interactive control through block orientation change and context-aware feedback.},
booktitle = {Proceedings of the Designing Interactive Systems Conference},
pages = {398¨C407},
numpages = {10},
keywords = {child-computer Interaction, digital manipulatives, education, tangible user interfaces},
location = {Newcastle Upon Tyne, United Kingdom},
series = {DIS '12}
}",The i-Cube: design considerations for block-based digital manipulatives and their applications,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A plastic cube (55*55*55mm),Planar surface,The bottom surface of plastic cube,One-handed,Rotating,Rotating a cube orientation on desktop at each 90-degree to insert/decrease a unit-time rest.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Modulating,Other,Audio,The unit-time rests in the music application.,Other,Use a polyhedron to modulate an audio by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The cube is on the desktop.
2. The cube is discrete from the audio player.
3. The audio player is in the room."
59,ISS,3D Interaction,https://dl.acm.org/doi/10.1145/2076354.2076390,"Sultanum, Nicole and Somanath, Sowmya and Sharlin, Ehud and Sousa, Mario Costa","@inproceedings{10.1145/2076354.2076390,
author = {Sultanum, Nicole and Somanath, Sowmya and Sharlin, Ehud and Sousa, Mario Costa},
title = {""Point it, split it, peel it, view it"": techniques for interactive reservoir visualization on tabletops},
year = {2011},
isbn = {9781450308717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2076354.2076390},
doi = {10.1145/2076354.2076390},
abstract = {Reservoir engineers rely on virtual representations of oil reservoirs to make crucial decisions relating, for example, to the modeling and prediction of fluid behavior, or to the optimal locations for drilling wells. Therefore, they are in constant pursue of better virtual representations of the reservoir models, improved user awareness of their embedded data, and more intuitive ways to explore them, all ultimately leading to more informed decision making. Tabletops have great potential in providing powerful interactive representation to reservoir engineers, as well as enhancing the flexibility, immediacy and overall capabilities of their analysis, and consequently bringing more confidence into the decision making process. In this paper, we present a collection of 3D reservoir visualization techniques on tabletop interfaces applied to the domain of reservoir engineering, and argue that these provide greater insight into reservoir models. We support our claims with findings from a qualitative user study conducted with 12 reservoir engineers, which brought us insight into our techniques, as well as a discussion on the potential of tabletop-based visualization solutions for the domain of reservoir engineering.},
booktitle = {Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces},
pages = {192¨C201},
numpages = {10},
keywords = {tabletop, scientific visualization, reservoir engineering, interactive 3D visualization of reservoir models},
location = {Kobe, Japan},
series = {ITS '11}
}","""Point it, split it, peel it, view it"": techniques for interactive reservoir visualization on tabletops",,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A model of cell probe,Straight edge,A ray casted from the tip of cell probe,One-handed,Positioning,Locating the tip of cell probe on desktop to aim at the 3D visualization for annotating information as a probe.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Modulating,3D,3D geological volume rendering,The information of 3D visualization of geological data at the input position displayed on the desktop projection.,2D display,Use an other to modulate a 3D geological volume rendering by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The cell probe is on the desktop.
2. The ray casted from the cell probe is crossed over the 3D visualization.
3. The 3D visualization is away from the user."
59,ISS,3D Interaction,https://dl.acm.org/doi/10.1145/2076354.2076390,"Sultanum, Nicole and Somanath, Sowmya and Sharlin, Ehud and Sousa, Mario Costa","@inproceedings{10.1145/2076354.2076390,
author = {Sultanum, Nicole and Somanath, Sowmya and Sharlin, Ehud and Sousa, Mario Costa},
title = {""Point it, split it, peel it, view it"": techniques for interactive reservoir visualization on tabletops},
year = {2011},
isbn = {9781450308717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2076354.2076390},
doi = {10.1145/2076354.2076390},
abstract = {Reservoir engineers rely on virtual representations of oil reservoirs to make crucial decisions relating, for example, to the modeling and prediction of fluid behavior, or to the optimal locations for drilling wells. Therefore, they are in constant pursue of better virtual representations of the reservoir models, improved user awareness of their embedded data, and more intuitive ways to explore them, all ultimately leading to more informed decision making. Tabletops have great potential in providing powerful interactive representation to reservoir engineers, as well as enhancing the flexibility, immediacy and overall capabilities of their analysis, and consequently bringing more confidence into the decision making process. In this paper, we present a collection of 3D reservoir visualization techniques on tabletop interfaces applied to the domain of reservoir engineering, and argue that these provide greater insight into reservoir models. We support our claims with findings from a qualitative user study conducted with 12 reservoir engineers, which brought us insight into our techniques, as well as a discussion on the potential of tabletop-based visualization solutions for the domain of reservoir engineering.},
booktitle = {Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces},
pages = {192¨C201},
numpages = {10},
keywords = {tabletop, scientific visualization, reservoir engineering, interactive 3D visualization of reservoir models},
location = {Kobe, Japan},
series = {ITS '11}
}","""Point it, split it, peel it, view it"": techniques for interactive reservoir visualization on tabletops",,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A pyramid-shaped device,Body,A pyramid-shaped device,One-handed,Positioning,Picking up and putting down a device on desktop for triggering the removal mode.,on the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Adjusting,3D,3D geological volume rendering,The removal mode status of 3D visualization of geological data at the input position displayed on the desktop projection.,2D display,Use a polyhedron to adjust a 3D geological volume rendering by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The device is on the desktop.
2. The device is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
59,ISS,3D Interaction,https://dl.acm.org/doi/10.1145/2076354.2076390,"Sultanum, Nicole and Somanath, Sowmya and Sharlin, Ehud and Sousa, Mario Costa","@inproceedings{10.1145/2076354.2076390,
author = {Sultanum, Nicole and Somanath, Sowmya and Sharlin, Ehud and Sousa, Mario Costa},
title = {""Point it, split it, peel it, view it"": techniques for interactive reservoir visualization on tabletops},
year = {2011},
isbn = {9781450308717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2076354.2076390},
doi = {10.1145/2076354.2076390},
abstract = {Reservoir engineers rely on virtual representations of oil reservoirs to make crucial decisions relating, for example, to the modeling and prediction of fluid behavior, or to the optimal locations for drilling wells. Therefore, they are in constant pursue of better virtual representations of the reservoir models, improved user awareness of their embedded data, and more intuitive ways to explore them, all ultimately leading to more informed decision making. Tabletops have great potential in providing powerful interactive representation to reservoir engineers, as well as enhancing the flexibility, immediacy and overall capabilities of their analysis, and consequently bringing more confidence into the decision making process. In this paper, we present a collection of 3D reservoir visualization techniques on tabletop interfaces applied to the domain of reservoir engineering, and argue that these provide greater insight into reservoir models. We support our claims with findings from a qualitative user study conducted with 12 reservoir engineers, which brought us insight into our techniques, as well as a discussion on the potential of tabletop-based visualization solutions for the domain of reservoir engineering.},
booktitle = {Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces},
pages = {192¨C201},
numpages = {10},
keywords = {tabletop, scientific visualization, reservoir engineering, interactive 3D visualization of reservoir models},
location = {Kobe, Japan},
series = {ITS '11}
}","""Point it, split it, peel it, view it"": techniques for interactive reservoir visualization on tabletops",,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A pyramid-shaped device,Body,A pyramid-shaped device,One-handed,Rotating,Rotating a device on desktop for adjusting the angle of viewing from the well.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,3D,3D geological volume rendering,The viewing angle from the well in the 3D visualization of geological data at the input position displayed on the desktop projection.,2D display,Use a polyhedron to adjust a 3D geological volume rendering by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The device is on the desktop.
2. The device is discrete from the 3D visualization.
3. The 3D visualization is away from the user."
60,CHI,3D Interaction,https://dl.acm.org/doi/10.1145/2702123.2702244,"Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel","@inproceedings{10.1145/2702123.2702244,
author = {Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel},
title = {The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702244},
doi = {10.1145/2702123.2702244},
abstract = {We present the design and evaluation of the Roly-Poly Mouse (RPM), a rolling input device that combines the advantages of the mouse (position displacement) and of 3D devices (roll and rotation) to unify 2D and 3D interaction. Our first study explores RPM gesture amplitude and stability for different upper shapes (Hemispherical, Convex) and hand postures. 8 roll directions can be performed precisely and their amplitude is larger on Hemispherical RPM. As minor rolls affect translation, we propose a roll correction algorithm to support stable 2D pointing with RPM. We propose the use of compound gestures for 3D pointing and docking, and evaluate them against a commercial 3D device, the SpaceMouse. Our studies reveal that RPM performs 31\% faster than the SpaceMouse for 3D pointing and equivalently for 3D rotation. Finally, we present a proof-of-concept integrated RPM prototype along with discussion on the various technical challenges to overcome to build a final integrated version of RPM.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {327¨C336},
numpages = {10},
keywords = {2d pointing, 3d interaction, input device},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}",The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A sphere-shaped mouse,Body,A sphere-shaped mouse,One-handed,Positioning,Moving a sphere-shaped mouse on desktop for translating the 3D map.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Navigating,3D,3D map,The viewpoint position of the 3D map displayed on the screen.,2D display,Use a spheroid to navigate a 3D map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The sphere-shaped mouse is on the desktop.
2. The sphere-shaped mouse is discrete from the 3D map.
3. The 3D map is away from the user."
60,CHI,3D Interaction,https://dl.acm.org/doi/10.1145/2702123.2702244,"Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel","@inproceedings{10.1145/2702123.2702244,
author = {Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel},
title = {The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702244},
doi = {10.1145/2702123.2702244},
abstract = {We present the design and evaluation of the Roly-Poly Mouse (RPM), a rolling input device that combines the advantages of the mouse (position displacement) and of 3D devices (roll and rotation) to unify 2D and 3D interaction. Our first study explores RPM gesture amplitude and stability for different upper shapes (Hemispherical, Convex) and hand postures. 8 roll directions can be performed precisely and their amplitude is larger on Hemispherical RPM. As minor rolls affect translation, we propose a roll correction algorithm to support stable 2D pointing with RPM. We propose the use of compound gestures for 3D pointing and docking, and evaluate them against a commercial 3D device, the SpaceMouse. Our studies reveal that RPM performs 31\% faster than the SpaceMouse for 3D pointing and equivalently for 3D rotation. Finally, we present a proof-of-concept integrated RPM prototype along with discussion on the various technical challenges to overcome to build a final integrated version of RPM.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {327¨C336},
numpages = {10},
keywords = {2d pointing, 3d interaction, input device},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}",The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction,,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A sphere-shaped mouse,Body,A sphere-shaped mouse,One-handed,Rotating,Rolling a sphere-shaped mouse on desktop for scaling the 3D map,on the horizontal surface,"Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane.,Navigating,3D,3D map,The viewpoint scale of the 3D map displayed on the screen.,2D display,Use a spheroid to navigate a 3D map by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The sphere-shaped mouse is on the desktop.
2. The sphere-shaped mouse is discrete from the 3D map.
3. The 3D map is away from the user."
60,CHI,3D Interaction,https://dl.acm.org/doi/10.1145/2702123.2702244,"Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel","@inproceedings{10.1145/2702123.2702244,
author = {Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel},
title = {The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702244},
doi = {10.1145/2702123.2702244},
abstract = {We present the design and evaluation of the Roly-Poly Mouse (RPM), a rolling input device that combines the advantages of the mouse (position displacement) and of 3D devices (roll and rotation) to unify 2D and 3D interaction. Our first study explores RPM gesture amplitude and stability for different upper shapes (Hemispherical, Convex) and hand postures. 8 roll directions can be performed precisely and their amplitude is larger on Hemispherical RPM. As minor rolls affect translation, we propose a roll correction algorithm to support stable 2D pointing with RPM. We propose the use of compound gestures for 3D pointing and docking, and evaluate them against a commercial 3D device, the SpaceMouse. Our studies reveal that RPM performs 31\% faster than the SpaceMouse for 3D pointing and equivalently for 3D rotation. Finally, we present a proof-of-concept integrated RPM prototype along with discussion on the various technical challenges to overcome to build a final integrated version of RPM.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {327¨C336},
numpages = {10},
keywords = {2d pointing, 3d interaction, input device},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}",The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction,N/A.,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A sphere-shaped mouse,Body,A sphere-shaped mouse,One-handed,Rotating,Rotating a sphere-shaped mouse on desktop for selecting the drawn color.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Looking up,3D,3D graphic,The drawn color of the 3D graphic displayed on the screen.,2D display,Use a spheroid to lookup a 3D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The sphere-shaped mouse is on the desktop.
2. The sphere-shaped mouse is discrete from the 3D map.
3. The 3D map is away from the user."
60,CHI,3D Interaction,https://dl.acm.org/doi/10.1145/2702123.2702244,"Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel","@inproceedings{10.1145/2702123.2702244,
author = {Perelman, Gary and Serrano, Marcos and Raynal, Mathieu and Picard, Celia and Derras, Mustapha and Dubois, Emmanuel},
title = {The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702244},
doi = {10.1145/2702123.2702244},
abstract = {We present the design and evaluation of the Roly-Poly Mouse (RPM), a rolling input device that combines the advantages of the mouse (position displacement) and of 3D devices (roll and rotation) to unify 2D and 3D interaction. Our first study explores RPM gesture amplitude and stability for different upper shapes (Hemispherical, Convex) and hand postures. 8 roll directions can be performed precisely and their amplitude is larger on Hemispherical RPM. As minor rolls affect translation, we propose a roll correction algorithm to support stable 2D pointing with RPM. We propose the use of compound gestures for 3D pointing and docking, and evaluate them against a commercial 3D device, the SpaceMouse. Our studies reveal that RPM performs 31\% faster than the SpaceMouse for 3D pointing and equivalently for 3D rotation. Finally, we present a proof-of-concept integrated RPM prototype along with discussion on the various technical challenges to overcome to build a final integrated version of RPM.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {327¨C336},
numpages = {10},
keywords = {2d pointing, 3d interaction, input device},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}",The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction,N/A.,Small,Single,A tangible widget,N/A,Rigid,No use,Spheroid,A sphere-shaped mouse,Body,A sphere-shaped mouse,One-handed,Rotating,Rolling a sphere-shaped mouse on desktop for adjusting thickness and type of drawn lines.,on the horizontal surface,"Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane.,Adjusting,3D,3D graphic,The thickness and type of drawn lines of the 3D graphic displayed on the screen.,2D display,Use a spheroid to adjust a 3D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The sphere-shaped mouse is on the desktop.
2. The sphere-shaped mouse is discrete from the 3D graphic.
3. The 3D graphic is away from the user."
61,VR,Tangible & Interaction,https://ieeexplore.ieee.org/document/8797812,"Ssin, Seung Youb and Walsh, James A. and Smith, Ross T. and Cunningham, Andrew and Thomas, Bruce H.","@INPROCEEDINGS{8797812,
  author={Ssin, Seung Youb and Walsh, James A. and Smith, Ross T. and Cunningham, Andrew and Thomas, Bruce H.},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={GeoGate: Correlating Geo-Temporal Datasets Using an Augmented Reality Space-Time Cube and Tangible Interactions}, 
  year={2019},
  volume={},
  number={},
  pages={210-219},
  keywords={Three-dimensional displays;Data visualization;Two dimensional displays;Trajectory;Complexity theory;Augmented reality;Uncertainty;Augmented Reality;Space Time Cube;Multivariate Network Visualization;Multiple Data-sets;Maritime Visualization;Geo-visualization;Tangible User Interface;Tabletop;H.1.2 [Information Systems]: User/Machine Systems¡ªHuman factors;I.3.6 [Computer Graphics]: Methodology and Techniques¡ªInteraction techniques},
  doi={10.1109/VR.2019.8797812}}",GeoGate: Correlating Geo-Temporal Datasets Using an Augmented Reality Space-Time Cube and Tangible Interactions,,Medium,Single,A tangible widget,N/A,Rigid,No use,Toroid,A ring-shaped tangible user interface,Planar surface,The bottom surface of ring-shaped tangible user interface,One-handed,Positioning+Rotating,Moving a ring-shaped tangible user interface on desktop to translate/rotate/scale the 3D visualization for navigating.,on the horizontal surface,"Position,Rotation",Physical widget: 2DOF translation and 1DOF rotation in the plane.,Navigating,3D,3D trajectories,"The position, rotation and scale of the 3D visualization of the geo-temporal data displayed on the desktop screen.",Augmented reality,Use a toroid to navigate a 3D trajectories by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The ring-shaped tangible user interface is on desktop.
2. The ring-shaped tangible user interface is embedded with the 3D visualization.
3. The 3D visualization is on the desktop."
61,VR,Tangible & Interaction,https://ieeexplore.ieee.org/document/8797812,"Ssin, Seung Youb and Walsh, James A. and Smith, Ross T. and Cunningham, Andrew and Thomas, Bruce H.","@INPROCEEDINGS{8797812,
  author={Ssin, Seung Youb and Walsh, James A. and Smith, Ross T. and Cunningham, Andrew and Thomas, Bruce H.},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={GeoGate: Correlating Geo-Temporal Datasets Using an Augmented Reality Space-Time Cube and Tangible Interactions}, 
  year={2019},
  volume={},
  number={},
  pages={210-219},
  keywords={Three-dimensional displays;Data visualization;Two dimensional displays;Trajectory;Complexity theory;Augmented reality;Uncertainty;Augmented Reality;Space Time Cube;Multivariate Network Visualization;Multiple Data-sets;Maritime Visualization;Geo-visualization;Tangible User Interface;Tabletop;H.1.2 [Information Systems]: User/Machine Systems¡ªHuman factors;I.3.6 [Computer Graphics]: Methodology and Techniques¡ªInteraction techniques},
  doi={10.1109/VR.2019.8797812}}",GeoGate: Correlating Geo-Temporal Datasets Using an Augmented Reality Space-Time Cube and Tangible Interactions,,Medium,Single,A tangible widget,N/A,Rigid,No use,Toroid,A ring-shaped tangible user interface,Planar surface,The bottom surface of ring-shaped tangible user interface,One-handed,Rotating,Rotating a ring-shaped tangible user interface on desktop for adjusting the time range.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,3D,3D trajectories,The time range for displaying the 3D visualization of the geo-temporal data displayed on the desktop screen.,Augmented reality,Use a toroid to adjust a 3D trajectories by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The ring-shaped tangible user interface is on desktop.
2. The ring-shaped tangible user interface is embedded with the 3D visualization.
3. The 3D visualization is on the desktop."
62,3DUI,Tangible & Interaction,https://ieeexplore.ieee.org/document/5444699,"Chan, Leith K. Y. and Lau, Henry Y. K.","@INPROCEEDINGS{5444699,
  author={Chan, Leith K. Y. and Lau, Henry Y. K.},
  booktitle={2010 IEEE Symposium on 3D User Interfaces (3DUI)}, 
  title={A tangible user interface using spatial Augmented Reality}, 
  year={2010},
  volume={},
  number={},
  pages={137-138},
  keywords={User interfaces;Augmented reality;Virtual environment;Lenses;Virtual reality;Manufacturing industries;Manufacturing systems;Systems engineering and theory;Art;Hardware;augmented reality;3D user interface},
  doi={10.1109/3DUI.2010.5444699}}",A tangible user interface using spatial Augmented Reality,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A MagicPad,Planar surface,A surface of the MagicPad,One-handed,Rotating,Flipping a MagicPad in space for switching the rendering type.,in the room space,Rotation,Physical widget: 3DOF rotation in the space.,Replacing,3D,3D graphic,The rendering type of the 3D visualization of model displayed in the virtual reality (CAVE).,Virtual reality,Use a plate to replace a 3D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Crossed,"1. The MagicPad is in user's hand.
2. The MagicPad is crossed over the 3D visualization.
3. The 3D visualization is in the room."
63,TVCG,Tangible & Interaction,https://ieeexplore.ieee.org/document/9904446,"Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin","@ARTICLE{9904446,
  author={Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Exploring Interactions with Printed Data Visualizations in Augmented Reality}, 
  year={2023},
  volume={29},
  number={1},
  pages={418-428},
  keywords={Data visualization;Task analysis;Augmented reality;Affordances;Three-dimensional displays;Navigation;Human computer interaction;Interaction design;augmented reality;paper interaction;tangible user interface;printed data visualization},
  doi={10.1109/TVCG.2022.3209386}}",Exploring Interactions with Printed Data Visualizations in Augmented Reality,,Medium,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",Foldable,Plate,A sheet of paper,Planar surface,A sheet of paper,Symmetric,Shaping,Folding a paper in space to cover a portion of the axis for selecting data points.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Locating,2D,2D scatterplot,The selected data points of the 2D scatter visualization displayed in the augmented reality (HMD).,Augmented reality,Use a plate to locate a 2D scatterplot by two-handed shaping.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper is in user's hand.
2. The paper is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
63,TVCG,Tangible & Interaction,https://ieeexplore.ieee.org/document/9904446,"Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin","@ARTICLE{9904446,
  author={Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Exploring Interactions with Printed Data Visualizations in Augmented Reality}, 
  year={2023},
  volume={29},
  number={1},
  pages={418-428},
  keywords={Data visualization;Task analysis;Augmented reality;Affordances;Three-dimensional displays;Navigation;Human computer interaction;Interaction design;augmented reality;paper interaction;tangible user interface;printed data visualization},
  doi={10.1109/TVCG.2022.3209386}}",Exploring Interactions with Printed Data Visualizations in Augmented Reality,,Medium,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",Foldable,Plate,A sheet of paper,Planar surface,A sheet of paper,Symmetric,Shaping,Folding a paper in space to cover a portion of the axis for scaling the 2D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,2D,2D scatterplot,The scale of the 2D scatter visualization displayed in the augmented reality (HMD).,Augmented reality,Use a plate to translate/rotate/scale a 2D scatterplot by two-handed shaping.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Aligned,"1. The paper is in user's hand.
2. The paper is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
63,TVCG,Tangible & Interaction,https://ieeexplore.ieee.org/document/9904446,"Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin","@ARTICLE{9904446,
  author={Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Exploring Interactions with Printed Data Visualizations in Augmented Reality}, 
  year={2023},
  volume={29},
  number={1},
  pages={418-428},
  keywords={Data visualization;Task analysis;Augmented reality;Affordances;Three-dimensional displays;Navigation;Human computer interaction;Interaction design;augmented reality;paper interaction;tangible user interface;printed data visualization},
  doi={10.1109/TVCG.2022.3209386}}",Exploring Interactions with Printed Data Visualizations in Augmented Reality,,Medium,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",No use,Plate,A sheet of paper,Planar surface,A sheet of paper,One-handed,Positioning,Moving a paper closer to or farther away from the user in space for scaling the 2D visualization.,above the horizontal surface,Position,Physical widget: 1DOF translation in the direction vertically toward the user.,Translating/Rotating/Scaling,2D,2D scatterplot,The scale of the 2D scatter visualization displayed in the augmented reality (HMD).,Augmented reality,Use a plate to translate/rotate/scale a 2D scatterplot by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper is in user's hand.
2. The paper is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
63,TVCG,Tangible & Interaction,https://ieeexplore.ieee.org/document/9904446,"Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin","@ARTICLE{9904446,
  author={Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Exploring Interactions with Printed Data Visualizations in Augmented Reality}, 
  year={2023},
  volume={29},
  number={1},
  pages={418-428},
  keywords={Data visualization;Task analysis;Augmented reality;Affordances;Three-dimensional displays;Navigation;Human computer interaction;Interaction design;augmented reality;paper interaction;tangible user interface;printed data visualization},
  doi={10.1109/TVCG.2022.3209386}}",Exploring Interactions with Printed Data Visualizations in Augmented Reality,,Medium,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",No use,Plate,A sheet of paper,Planar surface,A sheet of paper,One-handed,Rotating,Tilting/flipping a paper in space to translate the 2D visualization around the corresponding axis.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation in the space.,Translating/Rotating/Scaling,2D,2D scatterplot,The position of the 2D scatter visualization displayed in the augmented reality (HMD).,Augmented reality,Use a plate to translate/rotate/scale a 2D scatterplot by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper is in user's hand.
2. The paper is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
63,TVCG,Tangible & Interaction,https://ieeexplore.ieee.org/document/9904446,"Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin","@ARTICLE{9904446,
  author={Tong, Wai and Zhu-Tian, Chen and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Exploring Interactions with Printed Data Visualizations in Augmented Reality}, 
  year={2023},
  volume={29},
  number={1},
  pages={418-428},
  keywords={Data visualization;Task analysis;Augmented reality;Affordances;Three-dimensional displays;Navigation;Human computer interaction;Interaction design;augmented reality;paper interaction;tangible user interface;printed data visualization},
  doi={10.1109/TVCG.2022.3209386}}",Exploring Interactions with Printed Data Visualizations in Augmented Reality,,Medium,Double,Two tangible widgets,N/A,"Bendable, Foldable, Twistable",No use,Plate,Two sheet of papers,Planar surface,Two sheet of papers,Asymmetric,Positioning,Neighboring or stacking two papers in space for linking the visualizations.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Replacing,2D,2D scatterplot,The representation of combining data of the 2D visualization displayed in the augmented reality (HMD).,Augmented reality,Use two plates to replace a 2D scatterplot by coordinated positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper is in user's hand.
2. The paper is aligned with the 2D visualization.
3. The 2D visualization is above the desktop."
64,TVCG,Tangible & Interaction,https://ieeexplore.ieee.org/document/7539617,"Besan\c{c}on, Lonni and Issartel, Paul and Ammi, Mehdi and Isenberg, Tobias","@ARTICLE{7539617,
  author={Besan\c{c}on, Lonni and Issartel, Paul and Ammi, Mehdi and Isenberg, Tobias},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Hybrid Tactile/Tangible Interaction for 3D Data Exploration}, 
  year={2017},
  volume={23},
  number={1},
  pages={881-890},
  keywords={Three-dimensional displays;Data visualization;Navigation;Context;Sensors;Aerospace electronics;Collaboration;Interaction;tactile input;tangible input;3D data visualization},
  doi={10.1109/TVCG.2016.2599217}}",Hybrid Tactile/Tangible Interaction for 3D Data Exploration,,Medium,Double,A virtual widget+A tangible widget,Fully mapped,Rigid,No use,Plate (with Planar surface),A handheld tablet (with a virtual cutting plane),Planar surface,A virtual cutting plane,Symmetric,Positioning+Rotating,Moving a handheld tablet in space to control a virtual cutting plane for slicing the 3D visualization.,above the horizontal surface,"Position,Rotation","Virtual widget: 3DOF translation and 3DOF rotation in the space.
Physical widget: 3DOF translation and 3DOF rotation in the space.",Clipping,3D,3D fluid volume rendering,"1. The image, position and rotation of the slice from the 3D visualization of fluid volume data displayed on the screen.
2. The clipped 3D visualization of fluid volume data displayed on the screen.",2D display,Use a planar surface controlled by a plate to clip a 3D fluid volume rendering by two-handed positioning+rotating.,Reachable,"Virtual: Not impacted within the accessible distance.
Physical: Interaction is possible only if manipulable entity is grabbed by user.",Unreachable,Not impacted within the accessible distance.,Crossed,"1. The plate is in user's hand.
2. The virtual cutting plane controlled by the plate is crossed over the 3D visualization.
3. The 3D visualization is away from the user."
65,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/9229116,"Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim","@ARTICLE{9229116,
  author={Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics}, 
  year={2021},
  volume={27},
  number={2},
  pages={1193-1203},
  keywords={Collaboration;Data visualization;Three-dimensional displays;Visual analytics;Stakeholders;Microgrids;Smart grids;Data visualisation;tangible and embedded interaction;augmented reality;immersive analytics},
  doi={10.1109/TVCG.2020.3030334}}",Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics,,Small,Single,A tangible widget,N/A,Rigid,No use,Polyhedron,A time granularity picker,Planar surface,The bottom surface of time granularity picker,One-handed,Positioning,Locating a picker on desktop for selecting a level of time granularity of the 3D visualization.,on the horizontal surface,Position,Physical widget: 2DOF translation in the plane.,Looking up,3D,3D stacked choropleth map,The selected time granularity of the 3D visualization of space-time cube displayed in the augmented reality (HMD).,Augmented reality,Use a polyhedron to lookup a 3D stacked choropleth map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The stick with a slider is in user's hand.
2. The stick with a slider is discrete from the 3D visualization.
2. The 3D visualization is above the desktop."
65,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/9229116,"Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim","@ARTICLE{9229116,
  author={Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics}, 
  year={2021},
  volume={27},
  number={2},
  pages={1193-1203},
  keywords={Collaboration;Data visualization;Three-dimensional displays;Visual analytics;Stakeholders;Microgrids;Smart grids;Data visualisation;tangible and embedded interaction;augmented reality;immersive analytics},
  doi={10.1109/TVCG.2020.3030334}}",Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics,,Small,Single,A tangible widget,N/A,"Rigid, Reconfigurable",No use,Constrained body,A stick with a slider,Straight edge,The slider's motion path along the stick,One-handed,Positioning,Sliding the slider in space for adjusting the time of the 3D visualization.,above the horizontal surface,Position,Physical widget: 1DOF translation in a constrained direction.,Adjusting,3D,3D stacked choropleth map,The time of the 3D visualization of space-time cube displayed in the augmented reality (HMD).,Augmented reality,Use a constrained body to adjust a 3D stacked choropleth map by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The stick with a slider is in user's hand.
2. The stick with a slider is discrete from the 3D visualization.
2. The 3D visualization is above the desktop."
65,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/9229116,"Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim","@ARTICLE{9229116,
  author={Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics}, 
  year={2021},
  volume={27},
  number={2},
  pages={1193-1203},
  keywords={Collaboration;Data visualization;Three-dimensional displays;Visual analytics;Stakeholders;Microgrids;Smart grids;Data visualisation;tangible and embedded interaction;augmented reality;immersive analytics},
  doi={10.1109/TVCG.2020.3030334}}",Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics,,Small,Single,A tangible widget,N/A,"Rigid, Reconfigurable",No use,Slender body,A stick-shaped block,Body,A stick-shaped block,One-handed,Rotating,Rotating a stick-shaped block in space for switching the representation type of the 3D visualization.,above the horizontal surface,Rotation,Physical widget: 1DOF rotation at the plane perpendicular to the rotation axis in the space.,Replacing,3D,3D stacked choropleth map,The representation type of the 3D visualization of space-time cube displayed in the augmented reality (HMD).,Augmented reality,Use a slender body to replace a 3D stacked choropleth map by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The stick-shaped block is in user's hand.
2. The stick-shaped block is discrete from the 3D visualization.
2. The 3D visualization is above the desktop."
65,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/9229116,"Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim","@ARTICLE{9229116,
  author={Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics}, 
  year={2021},
  volume={27},
  number={2},
  pages={1193-1203},
  keywords={Collaboration;Data visualization;Three-dimensional displays;Visual analytics;Stakeholders;Microgrids;Smart grids;Data visualisation;tangible and embedded interaction;augmented reality;immersive analytics},
  doi={10.1109/TVCG.2020.3030334}}",Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics,,Small,Double,A virtual widget+A tangible widget,Fully mapped,"Rigid, Reconfigurable",No use,Constrained body (with Planar surface),A stick with a slider (with a virtual cutting plane),Planar surface,A virtual cutting plane,One-handed,Positioning,Sliding the slider in space to control a virtual cutting plane for slicing the 3D visualization.,above the horizontal surface,Position,"Virtual widget: 1DOF translation in a constrained direction.
Physical widget: 1DOF translation in a constrained direction.",Clipping,3D,3D stacked choropleth map,The position of slice of the 3D visualization of space-time cube displayed in the augmented reality (HMD).,Augmented reality,Use a planar surface controlled by a constrained body to clip a 3D stacked choropleth map by positioning.,Reachable,"Virtual: Not impacted within the accessible distance.
Physical: Interaction is possible only if manipulable entity is grabbed by user.",Reachable,Not impacted within the accessible distance.,Crossed,"1. The stick with a slider is in user's hand.
2. The virtual cutting plane controlled by the stick with a slider is crossed over the 3D visualization.
3. The 3D visualization is above the desktop."
65,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/9229116,"Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim","@ARTICLE{9229116,
  author={Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics}, 
  year={2021},
  volume={27},
  number={2},
  pages={1193-1203},
  keywords={Collaboration;Data visualization;Three-dimensional displays;Visual analytics;Stakeholders;Microgrids;Smart grids;Data visualisation;tangible and embedded interaction;augmented reality;immersive analytics},
  doi={10.1109/TVCG.2020.3030334}}",Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics,,Small,Single,A tangible widget,N/A,Rigid,No use,Other,A low-fidelity model of buildings,Body,A low-fidelity model of buildings,One-handed,Positioning,Picking up a low-fidelity model of buildings on desktop for displaying information of the building.,on the horizontal surface,Position,Physical widget: 1DOF translation in the vertical direction.,Modulating,2D,2D text,The information of the 2D visualization of the building displayed in the augmented reality (HMD).,Augmented reality,Use an other to modulate a 2D text by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The low-fidelity model of building is in user's hand.
2. The low-fidelity model of building is aligned with the 2D visualization.
2. The 2D visualization is above the desktop."
66,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/7118242,"L¨®pez, David and Oehlberg, Lora and Doger, Candemir and Isenberg, Tobias","@ARTICLE{7118242,
  author={L¨®pez, David and Oehlberg, Lora and Doger, Candemir and Isenberg, Tobias},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Towards An Understanding of Mobile Touch Navigation in a Stereoscopic Viewing Environment for 3D Data Exploration}, 
  year={2016},
  volume={22},
  number={5},
  pages={1616-1629},
  keywords={Three-dimensional displays;Stereo image processing;Cameras;Data visualization;Navigation;Mobile handsets;Visualization;Visualization of 3D data;human-computer interaction;expert interaction;direct-touch input;mobile displays;stereoscopic environments;VR;AR;conceptual model of interaction;interaction reference frame mapping;observational study;Visualization of 3D data;human-computer interaction;expert interaction;direct-touch input;mobile displays;stereoscopic environments;VR;AR;conceptual model of interaction;interaction reference frame mapping;observational study},
  doi={10.1109/TVCG.2015.2440233}}",Towards An Understanding of Mobile Touch Navigation in a Stereoscopic Viewing Environment for 3D Data Exploration,,Medium,Single,A tangible widget,N/A,Rigid,No use,Plate,A handheld tablet,Body,A handheld tablet,Symmetric,Rotating,Rotating the handheld tablet in space to rotate the 3D visualization for manipulating.,in the room space,Rotation,Physical widget: 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D fluid volume rendering+3D molecular visualization,The rotation of the 3D visualization of fluid/molecular data displayed in the stereoscopic screen.,Stereoscopic screen,Use a plate to translate/rotate/scale a 3D fluid volume rendering+3D molecular visualization by two-handed rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Discrete,"1. The handheld tablet is in user's hand.
2. The handheld tablet is discrete from the 3D visualization.
3. The 3D visualization is in the room."
67,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/8019876,"Bach, Benjamin and Sicat, Ronell and Beyer, Johanna and Cordeil, Maxime and Pfister, Hanspeter","@ARTICLE{8019876,
  author={Bach, Benjamin and Sicat, Ronell and Beyer, Johanna and Cordeil, Maxime and Pfister, Hanspeter},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality?}, 
  year={2018},
  volume={24},
  number={1},
  pages={457-467},
  keywords={Three-dimensional displays;Data visualization;Two dimensional displays;Augmented reality;Stereo image processing;Visualization;Mice;Augmented Reality;3D Interaction;User Study;Immersive Displays},
  doi={10.1109/TVCG.2017.2745941}}",The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality?,,Medium,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",No use,Plate,A sheet of paper,Planar surface,A sheet of paper,One-handed,Positioning+Rotating,Moving a paper in space for manipulating the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Translating/Rotating/Scaling,3D,3D scatterplot,The position and rotation of a 3D scatter visualization displayed in the augmented reality (HMD)/(screen).,Augmented reality,Use a plate to translate/rotate/scale a 3D scatterplot by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The paper is in user's hand. 
2. The paper is aligned with the 3D visualization.
3. The 3D visualization is above the desktop."
67,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/8019876,"Bach, Benjamin and Sicat, Ronell and Beyer, Johanna and Cordeil, Maxime and Pfister, Hanspeter","@ARTICLE{8019876,
  author={Bach, Benjamin and Sicat, Ronell and Beyer, Johanna and Cordeil, Maxime and Pfister, Hanspeter},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality?}, 
  year={2018},
  volume={24},
  number={1},
  pages={457-467},
  keywords={Three-dimensional displays;Data visualization;Two dimensional displays;Augmented reality;Stereo image processing;Visualization;Mice;Augmented Reality;3D Interaction;User Study;Immersive Displays},
  doi={10.1109/TVCG.2017.2745941}}",The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality?,,Medium,Single,A tangible widget,N/A,"Bendable, Foldable, Twistable",No use,Plate,A sheet of paper,Planar surface,A surface of the paper,One-handed,Positioning+Rotating,Moving a paper in space for slicing the 3D visualization.,above the horizontal surface,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Clipping,3D,3D scatterplot,The position and rotation of the cutting plane within the 3D scatter visualization displayed in the augmented reality (HMD)/(screen).,Augmented reality,Use a plate to clip a 3D scatterplot by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Crossed,"1. The tablet is in user's hand. 
2. The cutting plane attached to the surface of paper is crossed over the 3D visualization.
3. The 3D visualization is above the desktop."
68,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/8642297,"Mirhosseini, Seyedkoosha and Gutenko, Ievgeniia and Ojal, Sushant and Marino, Joseph and Kaufman, Arie","@ARTICLE{8642297,
  author={Mirhosseini, Seyedkoosha and Gutenko, Ievgeniia and Ojal, Sushant and Marino, Joseph and Kaufman, Arie},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Immersive Virtual Colonoscopy}, 
  year={2019},
  volume={25},
  number={5},
  pages={2011-2021},
  keywords={Colon;Rendering (computer graphics);Tools;Computed tomography;Biopsy;Task analysis;Haptic interfaces;Immersive Environments;Immersive Analytics;Interaction Design;Volume Rendering;Biomedical Visualization;Colon Cancer Screening;Medical Diagnosis},
  doi={10.1109/TVCG.2019.2898763}}",Immersive Virtual Colonoscopy,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A handheld VR controller,Point,The distal end of handheld VR controller,One-handed,Positioning+Rotating,Moving a handheld VR controller in space to for placing a light.,in the room space,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,3D,3D medical volume rendering,The placed light within the 3D visualization of medical volume data displayed in the virtual reality (HMD).,Virtual reality,Use a slender body to modulate a 3D medical volume rendering by positioning+rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Interaction is possible only if task object is reachable by user.,Embedded,"1. The handheld VR controller is in user's hand.
2. The distal end of handheld VR controller is embedded with the 3D visualization.
3. The 3D visualization is in the room."
68,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/8642297,"Mirhosseini, Seyedkoosha and Gutenko, Ievgeniia and Ojal, Sushant and Marino, Joseph and Kaufman, Arie","@ARTICLE{8642297,
  author={Mirhosseini, Seyedkoosha and Gutenko, Ievgeniia and Ojal, Sushant and Marino, Joseph and Kaufman, Arie},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Immersive Virtual Colonoscopy}, 
  year={2019},
  volume={25},
  number={5},
  pages={2011-2021},
  keywords={Colon;Rendering (computer graphics);Tools;Computed tomography;Biopsy;Task analysis;Haptic interfaces;Immersive Environments;Immersive Analytics;Interaction Design;Volume Rendering;Biomedical Visualization;Colon Cancer Screening;Medical Diagnosis},
  doi={10.1109/TVCG.2019.2898763}}",Immersive Virtual Colonoscopy,,Small,Single,A tangible widget,N/A,Rigid,No use,Slender body,A handheld VR controller,Straight edge,A casting ray attached to the distal end of handheld VR controller,One-handed,Casting,Moving a handheld VR controller in space to cast a ray on the 3D visualization to input a position for creating a magic lantern/measurement widget/bookmark annotation.,in the room space,"Position,Rotation",Physical widget: 3DOF translation and 3DOF rotation in the space.,Modulating,3D,3D medical volume rendering,The position of magic lantern within the 3D visualization of medical volume data displayed in the virtual reality (HMD).,Virtual reality,Use a slender body to modulate a 3D medical volume rendering by casting.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Crossed,"1. The handheld VR controller is in user's hand.
2. The casting ray from handheld VR controller is crossed over the 3D visualization.
3. The 3D visualization is in the room."
68,TVCG,3D Interaction,https://ieeexplore.ieee.org/document/8642297,"Mirhosseini, Seyedkoosha and Gutenko, Ievgeniia and Ojal, Sushant and Marino, Joseph and Kaufman, Arie","@ARTICLE{8642297,
  author={Mirhosseini, Seyedkoosha and Gutenko, Ievgeniia and Ojal, Sushant and Marino, Joseph and Kaufman, Arie},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Immersive Virtual Colonoscopy}, 
  year={2019},
  volume={25},
  number={5},
  pages={2011-2021},
  keywords={Colon;Rendering (computer graphics);Tools;Computed tomography;Biopsy;Task analysis;Haptic interfaces;Immersive Environments;Immersive Analytics;Interaction Design;Volume Rendering;Biomedical Visualization;Colon Cancer Screening;Medical Diagnosis},
  doi={10.1109/TVCG.2019.2898763}}",Immersive Virtual Colonoscopy,,Small,Double,A virtual widget+A tangible widget,Partial mapped,Rigid,No use,Slender body (with Planar surface),A handheld VR controller (with a virtual cutting plane),Planar surface,A virtual cutting plane,One-handed,Casting,Moving a handheld VR controller in space to cast a ray on the 3D visualization to input a position to control a virtual cutting plane for slicing the 3D visualization.,in the room space,"Position,Rotation","Virtual widget: 1DOF translation in a constrained direction.
Physical widget: 3DOF translation and 3DOF rotation in the space.",Clipping,3D,3D medical volume rendering,"The image, position and rotation of slice of the 3D visualization of medical volume data displayed in the virtual reality (HMD).",Virtual reality,Use a planar surface controlled by a slender body to clip a 3D medical volume rendering by casting.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Flexible,Not impacted within the accessible distance.,Crossed,"1. The handheld VR controller is in user's hand.
2. The cutting plane controlled by thecasting ray attached to the distal end of handheld VR controller is crossed over the 3D visualization.
3. The 3D visualization is in the room."
69,TEI,Widget,https://dl.acm.org/doi/10.1145/1935701.1935746,"Ullmer, Brygg and Dell, Christian and Gil, Claudia and Toole, Cornelius and Wiley, Cole and Dever, Zachary and Rogge, Landon and Bradford, Rachel and Riviere, Guillaume and Sankaran, Rajesh and Liu, Kexi and Freeman, Chase and Wallace, Alvin and DeLatin, Michael and Washington, Christian and Reeser, Alex and Branton, Christopher W. and Parker, Rod","@inproceedings{10.1145/1935701.1935746,
author = {Ullmer, Brygg and Dell, Christian and Gil, Claudia and Toole, Cornelius and Wiley, Cole and Dever, Zachary and Rogge, Landon and Bradford, Rachel and Riviere, Guillaume and Sankaran, Rajesh and Liu, Kexi and Freeman, Chase and Wallace, Alvin and DeLatin, Michael and Washington, Christian and Reeser, Alex and Branton, Christopher W. and Parker, Rod},
title = {Casier: structures for composing tangibles and complementary interactors for use across diverse systems},
year = {2010},
isbn = {9781450304788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935701.1935746},
doi = {10.1145/1935701.1935746},
abstract = {Casiers are a class of tangible interface elements that structure the physical and functional composition of tangibles and complementary interactors (e.g., buttons and sliders). Casiers allow certain subsets of interactive functionality to be accessible across diverse interactive systems (with and without graphical mediation, employing varied sensing capabilities and supporting software). We illustrate examples of casiers in use, including iterations around a custom walk-up-and-use kiosk, as well as casiers operable across com- mercial platforms of widely varying cost and capability.},
booktitle = {Proceedings of the Fifth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {229¨C236},
numpages = {8},
keywords = {tangible interfaces, slotted widgets, reality-based interaction, core tangibles, casier tangibles, cartouche tangibles},
location = {Funchal, Portugal},
series = {TEI '11}
}",Casier: structures for composing tangibles and complementary interactors for use across diverse systems,,Large,Single,A tangible widget,N/A,Rigid,No use,Constrained body,A constrained cartouche in a slot,Straight edge,The cartouche's motion path along the slot,One-handed,Positioning,Sliding the cartouche on desktop for selecting an interaction used to express.,on the inclined surface,Position,Physical widget: 1DOF translation in a constrained direction.,Looking up,2D,2D graphic,The selected interaction used to express in the 2D graphic displayed on the wall screen.,2D display,Use a plate to lookup a 2D graphic by positioning.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Discrete,"1. The cartouche is on the desktop.
2. The cartouche is discrete from the 2D graphic.
3. The 2D graphic is on the wall."
69,TEI,Widget,https://dl.acm.org/doi/10.1145/1935701.1935746,"Ullmer, Brygg and Dell, Christian and Gil, Claudia and Toole, Cornelius and Wiley, Cole and Dever, Zachary and Rogge, Landon and Bradford, Rachel and Riviere, Guillaume and Sankaran, Rajesh and Liu, Kexi and Freeman, Chase and Wallace, Alvin and DeLatin, Michael and Washington, Christian and Reeser, Alex and Branton, Christopher W. and Parker, Rod","@inproceedings{10.1145/1935701.1935746,
author = {Ullmer, Brygg and Dell, Christian and Gil, Claudia and Toole, Cornelius and Wiley, Cole and Dever, Zachary and Rogge, Landon and Bradford, Rachel and Riviere, Guillaume and Sankaran, Rajesh and Liu, Kexi and Freeman, Chase and Wallace, Alvin and DeLatin, Michael and Washington, Christian and Reeser, Alex and Branton, Christopher W. and Parker, Rod},
title = {Casier: structures for composing tangibles and complementary interactors for use across diverse systems},
year = {2010},
isbn = {9781450304788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935701.1935746},
doi = {10.1145/1935701.1935746},
abstract = {Casiers are a class of tangible interface elements that structure the physical and functional composition of tangibles and complementary interactors (e.g., buttons and sliders). Casiers allow certain subsets of interactive functionality to be accessible across diverse interactive systems (with and without graphical mediation, employing varied sensing capabilities and supporting software). We illustrate examples of casiers in use, including iterations around a custom walk-up-and-use kiosk, as well as casiers operable across com- mercial platforms of widely varying cost and capability.},
booktitle = {Proceedings of the Fifth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {229¨C236},
numpages = {8},
keywords = {tangible interfaces, slotted widgets, reality-based interaction, core tangibles, casier tangibles, cartouche tangibles},
location = {Funchal, Portugal},
series = {TEI '11}
}",Casier: structures for composing tangibles and complementary interactors for use across diverse systems,,Large,Single,A tangible widget,N/A,Rigid,No use,Plate,A wheel,Planar surface,The bottom surface of wheel,One-handed,Rotating,Rotating a wheel on desktop for adjusting an input parameter.,on the inclined surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D graphic,The input parameter of the 2D graphic displayed on the wall screen.,2D display,Use a plate to adjust a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Unreachable,Not impacted within the accessible distance.,Discrete,"1. The wheel is on the desktop.
2. The wheel is discrete from the 2D graphic.
3. The 2D graphic is on the wall."
70,TEI,Widget,https://dl.acm.org/doi/10.1145/3623509.3633382,"Getschmann, Christopher and Echtler, Florian","@inproceedings{10.1145/3623509.3633382,
author = {Getschmann, Christopher and Echtler, Florian},
title = {LensLeech: On-Lens Interaction for Arbitrary Camera Devices},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623509.3633382},
doi = {10.1145/3623509.3633382},
abstract = {Cameras provide a vast amount of information at high rates and are part of many specialized or general-purpose devices. This versatility makes them suitable for many interaction scenarios, yet they are constrained by geometry and require objects to keep a minimum distance for focusing. We present the LensLeech, a soft silicone cylinder that can be placed directly on or above lenses. The clear body itself acts as a lens to focus a marker pattern from its surface into the camera it sits on. This allows us to detect rotation, translation, and deformation-based gestures such as pressing or squeezing the soft silicone. We discuss design requirements, describe fabrication processes, and report on the limitations of such on-lens widgets. To demonstrate the versatility of LensLeeches, we built prototypes to show application examples for wearable cameras, smartphones, and interchangeable-lens cameras, extending existing devices by providing both optical input and output for new functionality.},
booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {34},
numpages = {10},
keywords = {Elastomer Sensors, Mobile Interfaces, Optical Widgets},
location = {Cork, Ireland},
series = {TEI '24}
}",LensLeech: On-Lens Interaction for Arbitrary Camera Devices,,Small,Single,A tangible widget,N/A,Elastic,No use,Plate,A soft silicone attachment,Planar surface,The bottom surface of soft silicone attachment,One-handed,Rotating,Rotating a wheel on desktop for traversing a list.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Looking up,2D,2D text,The selected item in list displayed on the screen.,2D display,Use a plate to lookup a 2D text by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The soft silicone attachment is in user's hand.
2. The soft silicone attachment is discrete from the 2D graphic.
3. The 2D graphic is on the screen."
70,TEI,Widget,https://dl.acm.org/doi/10.1145/3623509.3633382,"Getschmann, Christopher and Echtler, Florian","@inproceedings{10.1145/3623509.3633382,
author = {Getschmann, Christopher and Echtler, Florian},
title = {LensLeech: On-Lens Interaction for Arbitrary Camera Devices},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623509.3633382},
doi = {10.1145/3623509.3633382},
abstract = {Cameras provide a vast amount of information at high rates and are part of many specialized or general-purpose devices. This versatility makes them suitable for many interaction scenarios, yet they are constrained by geometry and require objects to keep a minimum distance for focusing. We present the LensLeech, a soft silicone cylinder that can be placed directly on or above lenses. The clear body itself acts as a lens to focus a marker pattern from its surface into the camera it sits on. This allows us to detect rotation, translation, and deformation-based gestures such as pressing or squeezing the soft silicone. We discuss design requirements, describe fabrication processes, and report on the limitations of such on-lens widgets. To demonstrate the versatility of LensLeeches, we built prototypes to show application examples for wearable cameras, smartphones, and interchangeable-lens cameras, extending existing devices by providing both optical input and output for new functionality.},
booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {34},
numpages = {10},
keywords = {Elastomer Sensors, Mobile Interfaces, Optical Widgets},
location = {Cork, Ireland},
series = {TEI '24}
}",LensLeech: On-Lens Interaction for Arbitrary Camera Devices,,Small,Single,A tangible widget,N/A,Elastic,Elastic,Plate,A soft silicone attachment,Body,A soft silicone attachment,One-handed,Shaping,Squeezing a soft silicone attachment in space for adjusting the status of confirmation/cancellation.,in the room space,Scale,Physical widget: 1DOF scale in the space.,Adjusting,2D,2D text,The status of confirmation/cancellation displayed on the screen.,2D display,Use a plate to adjust a 2D text by shaping.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Discrete,"1. The soft silicone attachment is in user's hand.
2. The soft silicone attachment is discrete from the 2D graphic.
3. The 2D graphic is on the screen."
71,ISS,Widget,https://dl.acm.org/doi/10.1145/2817721.2817725,"Voelker, Simon and \O{}verg\r{a}rd, Kjell Ivar and Wacharamanotham, Chat and Borchers, Jan","@inproceedings{10.1145/2817721.2817725,
author = {Voelker, Simon and \O{}verg\r{a}rd, Kjell Ivar and Wacharamanotham, Chat and Borchers, Jan},
title = {Knobology Revisited: A Comparison of User Performance between Tangible and Virtual Rotary Knobs},
year = {2015},
isbn = {9781450338998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2817721.2817725},
doi = {10.1145/2817721.2817725},
abstract = {We present an experimental comparison of tangible rotary knobs and touch-based virtual knobs in three output conditions: eyes-on, eyes-free, and peripheral. Twenty participants completed a simple rotation task on a interactive surface with four different input techniques (two tangibles and two virtual touch widgets) in the three output conditions, representing the distance from the locus of attention. We found that users were in average 20\% faster using tangible knobs than using the virtual knobs. We found that tangible knobs retains performance even if they are not in the locus of attention of the users. We provide four recommendations of suit- able choosing knobs based on tasks and design constraints.},
booktitle = {Proceedings of the 2015 International Conference on Interactive Tabletops \& Surfaces},
pages = {35¨C38},
numpages = {4},
keywords = {tangible user interfaces, tabletop interaction, rotary widget},
location = {Madeira, Portugal},
series = {ITS '15}
}",Knobology Revisited: A Comparison of User Performance between Tangible and Virtual Rotary Knobs,,Small,Single,A tangible widget,N/A,Rigid,No use,Plate,A knob/puck,Planar surface,The bottom surface of knob/puck,One-handed,Rotating,Rotating a knob/puck on desktop for adjusting an input parameter.,on the horizontal surface,Rotation,Physical widget: 1DOF rotation in the plane.,Adjusting,2D,2D graphic,The input parameter of the 2D graphic displayed on the desktop screen.,2D display,Use a plate to adjust a 2D graphic by rotating.,Reachable,Physical: Interaction is possible only if manipulable entity is grabbed by user.,Reachable,Not impacted within the accessible distance.,Aligned,"1. The knob/puck is in on the desktop. 
2. The knob/puck is aligned with the 2D graphic.
3. The 2D graphic is on the desktop."
